[{"title":"PaddleOCR模型训练详解","url":"/2025/07/24/ppocr-config/","content":"\n## PaddleOCR文本检测-模型训练配置文件\n\n### 1. Global（全局配置）\n\n| 字段                                                  | 含义                                                         |\n| :---------------------------------------------------- | :----------------------------------------------------------- |\n| `model_name: PP-OCRv5_server_det`                     | 任务名称，仅用于日志/保存路径等标识。                        |\n| `debug: false`                                        | 关闭调试信息。                                               |\n| `use_gpu: true`                                       | 强制使用 GPU 训练。                                          |\n| `epoch_num: &epoch_num 500`                           | 训练 500 个 epoch；`&epoch_num` 是 YAML 锚点，后文可用 `*epoch_num` 引用。 |\n| `log_smooth_window: 20`                               | 日志中 loss 取最近 20 个 batch 的滑动平均。                  |\n| `print_batch_step: 10`                                | 每 10 个 batch 打印一次 log。                                |\n| `save_model_dir: ./output/PP-OCRv5_server_det`        | 训练过程中保存 checkpoints 的根目录。                        |\n| `save_epoch_step: 10`                                 | 每 10 个 epoch 保存一次 checkpoint。                         |\n| `eval_batch_step: [0, 1500]`                          | 训练到第 0 个 batch 就开始第一次验证，此后每 1500 个 batch 再验证一次。 |\n| `cal_metric_during_train: false`                      | 训练 forward 时不立即算指标，节省显存。                      |\n| `checkpoints:`                                        | 当需要从某个 checkpoint 继续训练时填写路径；这里留空表示从头训练。 |\n| `pretrained_model: <url...>`                          | 预训练权重。                                                 |\n| `save_inference_dir: null`                            | 训练完成后若需要导出 inference 模型，可填目录；null 表示不导出。 |\n| `use_visualdl: false`                                 | 不使用 VisualDL 可视化。                                     |\n| `infer_img: doc/imgs_en/img_10.jpg`                   | 单张图快速推理时的默认图片。                                 |\n| `save_res_path: ./checkpoints/det_db/predicts_db.txt` | 推理结果保存路径。                                           |\n| `distributed: true`                                   | 开启多卡分布式训练（需 `paddle.distributed.launch` 启动）。  |\n\n------\n\n### 2. Architecture（网络结构）\n\n| 字段                          | 含义                                          |\n| :---------------------------- | :-------------------------------------------- |\n| `model_type: det`             | 任务类型：检测（det）。                       |\n| `algorithm: DB`               | 检测算法：Differentiable Binarization。       |\n| `Transform: null`             | 未使用额外变换模块。                          |\n| `Backbone.name: PPHGNetV2_B4` | 主干网络，PPHGNetV2_B4 是飞桨自研轻量级网络。 |\n| `Backbone.det: True`          | 打开检测任务的特定结构开关。                  |\n| `Neck.name: LKPAN`            | 颈部网络，LKPAN = Large Kernel PAN。          |\n| `Neck.out_channels: 256`      | LKPAN 输出通道数。                            |\n| `Neck.intracl: true`          | 启用 Intra-channel CL（通道内上下文增强）。   |\n| `Head.name: PFHeadLocal`      | 检测头，PFHeadLocal 表示局部感知预测头。      |\n| `Head.k: 50`                  | 每个像素取最近的 50 个轮廓点做预测。          |\n| `Head.mode: \"large\"`          | 使用 large 模式，对应高分辨率场景。           |\n\n------\n\n### 3. Loss（损失函数）\n\n| 字段                       | 含义                                          |\n| :------------------------- | :-------------------------------------------- |\n| `name: DBLoss`             | DB 论文的复合损失。                           |\n| `balance_loss: true`       | 正负样本平衡。                                |\n| `main_loss_type: DiceLoss` | 主损失为 Dice Loss。                          |\n| `alpha: 5, beta: 10`       | 控制 shrink map 与 threshold map 损失的权重。 |\n| `ohem_ratio: 3`            | OHEM 时负样本/正样本 ≈ 3:1。                  |\n\n------\n\n### 4. Optimizer（优化器）\n\n| 字段                                 | 含义                                                         |\n| :----------------------------------- | :----------------------------------------------------------- |\n| `name: Adam`                         | 使用 Adam。                                                  |\n| `beta1 / beta2`                      | Adam 默认 0.9 / 0.999。                                      |\n| `lr.name: Cosine`                    | 余弦退火学习率。                                             |\n| `lr.learning_rate: 0.001`            | 基础 lr，对应 8×8=64 卡总 batch_size 时的经验值；若你 batch_size 不同需线性缩放。 |\n| `lr.warmup_epoch: 2`                 | 前 2 个 epoch 线性 warmup。                                  |\n| `regularizer.name: L2, factor: 1e-6` | 权重衰减 1e-6。                                              |\n\n------\n\n### 5. PostProcess（后处理）\n\n| 字段                   | 含义                     |\n| :--------------------- | :----------------------- |\n| `name: DBPostProcess`  | DB 官方后处理。          |\n| `thresh: 0.3`          | 二值化阈值。             |\n| `box_thresh: 0.6`      | 文本框 score 阈值。      |\n| `max_candidates: 1000` | 单图最多输出 1000 个框。 |\n| `unclip_ratio: 1.5`    | 轮廓外扩比例。           |\n\n------\n\n### 6. Metric（评估指标）\n\n| 字段                    | 含义                                                |\n| :---------------------- | :-------------------------------------------------- |\n| `name: DetMetric`       | 检测指标：precision / recall / hmean。              |\n| `main_indicator: hmean` | 以 hmean 作为 early-stop / best-checkpoint 的依据。 |\n\n------\n\n### 7. Train（训练阶段数据与增强）\n\n| 字段                            | 含义                                                         |\n| :------------------------------ | :----------------------------------------------------------- |\n| `dataset.name: SimpleDataSet`   | 飞桨统一格式检测数据集。                                     |\n| `data_dir` / `label_file_list`  | 图片根目录 + 训练标注 txt。                                  |\n| `ratio_list: [1.0]`             | 目前仅用 1 份训练集。                                        |\n| **Transforms 列表**             |                                                              |\n| `DecodeImage`                   | 读图，BGR 格式。                                             |\n| `DetLabelEncode`                | 把标注解析为多边形。                                         |\n| `CopyPaste`                     | 随机 copy-paste 增强。                                       |\n| `IaaAugment`                    | Albumentations-style 增强：翻转、±10°旋转、0.5~3 倍尺度缩放。 |\n| `EastRandomCropData`            | 随机 crop 出 640×640 的小图。                                |\n| `MakeBorderMap`                 | 为 threshold map 生成训练目标。                              |\n| `MakeShrinkMap`                 | 为 shrink map 生成训练目标。                                 |\n| `NormalizeImage`                | ImageNet 归一化。                                            |\n| `ToCHWImage`                    | HWC→CHW。                                                    |\n| `KeepKeys`                      | 指定网络输入的 key 顺序。                                    |\n| `loader.batch_size_per_card: 8` | 单卡 batch=8，总 batch = 8 × GPU 数。                        |\n| `loader.num_workers: 8`         | 每个卡 8 个子进程加载数据。                                  |\n\n------\n\n### 8. Eval（验证阶段）\n\n| 字段                                             | 含义                                                     |\n| :----------------------------------------------- | :------------------------------------------------------- |\n| `dataset/label_file_list`                        | 验证集标注 txt。                                         |\n| `DetResizeForTest`                               | 验证时按原图长边不超过 2560 进行等比例缩放（默认逻辑）。 |\n| 其余 transforms 与训练阶段一致，但不做随机增强。 |                                                          |\n| `batch_size_per_card: 1`                         | 验证时单卡 batch=1，避免大图显存爆炸。                   |\n| `num_workers: 2`                                 | 验证数据加载进程数。                                     |\n\n------\n\n### 9. profiler_options: null\n\n未开启 Paddle Profiler 性能分析。\n\n------\n\n### 使用建议\n\n1、**GPU 显存不足**\n可把 `batch_size_per_card` 从 8 调到 4，或把 `EastRandomCropData.size` 降到 `[512,512]`。\n\n2、**学习率**\n若只用 1-2 张卡，需把 `learning_rate` 线性减小（例如单卡设 0.001/8 ≈ 0.000125）。\n\n## 模型训练中日志输出内容详解\n\n### 模型训练中单次step的日志\n\n```bash\nppocr INFO: epoch: [1/500], global_step: 10, lr: 0.000090, loss: 1.843800, loss_shrink_maps: 0.954784, loss_threshold_maps: 0.559544, loss_binary_maps: 0.191454, loss_cbn: 0.191454, avg_reader_cost: 0.07927 s, avg_batch_cost: 0.40427 s, avg_samples: 4.0, ips: 9.89442 samples/s, eta: 1:24:09, max_mem_reserved: 6279 MB, max_mem_allocated: 5350 MB\n```\n\n这段日志是 **PaddleOCR 文本检测模型训练过程中的一次 step 日志输出**，发生在 **第 1 个 epoch、第 10 个 global_step** 时。\n\n**以下是详细解释：**\n\n| 字段                            | 含义                                                         |\n| ------------------------------- | :----------------------------------------------------------- |\n| `epoch: [1/500]`                | 当前是第 1 个 epoch，总共训练 500 个 epoch。                 |\n| `global_step: 10`               | 从训练开始累计的第 10 个 batch。                             |\n| `lr: 0.000090`                  | 当前学习率（warmup 阶段，还没升到预设的 0.001）。            |\n| `loss: 1.843800`                | **总损失**，是下面各项损失的加权和。                         |\n| `loss_shrink_maps: 0.954784`    | **收缩图（shrink map）的 Dice Loss**，用于学习文字区域核心区域。 |\n| `loss_threshold_maps: 0.559544` | **阈值图（threshold map）的 L1 Loss**，用于学习二值化阈值。  |\n| `loss_binary_maps: 0.191454`    | **二值图（binary map）的 Dice Loss**，用于学习最终二值化结果。 |\n| `loss_cbn: 0.191454`            | 与 `loss_binary_maps` 相同，可能是兼容旧版本的字段名。       |\n\n| 性能相关字段                 | 含义                                                       |\n| :--------------------------- | :--------------------------------------------------------- |\n| `avg_reader_cost: 0.07927 s` | 每 batch 数据读取平均耗时（79ms）。                        |\n| `avg_batch_cost: 0.40427 s`  | 每 batch 总耗时（包括前向+反向+优化器更新）。              |\n| `avg_samples: 4.0`           | 每 batch 实际样本数（你设的是 `batch_size_per_card: 4`）。 |\n| `ips: 9.89442 samples/s`     | 当前实际吞吐 ≈ 10 张图/秒。                                |\n| `eta: 1:24:09`               | **预计剩余训练时间** 1 小时 24 分 9 秒（基于当前速度）。   |\n| `max_mem_reserved: 6279 MB`  | GPU 显存最大预留量（PyTorch/Paddle 显存池）。              |\n| `max_mem_allocated: 5350 MB` | GPU 显存实际使用量。                                       |\n\n#### 结论\n\n- **训练已正常启动**，GPU 显存占用 ≈ 5.3 GB，无 OOM。\n- **数据加载耗时占比不高**（79 ms vs 404 ms），说明数据 pipeline 合理。\n- **吞吐 10 img/s**，如果 GPU 利用率低，可考虑：\n  - 增大 `batch_size_per_card`；\n  - 提高 `num_workers`；\n  - 开启 AMP (`--amp_level=O2`) 加速。\n\n### 训练完成后的模型评估结果日志\n\n```bash\nppocr INFO: best metric, hmean: 0.7633587786259542, is_float16: False, precision: 0.78125, recall: 0.746268656716418, fps: 30.84728874632143, best_epoch: 60\n```\n\n这段日志是 **训练完成后的“最佳模型”评估结果**，记录了在 **验证集** 上表现最好的那次 epoch（这里是第 60 个 epoch）的检测性能指标。逐项解释如下：\n\n| 字段                        | 含义                                                         |\n| :-------------------------- | :----------------------------------------------------------- |\n| `best metric`               | 说明这是到目前为止 **最好的综合指标** 的一行日志。           |\n| `hmean: 0.7633587786259542` | **F-score（H-mean）**，即 Precision 与 Recall 的调和平均数，是检测任务的核心评价指标，越高越好。这里约为 **76.34%**。 |\n| `is_float16: False`         | 表示 **未启用 FP16 混合精度** 推理（即使用 FP32）。          |\n| `precision: 0.78125`        | **精确率** ≈ 78.13%，即预测为文本的框中有 78.13% 是正确的。  |\n| `recall: 0.746268656716418` | **召回率** ≈ 74.63%，即所有真实文本框中有 74.63% 被成功检测到。 |\n| `fps: 30.84728874632143`    | **推理速度**，约 **30.85 帧/秒**（基于验证集单张图测试）。   |\n| `best_epoch: 60`            | 在 **第 60 个 epoch** 时达到上述最佳成绩。                   |\n\n#### 结论\n\n- 当前模型在验证集上取得 **H-mean ≈ 76.3%** 的效果，属于 **中等偏上的检测精度**（具体好坏取决于数据集难度）。\n- **Precision > Recall** 说明模型更“保守”，漏检略多于误检。\n- 推理速度 **30.85 FPS**，可满足实时场景（≥25 FPS）。\n- 若需要更高精度，可继续训练（尚未到 500 epoch），或尝试数据增强、更大 backbone、FP16 推理提速。\n","tags":["PaddleOCR"],"categories":["人工智能"]},{"title":"PaddleOCR安装部署及模型微调","url":"/2025/07/24/ppocr/","content":"\n## 1. 安装PaddlePaddle\n\n请参考下述命令，使用飞桨框架官方 Docker 镜像，创建一个名为 `paddle` 的容器，并将当前工作目录映射到容器内的 `/paddle` 目录：\n\n（1）拉取预安装 PaddlePaddle 的镜像：\n\n```bash\ndocker pull ccr-2vdh3abv-pub.cnc.bj.baidubce.com/paddlepaddle/paddle:3.1.0-gpu-cuda11.8-cudnn8.9\n```\n\n（2）用镜像构建并进入Docker容器：\n\n```bash\ndocker run --gpus all --shm-size=8g --network=host --name paddle -it -v $PWD:/paddle ccr-2vdh3abv-pub.cnc.bj.baidubce.com/paddlepaddle/paddle:3.1.0-gpu-cuda11.8-cudnn8.9 /bin/bash\n```\n\n或先创建一个后台容器，再进入该容器：\n\n```bash\ndocker run -id --gpus all --shm-size=8g --network=host --name paddle -v $PWD:/paddle ccr-2vdh3abv-pub.cnc.bj.baidubce.com/paddlepaddle/paddle:3.1.0-gpu-cuda11.8-cudnn8.9\n```\n\n```bash\ndocker exec -it paddle /bin/bash\n```\n\n若您在安装后发现无法安装PyYAML,可通过如下命令修复：\n\n```bash\npython -m pip install --ignore-installed PyYAML\n```\n\n安装完成后，使用以下命令可以验证 PaddlePaddle 是否安装成功：\n\n```bash\npython -c \"import paddle; print(paddle.__version__)\"\n```\n\n如果已安装成功，将输出以下内容：\n\n```\n3.1.0\n```\n\n## 2. 安装paddleocr\n\n首先，需要确保环境中安装有符合要求的 CUDA 与 cuDNN。目前 PaddleOCR 仅支持与 CUDA 11.8 + cuDNN 8.9 兼容的 CUDA 和 cuDNN版本。如果使用飞桨官方镜像，则镜像中的 CUDA 和 cuDNN 版本已经是满足要求的，无需额外安装。\n\n建议安装的 CUDA 和 cuDNN 版本与环境中存在的 Python 包版本保持一致，以避免不同版本的库共存导致的潜在问题。可以通过如下方式可以查看 CUDA 和 cuDNN 相关 Python 包的版本：\n\n```bash\n# CUDA 相关 Python 包版本\npip list | grep nvidia-cuda\n# cuDNN 相关 Python 包版本\npip list | grep nvidia-cudnn\n```\n\n如果只希望使用 PaddleOCR 的推理功能，请参考 **安装推理包**；如果还希望进行模型训练、导出等，请参考 **安装训练依赖**。在同一环境中安装推理包和训练依赖是允许的，无需进行环境隔离。\n\n### 2.1 安装推理包\n\n从 PyPI 安装最新版本 PaddleOCR 推理包：\n\n```bash\npython -m pip install paddleocr\n```\n\n或者从源码安装（默认为开发分支）：\n\n```bash\npython -m pip install \"git+https://github.com/PaddlePaddle/PaddleOCR.git\"\n```\n\n### 2.2 安装训练依赖\n\n要进行模型训练、导出等，需要首先将仓库克隆到本地：\n\n```bash\n# 推荐方式\ngit clone https://github.com/PaddlePaddle/PaddleOCR\n\n# （可选）切换到指定分支\ngit checkout release/3.0\n\n# 如果因为网络问题无法克隆成功，也可选择使用码云上的仓库：\ngit clone https://gitee.com/paddlepaddle/PaddleOCR\n\n# 注：码云托管代码可能无法实时同步本 GitHub 项目更新，存在3~5天延时，请优先使用推荐方式。\n```\n\n执行如下命令安装依赖：\n\n```bash\npython -m pip install -r requirements.txt\n```\n\n## 3. 开发集成/部署\n\n如果通用 OCR 产线可以达到您对产线推理速度和精度的要求，您可以直接进行开发集成/部署。\n\n您可以将通用 OCR 产线直接应用在您的Python项目中，此外，PaddleOCR 也提供了其他两种部署方式，详细说明如下：\n\n（1）高性能推理：在实际生产环境中，许多应用对部署策略的性能指标（尤其是响应速度）有着较严苛的标准，以确保系统的高效运行与用户体验的流畅性。为此，PaddleOCR 提供高性能推理功能，旨在对模型推理及前后处理进行深度性能优化，实现端到端流程的显著提速，详细的高性能推理流程请参考[高性能推理](https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/deployment/high_performance_inference.html)。\n\n（2）服务化部署：服务化部署是实际生产环境中常见的一种部署形式。通过将推理功能封装为服务，客户端可以通过网络请求来访问这些服务，以获取推理结果。详细的产线服务化部署流程请参考[服务化部署](https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/deployment/serving.html)。\n\n### 3.1 高性能推理\n\n在实际生产环境中，许多应用对部署策略的性能指标（尤其是响应速度）有着较严苛的标准，以确保系统的高效运行与用户体验的流畅性。PaddleOCR 提供高性能推理能力，让用户无需关注复杂的配置和底层细节，一键提升模型的推理速度。具体而言，PaddleOCR 的高性能推理功能能够：\n\n- 结合先验知识自动选择合适的推理后端（Paddle Inference、OpenVINO、ONNX Runtime、TensorRT等），并配置加速策略（如增大推理线程数、设置 FP16 精度推理）；\n- 根据需要自动将飞桨静态图模型转换为 ONNX 格式，以使用更优的推理后端实现加速。\n\n#### 3.1.1 安装Paddle2ONNX插件\n\nPaddleX 的 Paddle2ONNX 插件提供了将飞桨静态图模型转化到 ONNX 格式模型的能力，底层使用 [Paddle2ONNX](https://github.com/PaddlePaddle/Paddle2ONNX)。\n\n```bash\npaddlex --install paddle2onnx\n```\n\n#### 3.1.2 安装高性能推理依赖\n\n高性能推理插件支持处理 **飞桨静态图（`.pdmodel`、 `.json`）**、**ONNX（`.onnx`）**、**华为 OM（`.om`）** 等多种模型格式。对于 ONNX 模型，可以使用 [Paddle2ONNX 插件](https://paddlepaddle.github.io/PaddleX/3.0/pipeline_deploy/paddle2onnx.html) 转换得到。如果模型目录中存在多种格式的模型，PaddleX 会根据需要自动选择，并可能进行自动模型转换。\n\n通过 PaddleOCR CLI 安装高性能推理所需依赖：\n\n```bash\npaddleocr install_hpi_deps {设备类型}\n```\n\n支持的设备类型包括：\n\n- `cpu`：仅使用 CPU 推理。目前支持 Linux 系统、x86-64 架构处理器、Python 3.8-3.12。\n- `gpu`：使用 CPU 或 NVIDIA GPU 推理。目前支持 Linux 系统、x86-64 架构处理器、Python 3.8-3.12。如果希望使用完整的高性能推理功能，还需要确保环境中安装有符合要求的 TensorRT。\n\n同一环境中只应该存在一种设备类型的依赖。对于 Windows 系统，目前建议在 Docker 容器或者 [WSL](https://learn.microsoft.com/zh-cn/windows/wsl/install) 环境中安装。\n\n**推荐使用飞桨官方 Docker 镜像安装高性能推理依赖。** 各设备类型对应的镜像如下：\n\n- `cpu`：`ccr-2vdh3abv-pub.cnc.bj.baidubce.com/paddlepaddle/paddle:3.0.0`\n- `gpu`：\n  - **CUDA 11.8**：`ccr-2vdh3abv-pub.cnc.bj.baidubce.com/paddlepaddle/paddle:3.0.0-gpu-cuda11.8-cudnn8.9-trt8.6`\n\n应确保环境中安装有符合要求的 TensorRT，否则 Paddle Inference TensorRT 子图引擎将不可用，程序可能无法取得最佳推理性能。目前 PaddleOCR 仅支持 TensorRT 8.6.1.6，请参考 [TensorRT 文档](https://docs.nvidia.com/deeplearning/tensorrt/archives/index.html) 安装 TensorRT。示例如下：\n\n```bash\n# 下载 TensorRT tar 文件\nwget https://developer.nvidia.com/downloads/compute/machine-learning/tensorrt/secure/8.6.1/tars/TensorRT-8.6.1.6.Linux.x86_64-gnu.cuda-11.8.tar.gz\n# 解压 TensorRT tar 文件\ntar xvf TensorRT-8.6.1.6.Linux.x86_64-gnu.cuda-11.8.tar.gz\n# 安装 TensorRT wheel 包\npython -m pip install TensorRT-8.6.1.6/python/tensorrt-8.6.1-cp310-none-linux_x86_64.whl\n# 添加 TensorRT 的 `lib` 目录的绝对路径到 LD_LIBRARY_PATH 中\nvim ~/.bashrc\n# 编辑.bashrc配置文件，添加以下内容：\nexport LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/paddle/TensorRT-8.6.1.6/lib\"\n# 保存文件后，运行以下命令使配置生效：\nsource ~/.bashrc\n```\n\n#### 3.1.2 执行高性能推理\n\n对于 PaddleOCR CLI，指定 `--enable_hpi` 为 `True` 即可执行高性能推理。例如：\n\n```bash\npaddleocr ocr --enable_hpi True ...\n```\n\n对于 PaddleOCR Python API，在初始化产线对象或者模块对象时，设置 `enable_hpi` 为 `True` 即可在调用推理方法时执行高性能推理。例如：\n\n```python\nfrom paddleocr import PaddleOCR\npipeline = PaddleOCR(enable_hpi=True)\nresult = pipeline.predict(...)\n```\n\n对于 PaddleX CLI，指定`--use_hpip`开启高性能推理。例如：\n\n```bash\npaddlex --serve --pipeline OCR --use_hpip --port 8081\n```\n\n或\n\n```bash\npaddlex --serve --pipeline /paddle/PaddleOCR.yaml --use_hpip --port 8081\n```\n\n#### 3.1.3 相关说明\n\n1. 对于部分模型，在首次执行高性能推理时，可能需要花费较长时间完成推理引擎的构建。推理引擎相关信息将在第一次构建完成后被缓存在模型目录，后续可复用缓存中的内容以提升初始化速度。\n2. 目前，由于使用的不是静态图格式模型、存在不支持算子等原因，部分模型可能无法获得推理加速。\n3. 在进行高性能推理时，PaddleOCR 会自动处理模型格式的转换，并尽可能选择最优的推理后端。同时，PaddleOCR 也支持用户指定 ONNX 模型。有关如何飞桨静态图模型转换为 ONNX 格式，可参考 [获取 ONNX 模型](https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/deployment/obtaining_onnx_models.html)。\n4. PaddleOCR 的高性能推理能力依托于 PaddleX 及其高性能推理插件。通过传入自定义 PaddleX 产线配置文件，可以对推理后端等进行配置。请参考 [使用 PaddleX 产线配置文件](https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/paddleocr_and_paddlex.html#3-使用-paddlex-产线配置文件) 和 [PaddleX 高性能推理指南](https://paddlepaddle.github.io/PaddleX/3.0/pipeline_deploy/high_performance_inference.html#22) 了解如何调整高性能推理配置。\n\n### 3.2 服务化部署\n\n#### 3.2.1 安装依赖\n\n执行如下命令，通过 PaddleX CLI 安装 PaddleX 服务化部署插件：\n\n```bash\npaddlex --install serving\n```\n\n#### 3.2.2 运行服务器\n\n通过 PaddleX CLI 运行服务器：\n\n```bash\npaddlex --serve --pipeline {PaddleX 产线注册名或产线配置文件路径} [{其他命令行选项}]\n```\n\n以通用 OCR 产线为例：\n\n```bash\npaddlex --serve --pipeline OCR\n```\n\n可以看到类似以下展示的信息：\n\n```\nINFO:     Started server process [63108]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://0.0.0.0:8080 (Press CTRL+C to quit)\n```\n\n如需调整配置（如模型路径、batch size、部署设备等），可指定 `--pipeline` 为自定义配置文件。请参考 [PaddleOCR 与 PaddleX](https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/paddleocr_and_paddlex.html) 了解 PaddleOCR 产线与 PaddleX 产线注册名的对应关系，以及 PaddleX 产线配置文件的获取与修改方式。\n\n与服务化部署相关的命令行选项如下：\n\n| 名称           | 说明                                                         |\n| :------------- | :----------------------------------------------------------- |\n| `--pipeline`   | PaddleX 产线注册名或产线配置文件路径。                       |\n| `--device`     | 产线部署设备。默认情况下，当 GPU 可用时，将使用 GPU；否则使用 CPU。 |\n| `--host`       | 服务器绑定的主机名或 IP 地址。默认为 `0.0.0.0`。             |\n| `--port`       | 服务器监听的端口号。默认为 `8080`。                          |\n| `--use_hpip`   | 如果指定，则使用高性能推理。请参考高性能推理文档了解更多信息。 |\n| `--hpi_config` | 高性能推理配置。请参考高性能推理文档了解更多信息。           |\n\n#### 3.2.3 调用服务\n\nPaddleOCR 产线使用教程中的 [“开发集成/部署”](https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/pipeline_usage/OCR.html#3)部分提供了服务的 API 参考与多语言调用示例。\n\n## 4. 二次开发\n\n如果 通用OCR 产线提供的默认模型权重在您的场景中，精度或速度不满意，您可以尝试利用**您自己拥有的特定领域或应用场景的数据**对现有模型进行进一步的**微调**，以提升 通用OCR 产线的在您的场景中的识别效果。\n\n### 4.1 模型微调\n\n通用 OCR 产线包含若干模块，模型产线的效果如果不及预期，可能来自于其中任何一个模块。您可以对识别效果差的图片进行分析，进而确定是哪个模块存在问题，并参考以下表格中对应的微调教程链接进行模型微调。\n\n| 情形               | 微调模块             | 微调参考链接                                                 |\n| :----------------- | :------------------- | :----------------------------------------------------------- |\n| 整图旋转矫正不准   | 文档图像方向分类模块 | [链接](https://paddlepaddle.github.io/PaddleX/latest/module_usage/tutorials/ocr_modules/doc_img_orientation_classification.html#_5) |\n| 图像扭曲矫正不准   | 文本图像矫正模块     | 暂不支持微调                                                 |\n| 文本行旋转矫正不准 | 文本行方向分类模块   | [链接](https://paddlepaddle.github.io/PaddleX/latest/module_usage/tutorials/ocr_modules/textline_orientation_classification.html#_5) |\n| 文本漏检           | 文本检测模块         | [链接](https://paddlepaddle.github.io/PaddleOCR/main/version3.x/module_usage/text_detection.html#_5) |\n| 文本内容不准       | 文本识别模块         | [链接](https://paddlepaddle.github.io/PaddleOCR/main/version3.x/module_usage/text_recognition.html#_5) |\n\n#### 4.1.1 文本检测模型微调\n\n如果文本检测模型在您的场景上效果仍然不理想，您可以尝试以下步骤进行模型微调。\n\n首先，您需要准备文本检测的数据集，可采用[PPOCRLabel](https://paddlepaddle.github.io/PaddleX/latest/data_annotations/ocr_modules/text_detection_recognition.html)标注工具，并参考[文本检测 Demo 数据](https://paddle-model-ecology.bj.bcebos.com/paddlex/data/ocr_det_dataset_examples.tar)的格式准备，准备好后，即可按照以下步骤进行模型训练和导出，导出后，可以将模型快速集成到上述 API 中。此处以文本检测 Demo 数据为例，在训练模型之前，请确保已经按照[安装文档](https://paddlepaddle.github.io/PaddleOCR/main/version3.x/installation.html)安装了 PaddleOCR 所需要的依赖。\n\n（1）准备数据集\n\n```bash\n# 下载示例数据集\nwget https://paddle-model-ecology.bj.bcebos.com/paddlex/data/ocr_det_dataset_examples.tar\ntar -xf ocr_det_dataset_examples.tar\n```\n\n（2）下载预训练模型\n\n```bash\n# 下载 PP-OCRv5_server_det 预训练模型\nwget https://paddle-model-ecology.bj.bcebos.com/paddlex/official_pretrained_model/PP-OCRv5_server_det_pretrained.pdparams\n```\n\n（3）修改`PP-OCRv5_server_det` 配置文件，进行模型训练\n\nPaddleOCR 对代码进行了模块化，训练 `PP-OCRv5_server_det` 检测模型时需要使用 `PP-OCRv5_server_det` 的[配置文件](https://github.com/PaddlePaddle/PaddleOCR/blob/main/configs/det/PP-OCRv5/PP-OCRv5_server_det.yml)，配置文件的位置：`PaddleOCR/configs/det/PP-OCRv5/PP-OCRv5_server_det.yml`，打开`PP-OCRv5_server_det.yml`文件，修改以下内容：\n\n```yaml\nGlobal:\n  ...\n  save_model_dir: ./output/PP-OCRv5_server_det #训练后的模型权重存储路径\n  ...\n  pretrained_model: /official_pretrained_model/PP-OCRv5_server_det_pretrained.pdparams #预训练模型路径\n  ...\n...\nTrain:\n  dataset:\n    ...\n    data_dir: /paddle/ocr_det_dataset_examples/ #数据集根目录\n    label_file_list:\n      - /paddle/ocr_det_dataset_examples/train.txt #训练集标注文件\n    ...\n...\nEval:\n  dataset:\n    ...\n    data_dir: /paddle/ocr_det_dataset_examples/ #数据集根目录\n    label_file_list:\n      - /paddle/ocr_det_dataset_examples/val.txt #验证集标注文件\n    ...\n...\n```\n\n执行以下命令进行模型训练：\n\n```bash\n#单卡训练\npython PaddleOCR/tools/train.py -c PaddleOCR/configs/det/PP-OCRv5/PP-OCRv5_server_det.yml\n\n#多卡训练，通过--gpus参数指定卡号\npython -m paddle.distributed.launch --gpus '0,1,2,3' PaddleOCR/tools/train.py -c PaddleOCR/configs/det/PP-OCRv5/PP-OCRv5_server_det.yml\n```\n\n模型训练完成后，训练好的模型权重会保存在`./output/PP-OCRv5_server_det`目录下。\n\n（4）模型评估\n\n打开`PP-OCRv5_server_det.yml`文件，将`pretrained_model`的路径设置为本地路径。若使用自行训练保存的模型，请注意修改路径和文件名为`{path/to/weights}/{model_name}`。\n\n```yaml\nGlobal:\n  ...\n  pretrained_model: ./output/PP-OCRv5_server_det/best_accuracy.pdparams #训练好的模型路径\n  ...\n...\n```\n\n执行以下命令进行模型评估：\n\n```bash\npython PaddleOCR/tools/eval.py -c PaddleOCR/configs/det/PP-OCRv5/PP-OCRv5_server_det.yml\n```\n\n（5）模型导出\n\n打开`PP-OCRv5_server_det.yml`文件，修改以下内容：\n\n```yaml\nGlobal:\n  ...\n  save_inference_dir: ./PP-OCRv5_server_det_infer/ #模型导出的存储目录\n  ...\n...\n```\n\n执行以下命令导出模型：\n\n```bash\npython PaddleOCR/tools/export_model.py -c PaddleOCR/configs/det/PP-OCRv5/PP-OCRv5_server_det.yml\n```\n\n导出模型后，静态图模型会存放于当前目录的`./PP-OCRv5_server_det_infer/`中，在该目录下，您将看到如下文件：\n\n```bash\n./PP-OCRv5_server_det_infer/\n├── inference.json\n├── inference.pdiparams\n├── inference.yml\n```\n\n至此，文本检测模型微调完成，该静态图模型可以直接集成到 PaddleOCR 的 API 中。\n\n#### 4.1.2 文本识别模型微调\n\n如果文本识别模型在您的场景上效果仍然不理想，您可以尝试以下步骤进行模型微调。\n\n首先，您需要准备文本识别的数据集，可采用[PPOCRLabel](https://paddlepaddle.github.io/PaddleX/latest/data_annotations/ocr_modules/text_detection_recognition.html)标注工具，并参考[文本识别 Demo 数据](https://paddle-model-ecology.bj.bcebos.com/paddlex/data/ocr_rec_dataset_examples.tar)的格式准备，准备好后，即可按照以下步骤进行模型训练和导出，导出后，可以将模型快速集成到上述 API 中。此处以文本识别 Demo 数据为例，在训练模型之前，请确保已经按照[安装文档](https://paddlepaddle.github.io/PaddleOCR/main/version3.x/installation.html)安装了 PaddleOCR 所需要的依赖。\n\n（1）准备数据集\n\n```bash\n# 下载示例数据集\nwget https://paddle-model-ecology.bj.bcebos.com/paddlex/data/ocr_rec_dataset_examples.tar\ntar -xf ocr_rec_dataset_examples.tar\n```\n\n（2）下载预训练模型\n\n```bash\n# 下载 PP-OCRv5_server_rec 预训练模型\nwget https://paddle-model-ecology.bj.bcebos.com/paddlex/official_pretrained_model/PP-OCRv5_server_rec_pretrained.pdparams\n```\n\n（3）修改`PP-OCRv5_server_rec` 配置文件，进行模型训练\n\nPaddleOCR 对代码进行了模块化，训练 `PP-OCRv5_server_rec` 识别模型时需要使用 `PP-OCRv5_server_rec` 的[配置文件](https://github.com/PaddlePaddle/PaddleOCR/blob/main/configs/rec/PP-OCRv5/PP-OCRv5_server_rec.yml)，配置文件的位置：`PaddleOCR/configs/rec/PP-OCRv5/PP-OCRv5_server_rec.yml`，打开`PP-OCRv5_server_rec.yml`文件，修改以下内容：\n\n```yaml\nGlobal:\n  ...\n  save_model_dir: ./output/PP-OCRv5_server_rec #训练后的模型权重存储路径\n  ...\n  pretrained_model: /official_pretrained_model/PP-OCRv5_server_rec_pretrained.pdparams #预训练模型路径\n  ...\n...\nTrain:\n  dataset:\n    ...\n    data_dir: /paddle/ocr_rec_dataset_examples/ #数据集根目录\n    label_file_list:\n      - /paddle/ocr_rec_dataset_examples/train.txt #训练集标注文件\n    ...\n...\nEval:\n  dataset:\n    ...\n    data_dir: /paddle/ocr_rec_dataset_examples/ #数据集根目录\n    label_file_list:\n      - /paddle/ocr_rec_dataset_examples/val.txt #验证集标注文件\n    ...\n...\n```\n\n执行以下命令进行模型训练：\n\n```bash\n#单卡训练\npython PaddleOCR/tools/train.py -c PaddleOCR/configs/rec/PP-OCRv5/PP-OCRv5_server_rec.yml\n\n#多卡训练，通过--gpus参数指定卡号\npython -m paddle.distributed.launch --gpus '0,1,2,3' PaddleOCR/tools/train.py -c PaddleOCR/configs/rec/PP-OCRv5/PP-OCRv5_server_rec.yml\n```\n\n模型训练完成后，训练好的模型权重会保存在`./output/PP-OCRv5_server_rec`目录下。\n\n（4）模型评估\n\n打开`PP-OCRv5_server_rec.yml`文件，将`pretrained_model`的路径设置为本地路径。若使用自行训练保存的模型，请注意修改路径和文件名为`{path/to/weights}/{model_name}`。\n\n```yaml\nGlobal:\n  ...\n  pretrained_model: ./output/PP-OCRv5_server_rec/best_accuracy.pdparams #训练好的模型路径\n  ...\n...\n```\n\n执行以下命令进行模型评估：\n\n```bash\npython PaddleOCR/tools/eval.py -c PaddleOCR/configs/rec/PP-OCRv5/PP-OCRv5_server_rec.yml\n```\n\n（5）模型导出\n\n打开`PP-OCRv5_server_rec.yml`文件，修改以下内容：\n\n```yaml\nGlobal:\n  ...\n  save_inference_dir: ./PP-OCRv5_server_rec_infer/ #模型导出的存储目录\n  ...\n...\n```\n\n执行以下命令导出模型：\n\n```bash\npython PaddleOCR/tools/export_model.py -c PaddleOCR/configs/rec/PP-OCRv5/PP-OCRv5_server_rec.yml\n```\n\n导出模型后，静态图模型会存放于当前目录的`./PP-OCRv5_server_rec_infer/`中，在该目录下，您将看到如下文件：\n\n```bash\n./PP-OCRv5_server_rec_infer/\n├── inference.json\n├── inference.pdiparams\n├── inference.yml\n```\n\n至此，文本识别模型微调完成，该静态图模型可以直接集成到 PaddleOCR 的 API 中。\n\n### 4.2 模型应用\n\n当您使用私有数据集完成微调训练后，可获得本地模型权重文件，然后可以通过参数指定本地模型保存路径的方式，或者通过自定义产线配置文件的方式，使用微调后的模型权重。\n\n#### 4.2.1 通过参数指定本地模型路径\n\n在初始化产线对象时，通过参数指定本地模型路径。以文本检测模型微调后的权重的使用方法为例，示例如下：\n\n命令行方式:\n\n```bash\n# 通过 --text_detection_model_dir 指定本地模型路径\npaddleocr ocr -i ./general_ocr_002.png --text_detection_model_dir your_det_model_path\n\n# 默认使用 PP-OCRv5_server_det 模型作为默认文本检测模型，如果微调的不是该模型，通过 --text_detection_model_name 修改模型名称\npaddleocr ocr -i ./general_ocr_002.png --text_detection_model_name PP-OCRv5_mobile_det --text_detection_model_dir your_v5_mobile_det_model_path\n```\n\n脚本方式：\n\n```python\nfrom paddleocr import PaddleOCR\n\n# 通过 text_detection_model_dir 指定本地模型路径\npipeline = PaddleOCR(text_detection_model_dir=\"./your_det_model_path\")\n\n# 默认使用 PP-OCRv5_server_det 模型作为默认文本检测模型，如果微调的不是该模型，通过 text_detection_model_name 修改模型名称\n# pipeline = PaddleOCR(text_detection_model_name=\"PP-OCRv5_mobile_det\", text_detection_model_dir=\"./your_v5_mobile_det_model_path\")\n```\n\n#### 4.2.2 通过配置文件指定本地模型路径\n\n1.获取产线配置文件\n\n可调用 PaddleOCR 中 通用 OCR 产线对象的 `export_paddlex_config_to_yaml` 方法，将当前产线配置导出为 YAML 文件：\n\n```python\nfrom paddleocr import PaddleOCR\n\npipeline = PaddleOCR()\npipeline.export_paddlex_config_to_yaml(\"PaddleOCR.yaml\")\n```\n\n2.修改配置文件\n\n在得到默认的产线配置文件后，将微调后模型权重的本地路径替换至产线配置文件中的对应位置即可。例如\n\n```yaml\n......\nSubModules:\n  TextDetection:\n    box_thresh: 0.6\n    limit_side_len: 64\n    limit_type: min\n    max_side_limit: 4000\n    model_dir: null # 替换为微调后的文本测模型权重路径\n    model_name: PP-OCRv5_server_det # 如果微调的模型名称与默认模型名称不同，请一并修改此处\n    module_name: text_detection\n    thresh: 0.3\n    unclip_ratio: 1.5\n  TextLineOrientation:\n    batch_size: 6\n    model_dir: null  # 替换为微调后的文本行方向分类模型权重路径\n    model_name: PP-LCNet_x1_0_textline_ori # 如果微调的模型名称与默认模型名称不同，请一并修改此处\n    module_name: textline_orientation\n  TextRecognition:\n    batch_size: 6\n    model_dir: null # 替换为微调后的文本识模型权重路径\n    model_name: PP-OCRv5_server_rec # 如果微调的模型名称与默认模型名称不同，请一并修改此处\n    module_name: text_recognition\n    score_thresh: 0.0\n......\n```\n\n在产线配置文件中，不仅包含 PaddleOCR CLI 和 Python API 支持的参数，还可进行更多高级配置，具体信息可在 [PaddleX模型产线使用概览](https://paddlepaddle.github.io/PaddleX/3.0/pipeline_usage/pipeline_develop_guide.html) 中找到对应的产线使用教程，参考其中的详细说明，根据需求调整各项配置。\n\n3.在 CLI 中加载产线配置文件\n\n在修改完成配置文件后，通过命令行的 `--paddlex_config` 参数指定修改后的产线配置文件的路径，PaddleOCR 会读取其中的内容作为产线配置。示例如下：\n\n```bash\npaddleocr ocr --paddlex_config PaddleOCR.yaml ...\n```\n\n4.在 Python API 中加载产线配置文件\n\n初始化产线对象时，可通过 `paddlex_config` 参数传入 PaddleX 产线配置文件路径或配置dict，PaddleOCR 会读取其中的内容作为产线配置。示例如下：\n\n```python\nfrom paddleocr import PaddleOCR\n\npipeline = PaddleOCR(paddlex_config=\"PaddleOCR.yaml\")\n```\n\n","tags":["PaddleOCR"],"categories":["人工智能"]},{"title":"通过IPMI 和 iDRAC 控制Dell服务器风扇转速","url":"/2025/01/13/ipmi-idrac/","content":"\n## Dell iDRAC介绍\n\niDRAC全称是 Integrated Dell Remote Access Controller，也就是集成戴尔远程控制卡，这是戴尔服务器的独有功能，iDRAC卡相当于是附加在服务器上的一计算机，可以实现一对一的服务器远程管理与监控，通过与服务器主板上的管理芯片BMC进行通信，监控与管理服务器的硬件状态信息。它拥有自己的系统和IP地址，与服务器上的OS无关，管理员通过iDRAC可以很方便的对服务器进行远程访问和管理。\n\n## 启用iDRAC功能\n\n### 进入BIOS\n\n1、启动Dell服务器，按F2，进入BIOS界面，选择`iDRAC Settings`。\n\n![](1.png)\n\n2、在IDRAC Settings界面中选择`Network`。\n\n![](2.png)\n\n3、在Network界面中，设置 `Enable NIC` 为 Enabled，设置 `NIC Selection` 为 Dedicated (专用网口) 或者LOM1~LOM4 (共享服务器1-4号网口) 。IDRAC Enterprise 版本推荐使用 `Dedicated` 的方式进行连接。\n\n![](3.png)\n\n4、在Network界面，下拉右侧的滚动条，找到`IPV4 SETTINGS`选项，启用IPV4并设置IP地址、网关和子网掩码。iDRAC管理口的默认IP地址为192.168.0.120，默认网关是192.168.0.1，默认子网掩码是255.255.255.0。\n\n这里我为了方便，将其设置成了局域网的IP地址：192.168.110.120，网关是192.168.110.1，子网掩码是255.255.255.0。这样我后面只需将网线插到服务器的 iDRAC 网口上，就可以通过局域网直接访问 iDRAC 管理平台了。\n\n![](4.png)\n\n### 访问iDRAC管理平台\n\n将局域网的网线插入到服务器的 iDRAC 网口上，那个是NIC专用网口。\n\n![](5.png)\n\n由于之前已经将 iDRAC的IP设置成了局域网IP，所以我们现在直接通过局域网就可以访问它了。打开电脑浏览器，输入192.168.110.120，即可访问 iDRAC 管理平台，默认账户：root，默认密码：calvin\n\n![](6.jpg)\n\n登录管理平台后，可自行修改账户密码。在管理平台上，我们可以查看服务器各项硬件指标，包括电池、风扇、CPU、内容等，同时也可以设置 iDRAC 网络、用户、会话等信息。\n\n![](7.jpg)\n\n## 打开系统控制权限\n\n1、登录iDRAC管理平台后，找到`iDRAC设置`中的`网络`选项，设置IPMI，启用LAN上的IPMI。\n\n![](8.jpg)\n\n2、在`网络`选项中，找到 `服务` 设置项，启用SNMP代理。\n\n![](9.jpg)\n\n## 设置风扇转速\n\n### 下载ipmitool工具包\n\nipmitool 是一个用于管理和配置支持智能平台管理接口（IPMI）设备的实用工具。IPMI是一种开放标准，用于监控、日志记录、恢复、库存和控制硬件，这些功能独立于主CPU、BIOS和操作系统实现。服务处理器（或基板管理控制器，BMC）是平台管理的核心，其主要目的是处理自主传感器监控和事件日志记录功能。\n\n`ipmitool`百度网盘下载地址：https://pan.baidu.com/s/1eqRW66f2-n4V5QQI4QC_Sw?pwd=s4q1 \n\n解压并安装ipmitool工具，然后将ipmitool所在路径添加到系统环境变量中。\n\n![](10.jpg)\n\n### 设置风扇转速\n\n打开`cmd`控制台，输入以下命令设置风扇转速：\n\n首先要关闭风扇自动调速功能，否则我们手动设置的转速是不会生效的。\n\n```bash\nipmitool -I lanplus -H 192.168.110.120 -U root -P calvin raw 0x30 0x30 0x01 0x00\n```\n\n- 最后的数值用来设置是否启用风扇的自动调速功能，`0x00`表示关闭自动调速，`0x01`表示开启自动调速。\n\n关闭自动调速之后，我们就可以按照自己的意愿调整转速了，比如设置为15%。\n\n```\nipmitool -I lanplus -H 192.168.110.120 -U root -P calvin raw 0x30 0x30 0x02 0xff 0x0f\n```\n\n- 最后的数值用来设置风扇转速(转速百分比的十六进制)，0x0a表示10%，0x0f表示15%，0x14表示20%，0x1e表示30%。\n\n在以上命令中：\n\n- `-I lanplus` 指定使用LANPlus作为通信接口‌。\n- `-H <服务器IP地址>` 设置目标IP地址，即你想要与之通信的IPMI设备的地址‌。\n- `-U <用户名>` 和 `-P <密码>` 分别用于身份验证，即目标IPMI设备上的用户名和密码‌。\n- `raw 0x30 0x30 0x01 0x00` 和 `raw 0x30 0x30 0x01 0x01` 是发送的原始IPMI命令，用于控制风扇的自动调速功能‌。\n- `raw 0x30 0x30 0x02 0xff <转速百分比(十六进制)>` 是设置风扇转速，其中，`0x30`是网络功能代码和命令代码，表示传感器和数据仓库以及特定传感器控制命令；`0x02`是子功能代码，表示设置风扇转速；`0xff`是命令子功能；`<转速百分比（十六进制）>`是你想要设置的风扇转速百分比，转换为十六进制值。‌\n\n风扇转速设置完成后，可通过iDRAC管理平台的`风扇`选项卡，确认配置是否生效。\n\n![](11.jpg)\n\n\n\n","tags":["centos","IPMI","iDRAC"],"categories":["linux系统"]},{"title":"Oracle VirtualBox虚拟机使用说明","url":"/2024/12/19/vbox/","content":"\n## 安装vbox\n\n```bash\nyum install virtualbox -y\n```\n\n## 导入OVA文件 \n\n```bash\nVBoxManage import mywin206.ova\n```\n\n## 启动虚拟机\n\n```bash\n# 以无头（headless）模式启动名为\"mywin206\"的VirtualBox虚拟机。虚拟机将在没有图形界面的情况下运行，通常用于后台任务或服务器场景。\nVBoxManage startvm \"mywin206\" --type headless\n```\n\n## 关闭虚拟机\n\n```bash\n# 向指定的虚拟机\"mywin206\"发送一个ACPI关机信号，模拟用户按下物理机的电源按钮，正常关闭虚拟机。\nVBoxManage controlvm \"mywin206\" acpipowerbutton\n```\n\n```bash\n# 强制关闭虚拟机\nVBoxManage controlvm \"mywin206\" poweroff\n```\n\n## 删除虚拟机\n\n```bash\n# 删除名为\"mywin206\"的VirtualBox虚拟机，包括其配置文件和虚拟硬盘，此操作不可逆，需谨慎使用。\nVBoxManage unregistervm \"mywin206\" --delete\n```\n\n## 设置虚拟机CPU和内存\n\n- 在修改虚拟机的CPU核心数和内存大小之前，建议关闭虚拟机以防止数据丢失或配置冲突。\n\n- 修改后的配置在虚拟机下次启动时生效。\n- 确保你的主机系统有足够的资源（如CPU核心和物理内存）来支持虚拟机的新配置。\n\n```bash\n# 将名为\"mywin206\"的虚拟机的CPU核心数设置为4\nVBoxManage modifyvm \"mywin206\" --cpus 4\n```\n\n```bash\n# 将把名为\"mywin206\"的虚拟机的内存大小设置为8192MB（即8GB）\nVBoxManage modifyvm \"mywin206\" --memory 8192\n```\n\n## 设置虚拟机端口转发规则\n\n```bash\n# 设置远程桌面访问的端口转发规则\nVBoxManage modifyvm \"mywin206\" --natpf1 \"rdp3389,tcp,,54489,,3389\"\n```\n\n```bash\n# 设置某后台服务的端口转发规则\nVBoxManage modifyvm \"mywin206\" --natpf1 \"web8080,tcp,,58080,,8080\"\n```\n\n```bash\n# 查看虚拟机已设置的所有规则\nVBoxManage showvminfo \"mywin206\" | grep \"Rule\"\n```\n\n```bash\n# 删除虚拟机已设置的某个规则\nVBoxManage modifyvm \"mywin206\" --natpf1 delete \"rdp3389\"\n```\n\n## 列出vbox中的虚拟机\n\n```bash\n# 列出vbox中的虚拟机\nVBoxManage list vms\n```\n\n```bash\n# 列出vbox中正在运行的虚拟机\nVBoxManage list runningvms\n```\n\n","tags":["虚拟机","vbox"],"categories":["linux系统"]},{"title":"CentOS系统磁盘空间再分配","url":"/2024/11/07/disk-alloc/","content":"\n由于在安装centos系统的时候，如果在安装时没有分配磁盘空间，选择的是默认分配的，在安装完成后，可以发现大容量磁盘往往分配在了home下面。\n\n如果要把home下面的磁盘空间分配到root磁盘下面，需要进行如下操作。\n\n### 查看CentOS的系统版本\n\n```bash\ncat /etc/redhat-release\n```\n\n![](1.png)\n\n### 查看分区\n\n```bash\ndf -h\n```\n\n可以看到`centos-home` 和 `centos-root`的磁盘使用情况。\n\n![](2.jpg)\n\n### 备份 /home 分区文件\n\n````bash\ntar zcvf /tmp/home.tar /home\n````\n\n**这一步很重要，一定要记得备份数据。**\n\n![](3.jpg)\n\n### 卸载 /home\n\n```bash\numount /home\n```\n\n![](4.jpg)\n\n**如果无法卸载，需要先使用 `fuser` 命令终止使用/home文件系统的进程**\n\n```bash\nfuser -km /home/\n```\n\n![](5.jpg)\n\n再次卸载，没有报错，表示卸载成功。\n\n![](6.jpg)\n\n### 删除 /home 所在的 lv\n\n```bash\nlvremove /dev/mapper/centos-home\n```\n\n![](7.jpg)\n\n### 扩展 /root 所在的 lv\n\n```bash\nlvextend -L +100G /dev/mapper/centos-root\n```\n\n![](8.jpg)\n\n### 扩展 /root 文件系统\n\n```bash\nxfs_growfs /dev/mapper/centos-root\n```\n\n![](9.jpg)\n\n### 重新创建 /home 的 lv\n\n**创建时计算好剩余的磁盘容量，建议比剩余小1G左右。**\n\n```bash\nlvcreate -L 41G -n /dev/mapper/centos-home \n```\n\n![](10.jpg)\n\n### 创建 /home 文件系统\n\n```bash\nmkfs.xfs /dev/mapper/centos-home\n```\n\n![](11.jpg)\n\n### 挂载 /home\n\n```bash\nmount /dev/mapper/centos-home\n```\n\n![](12.jpg)\n\n### 恢复 /home 分区文件\n\n```bash\ntar xvf /tmp/home.tar -C /home/\n```\n\n![](13.jpg)\n\n### 再次查看系统磁盘大小\n\n```bash\ndf -h\n```\n\n![](14.jpg)\n\n可以看到`home`下面100G的磁盘容量已经转移到`root`下面了，至此，转移任务结束。\n\n此为在`CentOS7.2`系统下测试使用的，在`CentOS6`版本下还没测试过。\n","tags":["centos","磁盘分配"],"categories":["linux系统"]},{"title":"facefusion容器化部署","url":"/2024/10/22/facefusion/","content":"\n## 以非持久化存储方式部署\n\n### 1、拉取facefusion3.0.0镜像\n\n```\ndocker pull registry.cn-beijing.aliyuncs.com/codewithgpu2/facefusion-facefusion:zNAvwLjrMp\n```\n\n### 2、创建facefusion容器，设置启动GPU，设置端口号、以及共享内存大小\n\n```\ndocker run -id --name=ff --gpus all -p 6006:6006 --shm-size 7g registry.cn-beijing.aliyuncs.com/codewithgpu2/facefusion-facefusion:zNAvwLjrMp\n```\n\n### 3、进入容器\n\n```\ndocker exec -it ff /bin/bash\n```\n\n### 4、修改facefusion服务ip和端口号\n\n```\nvi /root/facefusion/facefusion/uis/layouts/default.py\n```\n\n修改内容如下：\n\n```\ndef run(ui : gradio.Blocks) -> None:\n    ui.launch(favicon_path = 'facefusion.ico', inbrowser = state_manager.get_item('open_browser'), server_name='0.0.0.0', server_port=6006)\n```\n\n### 5、启动facefusion服务\n\n```\nsource activate facefusion && cd /root/facefusion && python facefusion.py run -o /root/outputs --execution-providers cuda cpu --skip-download\n```\n\n---\n\n## 以持久化存储方式部署\n\n### 1、拉取facefusion3.0.0镜像\n\n```\ndocker pull registry.cn-beijing.aliyuncs.com/codewithgpu2/facefusion-facefusion:zNAvwLjrMp\n```\n\n### 2、以volume挂载的方式创建容器\n\n```\ndocker run -id --name=ff --gpus all -p 6006:6006 --shm-size 7g -v /home/panzhe/ff_docker_v/default.py:/root/facefusion/facefusion/uis/layouts/default.py -v /home/panzhe/ff_docker_v/run.sh:/root/run.sh -v /home/panzhe/ff_docker_v/outputs:/root/outputs registry.cn-beijing.aliyuncs.com/codewithgpu2/facefusion-facefusion:zNAvwLjrMp\n```\n\n### 3、进入容器\n\n```\ndocker exec -it ff /bin/bash\n```\n\n### 4、启动facefusion服务\n\n```\nsource activate facefusion && cd /root/facefusion && python facefusion.py run -o /root/outputs --execution-providers cuda cpu --skip-download\n```\n\n# 查看GPU使用情况\n\n```\nwatch -n 1 nvidia-smi\n```\n\n-n 1代表每隔1秒刷新一次，ctrl+c退出。\n","tags":["视频换脸"],"categories":["人工智能"]},{"title":"GPT-SoVITS容器化部署","url":"/2024/10/22/sovits/","content":"\n## 1、从codewithgpu拉取sovits镜像\n\n```\ndocker pull registry.cn-beijing.aliyuncs.com/codewithgpu2/rvc-boss-gpt-sovits:gpM1WfbTsA\n```\n\n## 2、安装nvidia-container-toolkit，让docker容器可以使用GPU资源\n\n#### ubuntu系统安装方法\n\n（1）配置仓库\n\n```\ncurl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\\n  && curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\\n    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\\n    sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\n```\n\n（2）更新软件源\n\n```\nsudo apt-get update\n```\n\n（3）安装 NVIDIA 容器工具包\n\n``` \nsudo apt-get install -y nvidia-container-toolkit\n```\n\n（4）重启docker\n\n```\nsudo systemctl restart docker\n```\n\n#### centos系统安装方法\n\n（1）配置仓库\n\n```\ndistribution=$(. /etc/os-release;echo $ID$VERSION_ID)\ncurl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | sudo tee /etc/yum.repos.d/nvidia-docker.repo\n```\n\n（2）安装 NVIDIA 容器工具包\n\n```\nsudo yum install -y nvidia-container-toolkit\n```\n\n（3）重启docker\n\n```\nsudo systemctl restart docker\n```\n\n## 3、创建sovits容器，设置启动GPU，设置端口号、以及共享内存大小\n\n### 以非持久化存储方式创建\n\n```\ndocker run -id --name=sovits --gpus all -p 9874:9874 -p 9873:9873 -p 9872:9872 -p 9871:9871 --shm-size 7g registry.cn-beijing.aliyuncs.com/codewithgpu2/rvc-boss-gpt-sovits:gpM1WfbTsA\n```\n\n### 以持久化存储方式创建（volume挂载）\n\n```\ndocker run -id --name=sovits --gpus all -p 9874:9874 -p 9873:9873 -p 9872:9872 -p 9871:9871 --shm-size 7g -v /home/panzhe/sovits_docker_v/logs:/root/GPT-SoVITS/logs -v /home/panzhe/sovits_docker_v/audio_data:/root/GPT-SoVITS/audio_data -v /home/panzhe/sovits_docker_v/output:/root/GPT-SoVITS/output -v /home/panzhe/sovits_docker_v/GPT_weights_v2:/root/GPT-SoVITS/GPT_weights_v2 -v /home/panzhe/sovits_docker_v/SoVITS_weights_v2:/root/GPT-SoVITS/SoVITS_weights_v2 registry.cn-beijing.aliyuncs.com/codewithgpu2/rvc-boss-gpt-sovits:gpM1WfbTsA\n```\n\n## 4、启动gpt-sovits服务\n\n```\necho {}> ~/GPT-SoVITS/i18n/locale/en_US.json && source activate GPTSoVits && cd ~/GPT-SoVITS/ && python webui.py zh_C\n```\n\n# 查看GPU使用情况\n\n```\nwatch -n 1 nvidia-smi\n```\n\n-n 1代表每隔1秒刷新一次，ctrl+c退出。\n\n# FAQ\n\n1、执行`docker run`创建sovits容器时，报错：`docker:Error response from daemon: could not select device driver \"\" with capabilities: [[gpu]].`\n\n原因：未安装`nvidia-container-toolkit`。\n\n","tags":["声音克隆"],"categories":["人工智能"]},{"title":"如何快速将python程序打包成exe","url":"/2024/08/29/python-to-exe/","content":"\n### 创建一个纯净的python环境\n从开始菜单运行“Anaconda Prompt”，出现的界面输入创建虚拟环境的指令。\n```shell\n# 创建虚拟环境\nconda create -n py310 python==3.10\n# 激活虚拟环境\nconda activate py310\n```\n如果后面想退出当前虚拟环境，输入命令`conda deactivate`即可，同时也可以使用命令`conda info --envs`，查看conda环境下所有的虚拟环境。\n### 准备python程序相关依赖模块\n1、检查并确保python程序相关的依赖模块已经安装完成，如缺少相关依赖包，可使用命令`pip install`进行安装。\n2、安装pyinstaller，输入命令：`pip install pyinstaller`。\n### 打包成exe\npyinstaller命令有很多的参数可以选择，下面是一些比较常用的参数，供参考。\n\n| 参数                    | 说明                                                         |\n| ----------------------- | ------------------------------------------------------------ |\n| -F, –onefile            | 产生一个文件用于部署.                                        |\n| -D, –onedir             | 产生一个目录用于部署 (默认)                                  |\n| -K, –tk                 | 在部署时包含 TCL/TK                                          |\n| -a, –ascii              | 不包含编码.在支持Unicode的python版本上默认包含所有的编码.    |\n| -d, –debug              | 产生debug版本的可执行文件                                    |\n| -w,–windowed,–noconsole | 使用Windows子系统执行.当程序启动的时候不会打开命令行(只对Windows有效) |\n| -c,–nowindowed,–console | 使用控制台子系统执行(默认)(只对Windows有效)                  |\n| -s,–strip               | 可执行文件和共享库将run through strip.注意Cygwin的strip往往使普通的win32 Dll无法使用. |\n| -X, –upx                | 如果有UPX安装(执行Configure.py时检测),会压缩执行文件(Windows系统中的DLL也会)(参见note) |\n| -o DIR, –out=DIR        | 指定spec文件的生成目录,如果没有指定,而且当前目录是PyInstaller的根目录,会自动创建一个用于输出(spec和生成的可执行文件)的目录.如果没有指定,而当前目录不是PyInstaller的根目录,则会输出到当前的目录下. |\n| -p DIR, –path=DIR       | 设置导入路径(和使用PYTHONPATH效果相似).可以用路径分割符(Windows使用分号,Linux使用冒号)分割,指定多个目录.也可以使用多个-p参数来设置多个导入路径 |\n| –icon=<FILE.ICO>        | 将file.ico添加为可执行文件的资源(只对Windows系统有效)        |\n| –icon=<FILE.EXE,N>      | 将file.exe的第n个图标添加为可执行文件的资源(只对Windows系统有效) |\n| -v FILE, –version=FILE  | 将verfile作为可执行文件的版本资源(只对Windows系统有效)       |\n| -n NAME, –name=NAME     | 可选的项目(产生的spec的)名字.如果省略,第一个脚本的主文件名将作为spec的名字 |\n\n```shell\n# 最简单的命令\npyinstaller demo.py\n\n# 制作独立的可执行程序\npyinstaller -F demo.py\n\n# 独立可执行程序且不带控制台\npyinstaller -F -w demo.py\n\n# 独立可执行程序、不带控制台、指定exe图标\npyinstaller -F -w -i demo.ico demo.py\n```\n打包完成后，会在当前目录下生成两个文件夹，分别是dist和build，进入dist文件夹，可以看到已经打包好的exe文件。\n\n### 打包多个py文件\n如果需要打包多个python文件，如：demo.py是主程序，它调用了其它py文件中一些函数，那么在打包时需要生成demo.py对应的spec文件。\n```shell\n# 生成spec文件\npyi-makespec demo.py\n```\n修改spec文件内容，添加其它py文件名称，并在**pathex** 和 **hiddenimports**处，添加这些py文件所在目录的绝对路径，如果用到了额外资源，如：图片，视频，音频等，还需要在 **datas** 处添加这些额外资源的绝对路径。示例如下：\n```shell\na = Analysis(\n    ['cv_tools.py', 'facelandmarks.py', 'facelandmarks_videos.py'],\n    pathex=['C:\\\\Users\\\\Admin\\\\Desktop\\\\demo'],\n    binaries=[],\n    datas=[('C:\\\\anaconda3\\\\envs\\\\python310\\\\Lib\\\\site-packages\\\\mediapipe\\\\modules', 'mediapipe/modules')],\n    hiddenimports=['C:\\\\Users\\\\Admin\\\\Desktop\\\\demo'],\n    hookspath=[],\n    hooksconfig={},\n    runtime_hooks=[],\n    excludes=[],\n    noarchive=False,\n)\n```\n然后再使用pyinstall打包spec文件，就会在dist文件夹下生成exe文件。\n```shell\npyinstall demo.spec\n```\n\n参考链接：\nhttps://zhuanlan.zhihu.com/p/406790850\nhttps://blog.csdn.net/m0_38056893/article/details/106843806\nhttps://blog.csdn.net/xujianjun229/article/details/120049583","tags":["python","exe"],"categories":["python"]},{"title":"Elasticsearch环境离线安装","url":"/2024/08/29/es-offline/","content":"\n### Elasticsearch安装\n1、下载Elasticsearch离线安装包\n官网下载地址：https://www.elastic.co/cn/downloads/past-releases\n2、通过 SFTP工具将 elasticsearch-7.17.7-linux-x86_64.tar.gz 上传到服务器上\n3、解压安装包\n\n   ```shell\ntar -xzf elasticsearch-7.17.7-linux-x86_64.tar.gz\n   ```\n4、将elasticsearch相关文件拷贝到 /usr/elasticsearch\n\n   ```shell\nsudo mkdir /usr/elasticsearch\nsudo cp -r elasticsearch-7.17.7/* /usr/elasticsearch\n   ```\n\n5、配置elasticsearch\n\n- 修改 elasticsearch.yml\n\n```shell\nsudo vi /usr/elasticsearch/config/elasticsearch.yml\n```\n\n- 修改以下配置\n\n```yaml\ncluster.name: \"idata\"\nnetwork.host: 0.0.0.0\nxpack.security.enabled: true\ndiscovery.type: single-node\n````\n\n- 修改jvm.options\n\n```shell\nsudo vi /usr/elasticsearch/config/jvm.options\n```\n\n一般不超过机器内存的50%，Xms 和 Xmx 相同\n\n```shell\n-Xms4g\n-Xmx4g\n```\n\n6、添加elasticsearch用户\n\n   ```shell\nuseradd elasticsearch\npasswd elasticsearch\nchown -R elasticsearch /usr/elasticsearch\n   ```\n\n7、修改 systcl.conf\n\n   ```shell\nsudo vi /etc/sysctl.conf\n   ```\n\n在文件末尾添加,然后执行 sysctl -p \n\n   ```shell\nvm.max_map_count=655360\n   ```\n\n8、修改 limits.conf\n\n   ```shell\nsudo vi /etc/security/limits.conf\n   ```\n\n   在文件末尾添加\n\n   ```shell\n*   soft   nofile  65536\n*   hard   nofile  65536\n*   soft   nproc   4096\n*   hard   nproc   4096\n   ```\n\n9、启动elasticsearch\n切换到elasticsearch用户，执行启动命令。\n\n   ```shell\nsu elasticsearch\ncd /usr/elasticsearch\n./bin/elasticsearch -d -p pid\n   ```\n\n10、创建密码\n\n   ```shell\ncd /usr/elasticsearch\n./bin/elasticsearch-setup-passwords interactive\n   ```\n\n*注：请务必记住输入的密码。*   \n\n重启 elasticsearch\n\n   ```shell\ncd /usr/elasticsearch\npkill -F pid\n./bin/elasticsearch -d -p pid\n   ```\n\n11、检查\n访问 ip:9200, 确认是否安装成功。\n\n### Kibana 安装\n\n1、通过 SFTP工具将 kibana-7.17.7-linux-x86_64.tar.gz 上传到服务器上\n\n2、解压安装包\n\n   ```shell\ntar -xzf kibana-7.17.7-linux-x86_64.tar.gz\n   ```\n\n3、将kibana相关文件拷贝到 /usr/kibana\n\n   ```shell\nsudo mkdir /usr/kibana\nsudo cp kibana-7.17.7/* /usr/kibana\nchown -R elasticsearch /usr/kibana\n   ```\n\n4、配置kibana\n\n- 修改 kibana.yml\n\n```shell\nsudo vi /usr/kibana/config/kibana.yml\n```\n\n- 修改访问IP，端口，以及elasticsearch的地址\n\n```yaml\nserver.port: 5601\nserver.host: \"0.0.0.0\"\nelasticsearch.hosts: [\"http://ip:9200\"]\nelasticsearch.username: \"kibana_system\"\n```\n\n5、启动kibana\n切换到elasticsearch用户, 执行启动命令\n\n   ```shell\nsu elasticsearch\n/usr/kibana/bin/kibana -d -p pid\n   ```\n\n6、创建密码\n\n   ```shell\ncd /usr/kibana\n./bin/kibana-keystore create\n./bin/kibana-keystore add elasticsearch.password\n   ```\n\n*注：请务必记住输入的密码。*  \n\n 重启 kibana\n\n   ```shell\ncd /usr/kibana\npkill -F pid\n./bin/kibana -d -p pid\n   ```\n\n7、检查\n\n访问 ip:5601, 确认是否安装成功。\n\n### IK分词器安装\n\n1、通过 SFTP工具将 elasticsearch-analysis-ik-7.17.7.zip 上传到服务器上\n\n2、将IK安装包拷贝到 /usr/elasticsearch/plugins，并解压\n\n   ```shell\nsudo mkdir /usr/elasticsearch/plugins\nsudo cp elasticsearch-analysis-ik-7.17.7.zip /usr/elasticsearch/plugins\ncd /usr/elasticsearch/plugins\nunzip elasticsearch-analysis-ik-7.17.7.zip\nrm -rf elasticsearch-analysis-ik-7.17.7.zip\n   ```\n\n3、重启 elasticsearch 和 kibana","tags":["Elasticsearch"],"categories":["Elasticsearch"]},{"title":"docker环境离线安装","url":"/2024/08/29/docker-offline/","content":"\n### 一、安装步骤\n1、下载`Docker`二进制文件（离线安装包）\n\n下载地址：https://download.docker.com/linux/static/stable/x86_64/\n\n注：本文使用 /x86_64/docker-18.06.1-ce.tgz，注意对应操作系统类型。\n\n2、通过 FTP工具将 docker-18.06.1-ce.tgz 上传到服务器上\n3、解压安装包\n\n```bash\ntar zxf docker-18.06.1-ce.tgz\n```\n4、将docker 相关命令拷贝到 /usr/bin，方便直接运行命令\n```bash\nsudo cp docker/* /usr/bin/\n```\n5、启动Docker守护程序\n\n```bash\nsudo dockerd &\n```\n6、验证是否安装成功，执行docker info命令，若正常打印版本信息则安装成功。\n\n```bash\ndocker info\n```\n### 二、将docker注册成系统服务\n**注意：** 记得先 kill docker 服务后，再执行这一步操作。\n1、在 /usr/lib/systemd/system/ 目录下创建 docker.service 文件。\n```bash\nsudo vi /usr/lib/systemd/system/docker.service\n```\n文件内容如下：\n```bash\n[Unit]\nDescription=Docker Application Container Engine\nDocumentation=https://docs.docker.com\nAfter=network-online.target firewalld.service\nWants=network-online.target\n\n[Service]\nType=notify\nExecStart=/usr/bin/dockerd\nExecReload=/bin/kill -s HUP $MAINPID\nLimitNOFILE=infinity\nLimitNPROC=infinity\nTimeoutStartSec=0\nDelegate=yes\nKillMode=process\nRestart=on-failure\nStartLimitBurst=3\nStartLimitInterval=60s\n\n[Install]\nWantedBy=multi-user.target\n```\n2、启动 / 停止 docker 服务\n```bash\nsystemctl start/stop docker\n```\n3、开机自启/取消开机自启 docker 服务\n```bash\nsystemctl enable/disable docker\n```\n\n","tags":["docker"],"categories":["docker"]},{"title":"基于docker实现rasa容器化部署","url":"/2023/04/27/rasa-docker/","content":"\n## 基础环境搭建\n\n1、拉取python:3.9-slim 镜像\n\n```bash\ndocker pull python:3.9-slim\n```\n\n2、配置docker容器的网络环境\n\n```bash\n# 首先查看、创建一个网络 rasa-network \ndocker network ls \ndocker network create rasa-network\n#将容器加入网络当中\n方法一：\ndocker network connect rasa-netwrk 容器名称\n方法二：启动容器的时候加入：（本文选择此种方法）\ndocker run -itd --network rasa-network 容器名称\n# 在外面查看各个容器的IP地址 \ndocker network inspect rasa-network\n```\n\n3、创建rasa容器\n\n```bash\n# 设置容器名称、网络桥接、端口号、镜像名称\ndocker run -id --name=rasa-test --network rasa-network -p 5005:5005 python:3.9-slim\n# 进入容器\ndocker exec -it rasa-test /bin/bash\n```\n\n4、将容器的源更改为官方源（阿里源）\n\n```bash\n# 更新apt\napt-get update\n# 下载gnupg\napt-get install gnupg1\n# 设置公钥，否则无法使用阿里源\napt-key adv --keyserver keyserver.ubuntu.com --recv-keys 3B4FE6ACC0B21F32\n# 原文件备份\ncp /etc/apt/sources.list /etc/apt/sources.list.bak\n# 更改为阿里源并更新apt-get\necho \"deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse\ndeb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse\ndeb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse\ndeb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse\ndeb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse\">/etc/apt/sources.list\n```\n\n5、更新apt\n\n```bash\napt-get clean && apt-get update\n```\n\n5、将pip源更改为国内源（清华源）\n\n```bash\npip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n```\n\n## 安装rasa\n\n1、安装rasa\n\n```bash\n安装最新版：\npip install rasa\n也可在安装时指定版本号：\npip install rasa==3.4.0\n```\n\n2、rasa相关命令介绍，rasa的官方文档：https://rasa.com/docs/rasa/\n\n- rasa init：创建一个新的项目，包含示例训练数据，actions和配置文件。\n- rasa train：使用NLU数据和stories训练模型，模型保存在./models中。\n- rasa test：使用测试NLU数据和stories来测试Rasa模型。\n- rasa shell：通过命令行的方式加载训练模型，然后同聊天机器人进行对话。\n- rasa run：使用训练模型开启一个Rasa服务。\n- rasa run actions：使用Rasa SDK开启action服务器。\n- rasa interactive：开启一个交互式的学习会话，通过会话的方式，为Rasa模型创建一个新的训练数据。\n- telemetry：Configuration of Rasa Open Source telemetry reporting.\n- rasa visualize：可视化stories。\n- rasa data：训练数据的工具。\n- rasa export：通过一个event broker导出会话。\n- rasa evaluate：评估模型的工具。\n- rasa x：在本地启动Rasa X。\n- -h, --help：帮助命令。\n- --version：查看Rasa版本信息。\n\n## 创建rasa项目\n\n1、初始化rasa项目\n\n```bash\nmkdir rasa-test\ncd rasa-test\nrasa init\n```\n\n2、如果要实现中文分词、意图分类和实体识别，则还需要安装 jieba、transformers组件\n\n```bash\npip install jieba\npip install transformers\n```\n\n3、编写nlu.yml文件，准备自定义的NLU训练数据，主要用于意图分类模型训练。\n\n```yml\nversion: \"3.1\"\n\nnlu:\n- intent: greet\n  examples: |\n    - hey\n    - hello\n    - hi\n```\n\n其中`intent: greet`表示意图为greet，`examples`是具体的简单例子。稍微复杂点的例子格式是：[实体值]（实体类型名），比如[明天]（日期）[上海]（城市）的天气如何？其中的日期和城市就是NLP中实体识别中的实体了。除了intent之外，该文件还可以包含同义词synonym、正则表达式regex和查找表lookup等。\n\n4、修改config.yml文件，配置NLU模型，主要是配置pipeline。\n\n（1）其中pipeline主要是分词组件、特征提取组件、NER组件和意图分类组件等，通过NLP模型进行实现，并且组件都是可插拔可替换的。\n\n（2）如果LanguageModelFeaturizer配置了bert-base-chinese，则需要事先下载tf_model.h5文件，该文件是基于tensorflow的中文bert预训练模型，下载链接如下：\n\n```\n链接：https://pan.baidu.com/s/1QLdmfxGJJE_xsPgaplhcOQ?pwd=oo14 \n提取码：oo14\n```\n\n5、根据实际需要编写 story 故事数据（stories.yml文件）和 rule 规则数据（rules.yml文件）。\n\n```yaml\nversion: \"3.1\"\n\nstories:\n\n- story: happy path\n  steps:\n  - intent: greet\n  - action: utter_greet\n  - intent: mood_great\n  - action: utter_happy\n\n- story: sad path 1\n  steps:\n  - intent: greet\n  - action: utter_greet\n  - intent: mood_unhappy\n  - action: utter_cheer_up\n  - action: utter_did_that_help\n  - intent: affirm\n  - action: utter_happy\n\n- story: sad path 2\n  steps:\n  - intent: greet\n  - action: utter_greet\n  - intent: mood_unhappy\n  - action: utter_cheer_up\n  - action: utter_did_that_help\n  - intent: deny\n  - action: utter_goodbye\n```\n\n上述内容可看做是用户和机器人一个完整的真实的对话流程，对话策略可通过机器学习或者深度学习的方式从其中进行学习。\n\n6、编写domain.yml文件，定义领域domain，包含了聊天机器人的所有信息，包括意图(intent)、实体(entity)、词槽(slot)、动作(action)、表单(form)和回复(response)等。\n\n7、配置Rasa Core模型，主要是配置policies。policies主要是对话策略的配置，常用的包括*TEDPolicy、UnexpecTEDIntentPolicy、MemoizationPolicy、AugmentedMemoizationPolicy、RulePolicy、Custom Policies*等，并且策略之间也是有优先级顺序的。\n\n8、使用rasa train训练模型\n\n```bash\nrasa train\n或者\nrasa train nlu\nrasa train core\n```\n\n如果在配置pipeline时，作了如下配置，则表示rasa会从pre-models目录下加载bert-base-chinese预训练模型，所以需要将刚才下载的tf_model.h5文件拷贝到pre-models目录，\n\n*例如：pre-models/models--bert-base-chinese/snapshots/8d2a91f91cc38c96bb8b4556ba70c392f8d5ee55*\n\n然后再启动模型训练。\n\n```yaml\n- name: LanguageModelFeaturizer\n  model_name: 'bert'\n  model_weights: 'bert-base-chinese'\n  cache_dir: 'pre-models'\n```\n\nrasa的模型训练会使用data目录中的数据作为训练数据，使用config.yml作为配置文件，并将训练后的模型保存到models目录中。\n\n9、使用rasa test测试模型\n\n```\nrasa test\n```\n\n10、让用户使用聊天机器人\n\n可以通过shell用指定的模型进行交互：\n\n```bash\nrasa shell -m models/nlu-xxx.tar.gz\n也可不指定模型，默认使用最新一次训练的模型：\nrasa shell\n```\n\n此外，还可以通过api的方式，进行交互验证：\n\n```bash\nrasa run --enable-api\n也可同时指定服务端口号：\nrasa run --enable-api --port 8080\n```\n\n然后用户可通过API访问聊天机器人，也可通过postman访问，api请求格式如下：\n\n**仅解析意图**\n\n```bash\n请求地址：localhost:5005/model/parse\n命令行：curl -X POST localhost:5005/model/parse -d ‘{“text”: “hello”}’\n```\n\n- 代码示例\n\n```python\nimport json\nimport requests\n\nurl = \"http://localhost:5005/model/parse\"\ndata = {\"text\": \"hello\"}\ndata = json.dumps(data, ensure_ascii=False)\ndata = data.encode(encoding=\"utf-8\")\nr = requests.post(url=url, data=data)\nprint(json.loads(r.text))\n```\n\n**完整对话**\n\n```bash\n请求地址：localhost:5005/webhooks/rest/webhook\n命令行：curl -X POST localhost:5005/webhooks/rest/webhook -d {“sender”: \"user1\", “message”: \"hello\"}\n```\n\n- 代码示例\n\n```python\nimport json\nimport secrets\nimport requests\ndef post(url, data=None):\n    data = json.dumps(data, ensure_ascii=False)\n    data = data.encode(encoding=\"utf-8\")\n    r = requests.post(url=url, data=data)\n    r = json.loads(r.text)\n    return r\n\nsender = secrets.token_urlsafe(16)\nurl = \"http://localhost:5005/webhooks/rest/webhook\"\nmessage = input(\"Your input -> \")\ndata = {\n    \"sender\": sender,\n    \"message\": message\n}\nprint(post(url, data))\n```\n\n## rasa服务部署\n\n采用shell脚本文件，实现rasa服务的一键启停。\n\n1. 新建start-rasa.sh文件，内容如下：\n\n```bash\n#!/bin/bash\necho \"starting rasa-server...\"\n\ncd /root/rasa-server\nnohup rasa run actions > /root/actions.log 2>&1 &\nnohup rasa run --enable-api > /root/server.log 2>&1 &\ncd /root\n\necho \"rasa-server started!\"\n```\n\n在start-rasa.sh所在目录下，运行命令`source start-rasa.sh`即可启动rasa服务。\n\n上述脚本中，2>&1是用来将标准错误2重定向到标准输出1中，1前面的&是为了让bash将1解释成标准输出而不是文件1，而最后一个&是为了让bash在后台执行。\n\n2. 新建stop-rasa.sh文件，内容如下：\n\n```bash\n#!/bin/bash\n\n#根据进程名杀死进程\nif [ $# -lt 1 ]\nthen\n  echo \"缺少参数：pro_name\"\n  return 1\nfi\n\nPROCESS=`ps -ef | grep $1 | grep -v grep | grep -v PPID | awk '{print $2}'`\nfor i in $PROCESS\n  do\n    echo \"Kill the $1 process [ $i ]\"\n    kill -9 $i\n  done\n```\n\n在stop-rasa.sh所在目录下，运行命令`source stop-rasa.sh rasa`即可停止所有rasa服务。\n","tags":["docker","python","rasa"],"categories":["rasa"]},{"title":"低成本搭建家用轻NAS系统-玩客云","url":"/2022/11/15/wky-nas/","content":"\n## 写在前面\n\n- 目前网络上有很多关于使用玩客云搭建NAS系统的文章，其中我觉得写的比较详细的是知乎上的这一篇[《玩客云刷机armbian系列》](https://www.zhihu.com/column/c_1334222614072287232)，我有很多是参考他的内容。\n- 本文主要对我自己搭建的过程做一个详细和全面的介绍，供大家参考。\n- 标题写“低成本”，至于为什么是低成本，主要是有两个方面原因。一方面是本身硬件成本不高，主要由玩客云和存储硬盘组成，玩客云从闲鱼上买只要50元左右，硬盘可以用闲置的移动硬盘；另一方面是玩客云的功耗很低，只有3~5w，即使是外接移动硬盘，连续运行一年的电费也不会超过50元。\n- **玩客云的硬件配置**：CPU采用的是晶晨的S805，单核主频1.5GHz，这个CPU的最大优点就是功耗低，发热量小。内存RAM采用的是海力士，512MB*2，共1GB DDR3内存。闪存ROM是三星的8GB。网口芯片采用的是螃蟹的RTL6211F千兆网口。外观上采用铝合金工艺，前面板有一颗七彩灯，整体颜值较高。\n\n![](1.jpg)\n\n## 玩客云拆机\n\n### 准备工具\n\n因为刷机需要先拆机才能刷，所以需要借助有些工具来拆机。需准备的工具内容如下：\n\n（1）双公头的USB线\n\n（2）一把镊子或一根短接线\n\n（3）一根网线\n\n（4）平口和米字型螺丝刀\n\n（5）一台吹风机\n\n### 拆机\n\n（1）用吹风机将面板吹热，让玩客云粘和面板的胶水软化，然后用平口螺丝刀慢慢撬开。从SD卡的位置比较容易撬一些。\n\n![](2.jpg)\n\n（2）取下面板之后，拧掉露出来的六颗螺丝，然后将主板从盒子里抽出来。\n\n![](3.jpg)\n\n（3）玩客云的主板分为两个硬件版本，一个是V1.0，一个是V1.3，在主板上会有相应标识。这里需要特别注意下主板的硬件版本，因为不同硬件版本的主板，其刷机方式略有差异。\n\n![](4.jpg)\n\n## 玩客云刷机\n\n### 准备软件工具包\n\n（1）需准备的软件工具包如下：\n\n![](5.jpg)\n\n- Armbian_22.11.0是Armbian系统固件；\n\n- A-v1.0底包是V1.0主板的安卓盒子固件；\n\n- A-v1.3底包是V1.3主板的安卓盒子固件；\n\n- Amlogic.USB.Burning.Tool是刷机工具；\n\n- putty是远程连接玩客云盒子的通讯工具。\n\n（2）双击并安装Amlogic.USB.Burning.Tool。\n\n### 刷入Armbian系统\n\n> 什么是 Armbian ？\n\nArmbian是其他项目可以信赖的单板计算机（SBC）的基本操作系统平台，它拥有以下几个特点：\n\n- 轻量级基于Debian或Ubuntu的Linux发行版，专门用于ARM开发板；\n\n- 每个系统均由Armbian Build Tools进行编译，组装和优化；\n- 它具有强大的构建和软件开发工具，可以进行自定义构建； \n- 充满活力的社区。\n\n**Armbian其实就是Linux的一个发行版本，专门用于ARM开发板的小型系统。**\n\n#### 用双公头的USB线把电脑和主板连起来\n\n（1）打开刚才已安装好的USB_Burning_Tool。\n\n![](10.png)\n\n（2）将USB线的一头插到电脑的USB口上，另一头插到主板的USB口上，注意是靠近HDMI接口的那个USB口。\n\n![](9.jpg)\n\n#### 将主板短接\n\n用镊子或短接线将主板的某两个点进行短接，V1.0和V1.3主板的短接点不一样，具体如下图所示。\n\n> **V1.0版本的主板短接方式**\n\n![](6.jpg)\n\n> **V1.3版本的主板短接方式**\n\n![](7.jpg)\n\n使用镊子、线缆或其他能导电的东西都可以，如下图所示，使用镊子把两个端点连接。 **短接通电时，一定要注意，手部千万别碰触到面板，以免造成短路，把板子烧坏。**\n\n![](8.jpg)\n\n#### 通电刷机\n\n（1）当主板短接好之后，接上主板电源，给主板通电。**这里一定要一直保持住主板的两个点处于短接状态。**\n\n（2）当USB_Burning_Tool软件界面上出现“连接成功”时，将短接线或镊子移开。**如果短接成功，则主板上的灯也不会亮。** 如果短接失败，则主板上的灯会亮，那么就重新断开主板电源，短接好之后，再给主板通电。\n\n![](11.jpg)\n\n（3）连接成功之后，开始**导入安卓盒子固件，即A-v1.0底包.img 或 A-v1.3底包.img，根据自己的主板版本选择相应底包**，开始烧录。烧录完成后，点击“停止”按钮，然后断开电源，拔掉电脑侧的USB线。\n\n![](12.jpg)\n\n（4）接通主板电源，给主板通电运行一下底包。运行约1分钟以后，关闭主板电源。将电脑侧USB线接好，将主板短接，然后接通主板电源。当USB_Burning_Tool软件界面上出现“连接成功”时，将短接线或镊子移开。\n\n（5）**导入Armbian系统固件，即Armbian_22.11.0**，烧录成功后，点击“停止”按钮，关闭主板电源，拔掉电脑侧的USB线。\n\n（6）可将主板放回到玩客云盒子中，把面板螺丝拧紧固定好，把盒子组装好。将网线接到路由器和玩客云盒子上，**保证电脑与玩客云盒子同处于一个局域网环境下，即它们俩连的是同一个路由器，** 然后接通玩客云盒子的电源，此时会发现灯是红色的，而且会闪。\n\n![](13.jpg)\n\n#### 启动Armbian\n\n（1）通过windows控制台，输入ipconfig，查看网关IP地址，即当前路由器的IP地址，然后打开浏览器，访问该路由器配置界面，可以看到在路由器的设备列表中，有一个名字叫onecloud的设备，这个设备就是玩客云盒子。从这里可以看到玩客云的内网IP地址，即192.168.XX.XX。\n\n![](14.jpg)\n\n（2）打开putty通讯工具，用户名为root，初始登录密码是1234。登录成功之后，会提示你创建一个新密码。新密码设置完成后，就会正式进入到Armbian系统了。\n\n![](15.jpg)\n\n（3）修改系统时区\n\n```shell\nrm -rf /etc/localtime\nln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime\necho Etc/UTC > /etc/timezone\n```\n\n（4）更换为国内源，下载速度更快\n\n```shell\n# 备份原文件\ncp /etc/apt/sources.list.d/armbian.list /etc/apt/sources.list.d/armbian.list.bak\n# 更改为清华源(以下是一条命令，需一次性复制完整)\nsudo tee /etc/apt/sources.list.d/armbian.list <<-'EOF'\ndeb https://mirrors.tuna.tsinghua.edu.cn/armbian/ stretch main stretch-utils stretch-desktop\nEOF\n\n# 备份原文件\ncp /etc/apt/sources.list /etc/apt/sources.list.bak\n# 更改为中科大源(以下是一条命令，需一次性复制完整)\nsudo tee /etc/apt/sources.list <<-'EOF'\ndeb http://mirrors.ustc.edu.cn/debian stretch main contrib non-free\ndeb http://mirrors.ustc.edu.cn/debian stretch-updates main contrib non-free\ndeb http://mirrors.ustc.edu.cn/debian stretch-backports main contrib non-free\ndeb http://mirrors.ustc.edu.cn/debian-security/ stretch/updates main contrib non-free\nEOF\n\n# 更新软件列表和软件\nsudo apt-get update && sudo apt-get upgrade\n\n# 重启玩客云\nreboot\n```\n\n**到这里，Armbian系统就安装好了，玩客云刷机成功。**\n\n****\n\n*接下来开始部署可道云，实现家用轻 NAS 系统。*\n\n## 搭建WEB环境-LNMP\n\n所谓的LNMP是指 linux+nginx+mysql+php 的首字母，是一套用于运行WEB网站的软件组合包。\n\n- linux 就是我们现在已经刷好的Armbian系统。\n\n- nginx 是一个高性能的HTTP和反向代理web服务器，同时也提供了IMAP/POP3/SMTP服务。\n\n- mysql 是一个关系型数据库管理系统, 也是当前最流行的关系型数据库管理系统之一。\n\n- PHP 即“超文本预处理器”是在服务器端执行的脚本语言，主要用途在于处理动态网页。\n\n所以现在需要安装nginx、mysql、PHP，可以通过安装宝塔来一键可视化安装这些包，也可以通过挨个手动安装。我是采用的后者，因为装宝塔一直装不成功，各种版本的宝塔都试了，安装过程中出现了各种问题，后来一怒之下，弃之。如果感兴趣的，想安装宝塔的，可访问 [宝塔linux面板命令大全 - 宝塔面板](https://www.bt.cn/btcode.html)，查阅相关内容。\n\n### 安装nginx\n\n```shell\napt-get -y install nginx\n```\n\n安装完成后，使用电脑或手机浏览器访问 玩客云IP ，例如我的 192.168.2.194。如果显示了Welcome to nginx! 则表示nginx安装完成！\n\n![](16.jpg)\n\n### 安装php及其常用组件\n\n```shell\napt install -y php php-fpm php7.0-mysql php7.0-gd php7.0-curl php7.0-mbstring\n```\n\n同样，可以通过命令`php -v`查看php的版本号。\n\n### 安装mysql （可选，kodexplorer不依赖它）\n\n刚开始我是打算通过命令`apt install -y mysql-server`来安装mysql，但系统一直提示找不到相应的软件包，所以后来改用了MariaDB。\n\nMariaDB数据库管理系统是MySQL的一个分支，是由MySQL之父Michael开发的。开发这个分支的原因之一是：甲骨文公司收购了MySQL后，有将MySQL闭源的潜在风险，因此社区采用分支的方式来避开这个风险，所以mariadb就是mysql的替代品。\n\n```shell\napt install -y mariadb-server\n```\n\n然后可以通过命令`mysql -V`查看mysql的版本号。\n\n### 配置nginx环境\n\n这里使用到一个系统自带的文本编辑器nano，就像windows里的记事本，它比vi/vim要简单得多。想深入了解的同学可以使用`nano --help` 或 `man nano` 命令查看。\n\n**这里简单说下基本用法：**\n\n- 方向键上下左右，用于调整光标位置\n\n- ctrl + x 退出\n\n- ctrl + o 写入(保存)\n\n- ctrl + w 搜索\n\n- ctrl + c 游标位置(显示光标所在的行列)\n\n- ctrl + / 跳转到指定 行、列\n\n- ctrl + g 帮助\n\n接着我们对nginx配置文件做简单修改，输入命令：\n\n```shell\nnano -c /etc/nginx/sites-enabled/default\n```\n\n在第44行的最后面加上index.php，如下图所示。\n\n![](17.png)\n\n然后对56~63行的部分行，做去#号处理，如下图所示。\n\n> 处理前的内容\n\n![](18.jpg)\n\n> 处理后的内容，这里要注意千万别弄错了。\n\n![](19.jpg)\n\n按 `ctrl + o` 写入并保存，再按 `ctrl + x` 退出。\n\n![](20.jpg)\n\n先检查下修改后的nginx配置文件是否正确。输入`nginx -t` 命令，如果返回 successful ，则表示配置文件无错误，否则说明配置文件有错误。\n\n```shell\nnginx -t -c /etc/nginx/nginx.conf\n```\n\n确认nginx配置文件正确后，重启nginx服务。\n\n```shell\nservice nginx restart\n```\n\n接着创建一个测试文件，输入命令\n\n```shell\necho \"<?php phpinfo(); ?>\">/var/www/html/info.php\n```\n\n然后使用电脑或手机浏览器访问 “玩客云IP/info.php\"，比如：192.168.2.194/info.php。如果出现以下内容，表示nginx配置的没有问题。\n\n![](21.png)\n\n### 配置mysql/mariadb（可选，若无需安装mysql，则跳过）\n\n#### 使用配置向导\n\n输入命令 `mysql_secure_installation` 进行配置。\n\n![](22.jpg)\n\n此时会出现一些交互事项：\n\n- Enter current password for root (enter for none):  初次运次无密码，直接回车。\n\n- Set root password? [Y/n]  输入Y，这里的 root 是指mysql的用户名。\n\n- New password:  设置 root 用户的密码。\n\n- Re-enter new password:  再输入一次你设置的密码。\n\n- Remove anonymous users? [Y/n]  是否删除匿名用户，直接回车。\n- Disallow root login remotely? [Y/n]  是否禁止root远程登录，输入n。\n- Remove test database and access to it? [Y/n]  是否删除test数据库，直接回车。\n- Reload privilege tables now? [Y/n]  是否重新加载权限表，直接回车。\n\n#### 配置mariadb远程访问权限\n\n（1）开启数据库远程访问，输入刚才设置的root用户的密码来登录。\n\n```shell\nmysql -u root -p\n```\n\n（2）接着依次输入以下指令：\n\n```shell\nmysql> use mysql;\n\nmysql>GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY '123456' WITH GRANT OPTION;\n\nmysql>update user set plugin = 'mysql_native_password' where user = 'root';\n\nmysql> flush privileges;\n\nmysql> exit;\n```\n\n![](23.jpg)\n\n#### 修改MariaDB配置文件，允许远程访问\n\n```shell\nnano /etc/mysql/mariadb.conf.d/50-server.cnf\n```\n\n将bind-address = 127.0.0.1 改为 bind-address = 0.0.0.0，然后ctrl + o 保存，ctrl + x 退出。\n\n**至此，WEB环境搭建完成。**\n\n***\n\n## 安装可道云\n\n可道云是最常用的搭建私人云盘的软件之一，分为 *kod explorer 和 kodbox 两个版本*，属于不同产品，适用的场景也不相同。\n\n### kod explorer简介\n\nkod explorer是可道云的早期产品，**无需数据库就可以运行**，适用于个人用户或小型团队和企业。它本质上是一个在线的文件管理器，可以用来管理指定文件夹的文件，和File Browser有点类似，可以理解成是一个在线的“我的电脑”。通过kod explorer看到的文件跟我们通过WINSCP或者SSH看到的文件是一样的，说白了就是**kod explorer的文件目录结构与磁盘中存储的文件目录结构是一样的，因而比较适合那些对文件管理有强烈需求的用户。**\n\n### kodbox简介\n\nkodbox 是在 kod explorer 基础上进行了系统重构的全新产品。为满足系统更强性能、更安全、更多特性的拓展需求，Kodbox 对底层架构、存储方式、权限机制等进行了重构，同时继承并升级了 kod explorer 优秀前端体验。KodBox 更多针对企业级的应用需求，可支撑高并发、更多用户数、更高协作和安全要求。\n\n同时，**kodbox是需要数据库支持的**，它会将你上传的文件分成一个一个的小文件进行存储。在kodbox里面看到的是完整的文件，而通过WINSCP或SSH看到的则是一个一个的小文件，无法正常读取。同样的，通过WINSCP或者FTP上传的文件也不能被kodbox识别，所以kodbox的安全性会更高，更适合用来分享文件，但是不适合做文件的管理，因为kodbox在磁盘中存储的文件是按照日期分类存储的，与kodbox看到的文件目录结构完全不一致。\n\n*我搭建可道云私有化环境，主要是用来对我个人家庭的日常文件，如图片、视频等，进行文件的管理和维护，所以我选用了 kod explorer 作为家用的私有云存储系统。*\n\n下面将分别介绍 kod explorer 和 kodbox 的具体安装过程。**我们可根据自身需求，选择其中一个来安装和使用。**\n\n### 安装kod explorer\n\n（1）用命令wget获取kodexplorer安装包或前往[可道云官网](https://kodcloud.com/download/)自行下载。\n\n```shell\nwget https://static.kodcloud.com/update/download/kodexplorer4.49.zip\n```\n\n（2）解压kodexplorer到/var/www/html/kode目录下，并赋予kode目录读写权限。\n\n```shell\nunzip -d /var/www/html/kodb kodexplorer4.49.zip \nchmod -R 777 /var/www/html/kode/\n```\n\n（3）使用手机或电脑浏览器访问：玩客云IP/kode，例如我的是：192.168.2.194/kode，根据系统提示新建管理员密码，即可进入系统。\n\n![](32.jpg)\n\n（4）最后可前往可道云官网下载移动端APP，在手机上访问可道云。注意需要配置下服务器站点，如：192.168.2.194/kodb，才能正常访问，且要保证手机与玩客云连接的是同一个路由器。\n\n```shell\n安卓APP下载地址：https://static.kodcloud.com/update/client/app/kodexplorer/com.kodcloud.explorer.apk\n苹果APP获取方法：打开App Store，搜索 kodexplorer 即可。\n```\n\n![](33.jpg)\n\n#### 修改kod explorer的默认存储位置\n\nkod explorer登录进去之后的默认存储位置（主文件夹）是在玩客云的内部存储，所以我们上传文件时默认上传到了玩客云的内部存储。由于玩客云的内部存储空间小，且存放着系统文件，可谓一寸空间一寸金。因此，将默认存储位置修改到外部存储设备就显得十分有必要了。\n\n（1）准备好外接存储设备\n\n外接存储设备必须是ext4格式的，否则将会挂载失败。如果外接存储设备不是ext4格式，则需要进行格式转化，具体步骤如下：\n\n```shell\n# 查看你的U盘序号，通常是/dev/sda或/dev/sdb之类的\nfdisk -l \n# 格式化为ext4分区\nmkfs.ext4 /dev/sda1\n```\n\n然后将U盘挂载到系统上，并将kod explorer现有数据迁移到U盘\n\n```shell\n# 建立挂载点，netdisk为挂载点名称，可以自定义\nmkdir /var/www/netdisk\n# 挂载U盘\nmount -t ext4 /dev/sda1 /var/www/netdisk\n# 迁移数据\ncp -r /var/www/html/kode/data /var/www/netdisk/\n# 赋予挂载目录读写权限\nchmod -R 777 /var/www/netdisk/\n```\n\n（2）修改默认存储位置\n\n在/var/www/html/kode/config目录下新建一个define.php文件，\n\n```shell\nnano -c /var/www/html/kode/config/define.php\n```\n\n并输入如下内容：\n\n```php\n<?php\ndefine('DATA_PATH','/var/www/netdisk/data/');\n?>\n```\n\n保存文件后，重新登录kod explorer，会发现默认存储位置或主文件夹已经变成了修改后的路径了。\n\n![](31.png)\n\n### 安装kodbox\n\n（1）用命令wget获取可道云KodBox安装包或前往[可道云官网](https://kodcloud.com/download/)自行下载。\n\n```shell\nwget https://static.kodcloud.com/update/download/kodbox.1.35.zip\n```\n\n（2）解压kodbox到/var/www/html/kodb目录下，并赋予kodb目录读写权限。\n\n```shell\nunzip -d /var/www/html/kodb kodbox.1.35.zip \nchmod -R 777 /var/www/html/kodb/\n```\n\n（3）为了提升系统访问速度，我们采用redis系统缓存，所以先安装下redis-server及php-redis组件。\n\n```shell\napt-get install -y php-redis\napt-get install -y redis-server\n```\n\n（4）重启 php7.0-fpm\n\n```shell\nservice php7.0-fpm restart\n```\n\n（5）使用手机或电脑浏览器访问：玩客云IP/kodb，例如我的是：192.168.2.194/kodb，会出现安装向导。\n\n**环境检测：** 由于玩客云s805不是64位CPU，所以只能支持32位，所以在环境检测中选择跳过。\n\n![](24.jpg)\n\n**数据库配置：** 数据库类型，选择mysql，并填写mysql 的用户名与密码。系统缓存，选择 Redis ，然后点击“确定”即可。\n\n![](25.jpg)\n\n**账号设置：** 设置好kodbox的管理员密码，就可以登录了。\n\n![](26.jpg)\n\n最后可前往可道云官网下载移动端APP，在手机上访问可道云。注意需要配置下服务器站点，如：192.168.2.194/kodb，才能正常访问，且要保证手机与玩客云连接的是同一个路由器。\n\n![](27.jpg)\n\n***\n\n**到这里，利用玩客云来搭建家用轻NAS系统的操作就全部完成了。**\n\n## 遇到的问题及解决方案\n\n### 使用putty时报错：tput: unknown terminal \"xterm\"\n\n**问题描述：** 在使用putty过程中，报错 tput: unknown terminal \"xterm\"，此时按后退键和上下左右键都会出现乱码。\n\n**解决方案：** 输入以下命令，重装**ncurses-base**即可。\n\n```shell\napt reinstall ncurses-base\n```\n\n### 安装mysql或mariadb时报错：The following packages have unmet dependencies\n\n**问题描述：** 输入命令`apt-get install mysql-server`安装mysql时，出现以下错误：\n\n```shell\nThe following packages have unmet dependencies:\n mysql-server : Depends: default-mysql-server but it is not going to be installed\nE: Unable to correct problems, you have held broken packages.\n```\n\n被告知需要安装依赖包：default-mysql-server，然后输入命令`apt-get install default-mysql-server`安装这个依赖包，但又出现以下错误：\n\n```\nThe following packages have unmet dependencies:\n default-mysql-server : Depends: mariadb-server-10.1 but it is not going to be installed\nE: Unable to correct problems, you have held broken packages.\n```\n\n这次被告知需要安装依赖包：mariadb-server-10.1，然后继续输入命令`apt-get install mariadb-server-10.1`安装这个依赖包，但又出现了以下错误：\n\n```\nThe following packages have unmet dependencies:\n mariadb-server-10.1 : Depends: libdbi-perl but it is not going to be installed\nE: Unable to correct problems, you have held broken packages.\n```\n\n根据提示，需要安装依赖包：libdbi-per，然后再输入命令`apt-get install libdbi-perl`安装这个依赖包，但又出现了以下错误：\n\n```\nThe following packages have unmet dependencies:\n libdbi-perl : Depends: perlapi-5.24.1\nE: Unable to correct problems, you have held broken packages.\n```\n\n可以看出，它又依赖于perlapi-5.24.1，所以继续输入命令`apt-get install perlapi-5.24.1`安装它，但依然报错：\n\n```\nPackage perlapi-5.24.1 is a virtual package provided by:\n  perl-base 5.24.1-3+deb9u5 [Not candidate version]\n\nE: Package 'perlapi-5.24.1' has no installation candidate\n```\n\n到这里，终于出现了终极错误。原来是因为 **没有安装perl-base 5.24.1** 而导致mysql无法正常安装。但我们通过命令`perl -v`可以看到，系统里其实已经安装了perl-base，只是版本号不是5.24.1，而是其它别的版本，但一般来说，perl的依赖关联实在太多，我们不能直接卸载它进行重装，否则将会非常麻烦。\n\n**解决方案：** 基于上述情况，我们可以考虑将当前系统的perl版本平滑降至5.24.1，来解决这个问题。\n\n（1）首先我们去debian官网下载[perl-base 5.24.1软件包](https://packages.debian.org/stretch/perl-base)，由于玩客云的硬件架构师armhf的，所以选择下载 armhf 的软件包。\n\n![](28.png)\n\n点击“armhf”，进入到另一个页面，选择亚洲节点进行下载，也可输入如下命令，直接获取软件包到玩客云上。\n\n```shell\nwget http://mirrors.ustc.edu.cn/debian/pool/main/p/perl/perl-base_5.24.1-3+deb9u7_armhf.deb\n```\n\n（2）通过dpkg来安装deb包\n\n```shell\nsudo dpkg -i perl-base_5.24.1-3+deb9u7_armhf.deb\n```\n\n（3）修复相关依赖：\n\n```shell\napt --fix-broken install\n```\n\n此时输入命令`perl -v`查看perl版本，发现perl版本变成了5.24.1，然后再次输入安装mysql或mariadb的命令，就可以成功安装了。\n\n### 使用SD卡刷机后，如何恢复SD卡的原始存储空间\n\n**问题描述：** 有些玩客云刷机教程采用的是SD卡刷机，首先是利用 BalenaEtcher 刻录工具将armbian系统刻录到SD卡中，作为系统启动盘。我尝试过一次，感觉这种方式刷机比较慢，大概等了半个多小时才刷好，所以后来还是采用了拆机短接的方式刷的。那么如何将之前作为系统启动盘的SD卡恢复回去，继续作为普通的文件存储U盘使用呢？\n\n**解决方案：** 利用diskpart将SD卡中的数据清空，然后再进行格式化，就可以了。具体操作步骤如下：\n\n（1）打开windows命令行，输入diskpart命令。\n（2）在diskpart里面，输入list disk命令，查看当前系统挂载的磁盘（包括SATA、U盘、SD卡等），如下图所示。\n\n![](29.png)\n\n（3）找到要恢复的磁盘，比如我要恢复的是磁盘1，则输入命令`select disk 1`\n\n（4）再输入命令clean，就可以将4中所选的磁盘数据清空了，再次输入list disk可以看到磁盘的可用已经和大小一样了。此时已经完成了SD卡的恢复，接下来我们将SD卡格式化。\n\n（5）依次输入以下命令：\n\n```shell\n# 创建卷\ncreate partition primary\n# 查看创建的卷\nlist partition\n# 选中磁盘1\nselect partition 1\n# 格式化磁盘1，即SD卡\nformat quick\n```\n\n![](30.png)\n\n","tags":["armbian","NAS"],"categories":["NAS系统"]},{"title":"使用工具logrotate实现大日志文件的分割和转储","url":"/2021/05/19/logrotate/","content":"\n## 为什么需要用logrotate\n\n通常情况下，系统运行时所产生的日志文件，会记录系统中已发生的一些重要的事件信息，经常被用于系统排障或系统性能分析。而对于比较忙碌的服务器，其日志文件大小会快速增长，大量消耗服务器的磁盘空间，造成磁盘空间不足，这也就成了一个不可忽视的问题。除此之外，查阅和处理一个体积庞大的日志文件也常常是件十分棘手的事情。\n\n为了解决以上问题，自然而然的就想到了logrotate，它是linux系统自带的日志文件管理工具，它可以自动对日志进行截断（或轮循）、压缩以及删除旧的日志文件。例如，你可以设置logrotate，让/var/log/foo日志文件每30天轮循一次，并删除超过6个月的日志。配置完成后，logrotate的运作完全自动化，不必进行任何进一步的人为干预。另外，旧日志也可以通过电子邮件的方式发送到指定邮箱中。\n\n## 安装logrotate（一般系统都会默认自动安装）\n\n主流Linux发行版上都默认安装有logrotate包。如果出于某种原因，logrotate没有被系统自动安装，那么你可以使用apt-get或yum命令来手动安装。\n\n在Debian或Ubuntu上：\n\n```shell\napt-get install logrotate cron\n```\n\n在Fedora、CentOS或RHEL上：\n\n```shell\nyum install logrotate crontabs\n```\n\nlogrotate的配置文件是/etc/logrotate.conf，我们通常不需要对它进行修改。每个应用程序的日志文件，其轮循策略被设置在独立的配置文件中，这些配置文件都会放在/etc/logrotate.d/目录下。\n\n## logrotate实现日志文件转储的工作原理\n\n针对文章开头提出的因单个日志文件内容过大而导致的一系列问题，可以通过linux系统自带的logrotate来对系统生成的日志文件按照日期、大小等进行转储，让logrotate定期转储日志文件，并且保留指定数量的日志转储文件，以满足线上运维的需求。\n\n其实logrotate转储日志文件的工作机制比较简单，即在linux系统下，Crontab每天都会执行logrotate，而logrotate每执行一次，就可以把我们的日志文件转储一次。\n\nlogrotate通过与定时任务Crontab结合来工作，就能满足定期，例如每天对日志文件进行转储的功能，**其原理是：**\n\nCrontab在linux系统的/etc目录中有几个定时执行的脚本目录，例如：/etc/cron.daily，在该文件夹下保存了Crontab每天都会定时执行的脚本；目录/etc/cron.weekly下则是记录了Crontab每周都会定时执行的脚本。\n\n我们可以看到在目录/etc/cron.daily中有个脚本文件：logrotate，这个脚本的内容为：\n\n```bash\n#!/bin/sh\n/usr/sbin/logrotate /etc/logrotate.conf\nEXITVALUE=$?\nif [ $EXITVALUE != 0 ]; then\n/usr/bin/logger -t logrotate \"ALERTexited abnormally with [$EXITVALUE]\"\nfi\nexit 0\n```\n\n从上面的脚本内容可以看出，它主要是执行程序logrotate，并且启动logrotate的时候加载了配置文件/etc/logrotate.conf。\n\n下面就是对这个配置文件 logrotate.conf 的内容进行简要说明：\n\n```bash\n# see \"man logrotate\" fordetails\n# rotate log files weekly\nweekly\n# keep 4 weeks worth of backlogs\nrotate 4\n# create new (empty) log files afterrotating old ones\ncreate\n# use date as a suffix of the rotated file\ndateext\n# uncomment this if you want your logfiles compressed\n#compress\n\n# RPM packages drop log rotationinformation into this directory\ninclude /etc/logrotate.d\n\n# no packages own wtmp and btmp -- we'll rotate them here\n/var/log/wtmp {\nmonthly\ncreate 0664 root utmp\nminsize 1M\nrotate 1\n}\n/var/log/btmp {\nmissingok\nmonthly\ncreate 0600 root utmp\nrotate 1\n}\n# system-specific logs may be also beconfigured here.\n```\n\n该文件的前半部分内容都是默认配置项，这些配置项可以被后续的配置所覆盖，这里需要关注的是配置项：**include /etc/logrotate.d**，它表示logrotate在启动的时候还要把目录/etc/logrotate.d中的配置文件都执行一遍。\n\n实际上，为了便于使用，每个应用程序都可以编写自己的logrotate配置文件，然后把编写好的配置文件放在目录/etc/logrotate.d下，这样每个程序自己的配置项就会把上面的默认配置项给覆盖掉。\n\n**覆盖默认配置项的具体过程如下：**\n\n（1）logrotate的启动脚本被放在了Crontab每天执行的脚本目录中/etc/cron.daily，这样Crontab每天都会执行一次logrotate；\n\n（2）logrotate启动的时候，加载了配置文件/etc/logrotate.conf；\n\n（3）配置文件/etc/logrotate.conf 又引入了目录：/etc/logrotate.d；\n\n（4）我们在/etc/logrotate.d目录下新建了一个自己的logrotate配置文件；\n\n（5）这样，当logrotate每次启动的时候就会执行加载我们自己新建的logrotate配置文件，从而按照我们设定的配置项来转储我们指定的日志文件。\n\n## 以mosquitto日志文件为例说明\n\n（1）在目录/etc/logrotate.d/下创建一个日志转储的配置文件（*名字可以自己定义，只要在该目录下就会被执行*）：mosquitto\n\n（2）配置文件mosquitto的内容如下：\n\n```bash\n/home/logs/mosquitto/mosquitto.log {\n daily\n dateext\n copytruncate\n nocompress\n rotate 15\n}\n```\n\n以下是该配置文件的内容说明：\n\n- 第一行左大括号之前的/home/logs/mosquitto/mosquitto.log 指出了要转储的日志文件的具体位置和文件名；\n\n- daily：按天去转储；\n\n- dateext：表示转储后的日志文件会附加上日期信息\n\n- copytruncate：对于正在open中的日志文件，会把当前日志备份并截断\n\n- nocompress：表示不要对转储的日志压缩\n\n- rotate 15：表示最多保留多少个转储之后的日志文件\n\n（3）确保刚才新建的mosquitto配置文件的权限为：-rw-r--r--\n\n**注意：**该配置文件的权限不能错，如果你修改为其他的，例如：-rwxrwxrwx，虽然你放开了权限，但是logrotate在运行时仍会报错：\n\n```bash\n/usr/sbin/logrotate -vf /etc/logrotate.d/\n \nIgnoring mosquitto because of bad filemode.\n \n进而造成logrotate读取你的配置文件失败！！！！\n```\n\n（4）查看log文件所在**父目录的权限，确保group权限和other权限中没有“w”权限**，否则在执行logrotate转储命令时会报错：\n\n```\nlogrotate执行轮询异常，“considering log /home/logs/mosquitto/mosquitto.log\nerror: skipping “/home/logs/mosquitto/mosquitto.log” because parent directory has insecure permissions (It’s world writable or writable by group which is not “root”) Set “su” directive in config file to tell logrotate which user/group should be used for rotation.”\n```\n\n如果发现group权限和other权限中含有“w”权限，则需使用chmod命令删除“w”权限，具体命令如下：\n\n```bash\nchmod go-w /home/logs/mosquitto\n```\n\n（5）最后测试一下配置文件的配置内容是否有误。执行logrotate转储命令：\n\n```bash\n/usr/sbin/logrotate -vf /etc/logrotate.conf\n```\n\n可以看到新生成的转储文件与原日志文件在同一个目录下，如下所示：\n\n```bash\n-rwxrwxrwx. 1 root root 482 5月  18 15:36 mosquitto.log\n-rwxrwxrwx. 1 root root 950 5月  18 15:25 mosquitto.log-20210518\n```\n\n这样后续每天原始日志文件的内容都会自动备份和截断，在当前目录下自动生成一个带有日期标签的日志转储文件。","tags":["linux","logrotate"],"categories":["linux系统"]},{"title":"人工智能之常见机器学习算法介绍","url":"/2021/04/29/ml/","content":"\n## 引言\n\n近些年，互联网成为人类日常生活中不可或缺的元素，无处不在。同时，人工智能、大数据、云计算、物联网、区块链等新兴技术也被人们炒的火热，正逐渐融入到我们的日常生活中，其中大数据代表着人类新一代的生产要素，云计算和人工智能作为新一代生产力的典型代表，而物联网和区块链则促进着人类未来生产关系的改变。\n\n我们知道，当前人工智能的算法大多数是基于概率的，会涉及到概率论、统计学等各种数学理论体系。同时我们也知道，人工智能离不开数据，从理论上来说，数据越多，人工智能算法效果越好，会无限趋近于99.999999.......%，但因为是基于概率的，所以永远不可能达到100%，这也是当前人工智能大多只能用来辅助人类决策，而不能代替人类做决策的原因。当然随着科技的进步和人工智能的不断发展，未来也可能真的可以代替人类来做一些决策。\n\n**下面将逐一介绍深度学习、迁移学习和强化学习。**\n\n## 深度学习\n\n大数据造就了深度学习，通过大量的数据训练，我们能够轻易的发现数据的规律，从而实现基于监督学习的数据预测。\n\n基于神经网络的深度学习（包括CNN、RNN、DNN），主要解决的领域是图像、文本、语音等，问题聚焦在分类、回归。然而这里并没有提到推理，显然我们用之前的这些深度学习的知识无法造一个AlphaGo出来。\n\n![](1.png)\n\n上面这张图是在2016年的 NIPS 会议上，吴恩达 给出了一个未来 AI方向的技术发展图，还是很客观的。\n\n毋庸置疑，监督学习是目前成熟度最高的，可以说已经成功商用，而下一个商用的技术 将会是迁移学习（Transfer Learning），这也是Andrew预测未来五年最有可能走向商用的 AI技术。\n\n## 迁移学习\n\n迁移学习也可看作是举一反三，它本质上是**用相关的、类似的数据来做训练，然后通过迁移学习来实现该模型本身的泛化能力**，它所要解决的问题是如何将学习到的知识从一个场景迁移到另一个场景。\n\n就拿图像识别来说，迁移学习是指从识别自行车到识别汽车，从识别中国人到 识别外国人……\n\n![](2.jpg)\n\n下面再借用一张示意图（*图片来源：A Survey on Transfer Learning*）来进行说明：\n\n![](3.png)\n\n实际上，你可能在不知不觉中使用到了迁移学习，比如所用到的预训练模型，在此基础所做的Fine-Turning，再比如你做目标跟踪Tracking所用的online learning。\n\n**迁移学习的价值体现在：**\n\n1、一些场景的数据根本无法采集，这时迁移学习就很有价值；\n\n2、复用现有知识域数据，已有的大量工作不至于完全丢弃；\n\n3、不需要再去花费巨大代价去重新采集和标定庞大的新数据集；\n\n4、对于快速出现的新领域，能够快速迁移和应用，体现时效性优势；\n\n**关于迁移学习算法的实践总结：**\n\n1、通过原有数据和少量新领域数据混淆训练；\n\n2、将原训练模型进行分割，保留基础模型（数据）部分作为新领域的迁移基础；\n\n3、通过三维仿真来得到新的场景图像（OpenAI的Universe平台借助赛车游戏来训练）；\n\n4、借助对抗网络 GAN 进行迁移学习 的方法；\n\n## 强化学习\n\n强化学习的全称是 Deep Reinforcement Learning（DRL），其所带来的推理能力，是智能的一个关键特征衡量，真正的让机器有了自我学习、自我思考的能力。目前强化学习主要用在游戏 AI 领域，最出名的案例应该是AlphaGo的围棋大战。\n\n实际上，强化学习是一种探索式的学习方法，通过不断地 “试错” 来得到改进，**不同于监督学习**的地方是，强化学习本身没有Label，每一步的 Action 之后它无法得到明确的反馈（在这一点上，监督学习每一步都能进行Label 比对，得到 **True** or **False**）。\n\n强化学习中由环境提供的**强化信号**是Agent对所产生动作的好坏作一种评价（通常为标量信号），而不是告诉 Agent 如何去产生正确的动作。由于外部环境提供了很少的信息，Agent 必须靠自身的经历进行学习。通过这种方式，Agent在行动逐一评价的环境中不断获得知识，改进行动方案以适应环境。\n\n**基本原理：**\n\n首先Agent选择一个动作用于环境，环境接受该动作后状态发生变化，同时产生一个强化信号(奖或惩)反馈给Agent，Agent根据强化信号和环境当前状态再选择下一个动作，选择的原则是使受到正强化(奖)的概率增大。如果Agent的某个行为策略导致环境正的奖赏(强化信号)，那么Agent以后产生这个行为策略的趋势便会加强。\n\nAgent学习的目标是通过**动态地调整参数**，以达到强化信号最大，也就是在每个离散状态发现最优策略以使期望的折扣奖赏和最大。\n\n强化学习是通过以下几个元素来进行组合描述的：\n\n> **对象（Agent）**\n\n也就是我们的智能主题，比如 AlphaGo。\n\n> **环境（Environment）**\n\nAgent 所处的场景－比如下围棋的棋盘，以及其所对应的状态（State）－比如当前所对应的棋局。\n\nAgent 需要从 Environment 感知来获取反馈（当前局势对我是否更有利）。\n\n> **动作 (Actions)**\n\n在每个State下，可以采取什么行动，针对每一个 Action 分析其影响。\n\n> **奖励 (Rewards)**\n\n执行 Action 之后，得到的奖励或惩罚，Reward 是通过对环境的观察得到。\n\n通过强化学习，我们得到的输出就是：Next Action，也就是下一步该怎么走，这其实就是 AlphaGo 的棋局。","tags":["人工智能技术"],"categories":["人工智能"]},{"title":"大数据基础知识介绍","url":"/2021/04/29/bigdata/","content":"\n## 什么是数据洞察\n\n### 基本定义\n\n在说数据洞察前，我们先来阐述下数据分析/数据挖掘/数据洞察这几个词的定义。\n\n- 数据分析（Business Analysis）：传统定义的数据分析，一般通过SQL/Python/Excel等工具汇总数据，结合对业务的理解和经验，主要是由人将数据转换为信息；\n- 数据挖掘：一般通过建模来挖掘数据内在的关联和信息，主要是机器从训练集中发现一定的规律，从而将数据转换为信息；\n- 数据洞察：通过数据分析/挖掘，将数据转换为信息，结合业务场景，梳理出影响业务结果的因素和作用链路，从而正确地对于问题进行归因和得出改进的方向。\n\n所以我们可以看出数据分析和数据挖掘是殊途同归的，最终都收归于数据洞察的体系中。\n\n### 如何理解数据洞察\n\n可能上面关于数据洞察的定义还有一些晦涩，不好理解，接下来我说说我个人的理解：\n\n- 数据分析和数据挖掘更加偏向于数据处理的手段，通过业务或者机器的方式将数据加工成一些信息 ，比如：啤酒和纸尿裤放在销售量比单卖要高；用户喜欢在夏天到来时才购买游泳装备等等。\n- 而数据洞察更强调的对多种信息的加工和处理 —— 结合业务场景，产出对于业务发展有价值的结论。\n\n既然数据洞察的目的是推动业务的发展，那么就需要我们以业务为导向，关注业务中实际遇到的需求或者问题。并且在得出结论后，能够产生可落地的action，去验证和迭代我们的结论，从而推动业务的发展。\n\n我们用一张图来描述下数据洞察的一个完整链路 ：\n\n![](1.jpg)\n\n**数据洞察有三要素：数据、业务场景、标准**\n\n- 数据：我们得出的结论要基于数据，避免受到个案或者特例的影响 ；\n\n- 业务场景：少了业务场景，就无法理解孤立的数据对于业务的实际意义；\n\n- 标准：结合业务场景，我们才能对于数据的好与坏制定出标准，比如说身高150对于成年男性可能不算高，但是对于小学生来说却是很高了；\n\n### 如何做数据洞察\n\n以上我们了解了数据洞察的一些基本概念，接下来我们来讲讲如何实际操作。\n\n![](2.png)\n\n图上步骤主要分为以下几个层级：\n\n1、业务层：结合业务的问题和需求，先定义需要哪些数据，以及这些数据在场景中的含义\n\n2、数据层：通过数据埋点上报、业务数据库同步等方式获取业务所需的数据，进行相应的数据清洗，避免脏数据的影响；将数据进行合并和整理，便于分析；\n\n3、分析层：通过数据分析或数据挖掘的手段从数据中获取规律、现象或者数据模型\n\n4、输出层：结合分析层得到的信息和业务场景，输出洞察结论，制定行动计划；在行动后根据新产生的数据验证之前得到的结论的有效性，进行迭代；\n\n**最终通过以上的循环，我们可以不断地积累不同业务场景下的洞察结论。**\n\n> 通过对数据洞察的了解 ，我们可以发现，数据洞察与业务的结合是非常紧密的 。每个洞察结论离开了其背后的业务场景可能都是无效的。所以数据洞察不存在“银弹“或者“万金油”，我们还是要通过不断地实操进行场景上的积累 ，从而提升数据洞察力。\n\n## 闲聊OLTP/OLAP\n\n企业日常的各个环节都会产生数据，一个企业从小到大的过程中，建设IT系统的时刻是一个分隔点。但在此之前，数据零散分布在邮箱、发票、单据、APP等各种地方。当企业规模达到一定程度时，则必须要建设IT系统，此时，数据开始在各种系统（ERP、CRM、MES等）中积累。\n\n数据自身的价值随着其体量不断的累积在一直增加，所以通常我们也会把企业自身产生的有价值的数据称之为企业数据资产。\n\n企业通过从数据中获取的知识，能够帮助企业发现问题与机遇并进行正确的决策，以达到赢得市场之目的，而数据分析则是实现以上目标的重要手段之一。\n\n数据分析体系的建设往往是在初次进行信息化建设后某个时间开始，数据分析体系与其他业务类系统有着显著的不同：\n\n1、业务类系统主要是供基层人员使用，进行一线业务操作，通常被称为OLTP（On-Line Transaction Processing，联机事务处理）。\n\n2、数据分析的目标则是探索并挖掘数据价值，作为企业高层进行决策的参考，通常被称为OLAP（On-Line Analytical Processing，联机分析处理）。\n\n3、从功能角度来看，OLTP负责基本业务的正常运转，而业务数据积累时所产生的价值信息则被OLAP不断呈现，企业高层通过参考这些信息会不断调整经营方针，也会促进基础业务的不断优化，这是OLTP与OLAP最根本的区别。\n\n4、一般来说，OLAP不应该对OLTP产生任何影响，在理想情况下，OLTP应该完全感觉不到OLAP的存在。\n\n## 数据湖与数据中台\n\n### 先说数据湖\n\n数据湖（Data Lake）概念的提出时间仅次于大数据，可以说是一个很老的概念了，它最早是在2011年由CITO Research网站的CTO和作家Dan Woods所提出，其比喻是：如果我们把数据比作大自然的水，那么各个江川河流的水未经加工，源源不断地汇聚到数据湖中。\n\n**数据湖的定义**（*来自维基百科*）：\n\n数据湖（Data Lake）是一个以原始格式存储数据的存储库或系统，它按原样存储数据，而无需事先对数据进行结构化处理。一个数据湖可以存储结构化数据（如关系型数据库中的表）、半结构化数据（如CSV、日志、XML、JSON）、非结构化数据（如电子邮件、文档、PDF）和二进制数据（如图形、音频、视频）。\n\n数据湖本质上就是一个大数据平台，它随着大数据技术的不断完善，目前成熟的数据湖体系已具备了大数据存储、大数据处理、机器学习、大数据分析等能力。国外公司像亚马逊的AWS、Informatica、IBM、微软等都有数据湖的相关产品和解决方案，而在国内，目前这方面的产品和方案还很少见。\n\n### 再谈数据中台\n\n其实数据中台是咱们中国人自己创造的一个概念，在国外并没有太多人谈数据中台。但即使如此，在国内目前也还没有对数据中台形成一个统一的认知和标准的定义。\n\n1、“中台”的鼻祖——阿里巴巴对数据中台的定义：\n\n数据中台是数据+技术+产品+组织的组合，是企业开展新型运营的一个中枢系统。具象地说，它是一套解决方案，抽象的理解，它是一种新的公司运营理念。\n\n2、数澜科技对数据中台的理解：\n\n数据中台是让数据持续用起来的一套机制，经过业务数据化、数据资产化、资产服务化，并在有权限管理的情况下以API的方式开放出去。\n\n### 它们之间的关系\n\n在大数据时代，随着数据量的不断增加，数据形式也越来越复杂，而以数据仓库为代表的、现有的数据存储和处理方式已无法满足海量、多样的数据处理需求，在这样的背景下产生了“数据湖”，数据湖是将复杂的事物具象化，以一个形象的名字，来反应它在大数据存储和处理方面的优势和能力。\n\n数据湖作为一个**集中的存储库**，可以在其中存储任何形式、任意规模的数据。在数据湖中，可以不对存储的数据进行结构化，只有在使用数据的时候，再利用数据湖强大的数据查询、处理、分析等能力组件对数据进行处理和应用。因此，数据湖具备运行不同类型数据分析的能力。\n\n而数据中台**从技术层面承接了数据湖**，它通过数据技术，对海量、多源、多样的数据进行采集、处理、存储、计算，同时统一标准，以标准形式进行数据存储，**形成大数据资产**，以满足前台数据分析和应用的需求。\n\n总的来说，**数据中台更强调应用，离业务更近，强调服务于前台的能力**，实现逻辑、算法、标签、模型、数据资产的沉淀与复用，能够更快速的响应业务和应用开发的需求，且可追溯、更精准。","tags":["大数据技术"],"categories":["大数据"]},{"title":"更改Windows系统PowerShell的界面配色","url":"/2021/04/04/powershell/","content":"\n先附一张最终效果图\n\n**（使用的是campbell配色，然后我自己更改了一下透明度和字体大小）**\n\n![](1.jpg)\n\n好了，接下来上教程：\n\n首先，点击**[下载文件](https://pan.baidu.com/s/1ryWwSqNkliA0j9l0t8NN_w)**（密码：**fd22**）\n\n然后，**解压至任一文件夹**，最好放到一个英文目录下，以后最好能够找到，因为不喜欢配色的话还可以去修改。\n\n![](2.jpg)\n\n然后在**当前目录下打开windows powershell**，这里提供一个**快捷打开方式**：在当前目录下，按住shift键，单击鼠标右键，然后在弹出的菜单中，选择在此处打开powershell。\n\n![](3.jpg)\n\n最后在命令行输入 \n\n```javascript\ncolortool -b campbell\n```\n\n如果提示出错什么的，请修改为\n\n```javascript\n.\\colortool -b campbell\n```\n\n注意：**campbell为schemes目录下的文件名，就是一个配色方案，可以根据自己的喜好修改为其他方案**\n\n好了，最后，献上[官方地址](https://blogs.msdn.microsoft.com/commandline/2017/08/11/introducing-the-windows-console-colortool/) ，到这里就结束了！","tags":["windows","powershell"],"categories":["windows系统"]},{"title":"浅谈RTSP和RTMP流媒体协议","url":"/2020/05/13/rtsp-rtmp/","content":"\n# 流媒体协议一览\n\n流媒体协议是服务器与客户端之间通信遵循的规定，当前网络上主要的流媒体协议如下表所示：\n\n| 名称     | 推出机构       | 传输层协议 | 客户端   | 目前使用领域    |\n| -------- | -------------- | ---------- | -------- | --------------- |\n| RTSP+RTP | IETF           | UDP        | VLC, WMP | IPTV            |\n| RTMP     | Adobe Inc.     | TCP        | Flash    | 互联网直播      |\n| RTMFP    | Adobe Inc.     | UDP        | Flash    | 互联网直播      |\n| MMS      | Microsoft Inc. | TCP/UDP    | WMP      | 互联网直播+点播 |\n| HTTP     | WWW+IETF       | TCP        | Flash    | 互联网点播      |\n\n# RTMP协议简介\n\nRTMP，全称Real Time Messaging Protocol，实时消息传输协议，是TCP/IP协议体系中的一个应用层协议，该协议基于TCP传输，包括RTMP基本协议及RTMPT/RTMPS/RTMPE等多种变种。RTMP是一种设计用来进行实时数据通信的网络协议，主要用来在Flash/AIR平台和支持RTMP协议的流媒体/交互服务器之间进行音视频和数据通信。支持该协议的软件包括Adobe Media Server/Ultrant Media Server/red5等。RTMP与HTTP一样，都属于TCP/IP四层模型的应用层。\n\n# RTP/RTCP协议简介\n\nRTP：实时传输协议；RTCP：实时传输控制协议。\n\nRTP被定义为传输音频、视频、模拟数据等实时数据的传输协议，与传统的注重的高可靠的数据传输的运输层协议相比，它更加侧重的数据传输的实时性。此协议提供的服务包括数据顺序号、时间标记、传输控制等。\n\nRTP通常与传输控制协议RTCP一起工作，RTP只负责实时数据的传输，RTCP负责对RTP的通信和会话进行带外管理（如流量控制、拥塞控制、会话源管理等）。\n\nRTP位于传输层之上，应用层之下，默认是基于UDP传输数据。具体传输流程：实时语音、视频数据经过模数转换和压缩编码处理后，先送给RTP封装成为RTP数据单元，RTP数据单元被封装为UDP数据报，然后再向下递交给IP封装为IP数据包。\n\nRTP分组只包含RTP数据，而控制是由配套协议RTCP提供。\n\n# RTSP协议简介\n\nRTSP，全称Real Time Streaming Protocol，实时流传输协议，是TCP/IP协议体系中的一个应用层协议，该协议定义了一对多应用程序如何有效地通过IP网络传送多媒体数据。\n\nRTSP在体系结构上位于RTP/RTCP之上，它使用UDP完成数据传输。\n\nHTTP与RTSP相比，HTTP传送HTML，而RTSP传送的是多媒体数据。HTTP请求由客户机发出，服务器作出响应；而使用RTSP时，客户机和服务器都可以发出请求，所以RTSP可以是双向的。\n\n# RTMP和RTSP对比\n\n**RTMP，实时消息传输协议**\n\n- 是应用层协议\n- 是流媒体协议\n- 基于TCP协议传输\n- 是Adobe的私有协议，未完全公开。\n- 依赖flash player作为播放器\n- 一般传输flv，f4v格式流\n- 一般在TCP1个通道上传输命令和数据\n\n**综合评价：**\n\n1. 由于是基于TCP协议传输，所以RTMP不会丢包，但会有积累延迟：当网络状态差时，服务器会将包缓存起来，导致累积的延迟；待网络状况好了，就一起发给客户端。这个的对策就是，当客户端的缓冲区很大，就断开重连。\n2. 由于互联网环境相对较差，采用RTMP保证了视频的传输质量，但是其传输延迟相对较高，传输效率相对较低。 \n\n**RTSP，实时流传输协议**\n\n- 是应用层协议\n- 是流媒体协议\n- 是共有协议，有专门机构做维护。\n- 基于UDP协议传输\n- 一般传输ts，mp4格式流\n- 一般需要2~3个通道上传输，命令和数据通道分离。\n\n**综合评价：**\n\n1. RTSP+RTP经常用于IPTV领域。因为其采用UDP传输视音频，支持组播，效率较高。但其缺点是网络不好的情况下可能会丢包，影响视频观看质量。\n2. 由于互联网网络环境的不稳定性，RTSP+RTP很少用于互联网视音频传输。互联网视频服务通常采用TCP作为其流媒体的传输层协议，因而像RTMP，MMS，HTTP这类的协议广泛用于互联网视音频服务之中，这类协议不会发生丢包，因而保证了视频的质量，但是传输的效率会相对低一些。\n","tags":["流媒体协议"],"categories":["网络通信"]},{"title":"《幕后产品：打造突破式产品思维》之精华提炼","url":"/2020/03/04/behind-prod/","content":"\n本书作者是网易云音乐产品经理，全书围绕网易云音乐的产品设计展开，里面有大量的实战经验和总结，每个产品细节的功能都是在大量思考和权衡下做出的最终决策，相较其他一些只谈理论的书，这本书是非常接地气了。\n\n本书共有10个章节，下面将对每章中的精华部分做相应摘抄和提炼。\n\n# 第1章 产品经理的四个素质\n\n本章作者开篇给出了产品经理的四个素质——创业精神、终身学习、善于联想、善于决断。作者认为一个产品经理如果没有创业心态，是无法克服一个又一个的困难，最终做出优秀的产品的。紧接着作者谈到求知心态，他认为产品经理本身的工作会涉及到很多的领域，应注重平时的积累，不要看太多入门书、大而全的书。随后作者提到产品经理向上发展的关键能力之一：联想（洞察力、归纳力、联想力），善于联想能够让产品经理更具创造性地设计产品、满足用户需求。最后说到了产品经理应具备的善断能力，并以网易云音乐的导入歌单功能为例，讲述如何降低用户在更换一款音乐APP时的迁移成本，以及上线了导入歌单功能后的燎原之势。作者认为创业和求知是决定了产品经理的高度，而联想和善断则会帮助产品经理向上发展。\n\n## 经典语录\n\n- 优秀的产品经理会不断地尝试通过自己的努力去影响他人、解决问题、完成目标，而非坐看这个产品烂掉。\n\n- 汝果欲学诗，功夫在诗外。\n\n- 善断不仅需要勇气和决心，更需要严谨的方法：首先要抓住重点，其次是不追求完美，最后还要有实验意识（A/B测试——建议仅在“影响大、选择难”的时候才使用）。\n\n# 第2章 如何全面深入地了解用户\n\n本章主要介绍一些做用户研究的方法论，其中谈到了亲力亲为，这个方法比较适用在移动互联网的产品上，因为这类的产品迭代周期和给予的决策时间都会比较短，如果产品经理还按照传统的用户研究方法，每次都向用研团队提需求，拿结果，时间上是不允许的。所以为了快速研究用户，产品经理必须要亲力亲为。本章最后对关于如何做一片产品的用户（换句话说，产品经理如果遇到自己不太感兴趣的领域，该如何去理解用户、理解需求），作者梳理了自己在工作中的一些经验，比如培养同理心、发展多方面的兴趣等，认为做产品正如体验人生。\n\n# 第3章 需求分析方法论\n\n本章主要说产品经理在面对众多需求的时候，该如何淡然处之，那这其中就要掌握一些需求分析的方法和具备一定的沟通能力。做需求分析，第一步就是要先收集需求，作者认为需求也是符合二八原则的，即80%的人提出的都是20%的需求，但产品经理应该对剩下80%的长尾需求投入更多的精力（此处以网易云音乐的导入歌单需求举例论证）。其次是分析这些需求背后的动机以及实现这些需求会带来的利弊，作者通过解释网易云音乐为什么没有做场景电台（其他类似产品都有）来切入说明。接着作者又介绍了一个经典的需求分析方法：角色、场景、流程，该方法通常会被应用在比较复杂的大需求上：有多个角色、有复杂的使用场景、使用流程比较长。最后通过举网易云音乐导入歌单功能的例子，来说明如何在产品上实现差异化竞争。\n\n## 经典语录\n\n- 就算是一时最不靠谱的需求，在产品所处的时间、环境等变化后，也可能会变得有用。\n\n- 在一个充分竞争的市场环境中，越是主流的需求，越是被充分挖掘，也就越显得竞争力不够。而那些尚未被发掘的需求，才是可能创新的所在。\n\n- 实现产品需求，不能光满足用户，还需要满足产品的利益，这就是产品经理在其中所做的权衡与抉择。\n\n- 差异化竞争更有效的办法是深入地思考用户的需求重点、竞争对手真正薄弱的地方、自己能发挥巨大优势的地方，并将这三者结合起来。\n\n# 第4章 产品经理的基本功\n\n本章一开始就给出了产品经理的技能树，技能树共分为3个时期：1~3年基础期、3~7年资深期、7年以上顶级期，每个时期的技能要求自然也不一样。作者以头条系产品为例，认为头条对流量ROI的运用纯熟度与效率很高，而流量运作又非常依赖大数据和算法，所以催生出头条系产品的方法论基本上是构建在数据和算法上的。在本章中，作者认为产品经理还应具备一定的交互设计能力，其交互设计最关键的是考虑用户认知和使用场景。最后，作者讲述产品经理具备一定审美能力的重要性，这其实也是我目前所欠缺的能力，所以重点拜读了一下。作者认为审美能力是厚积而薄发的，不能急功近利，心态不好反而会适得其反。\n\n![](1.jpg)\n\n## 经典语录\n\n- 用户是很“懒”的，用户在同一时间只能理解一件事情，用户的耐心通常只有几秒，用户是冲动的，用户是“贪心”的（爱占小便宜）。\n\n- 审美能力对产品的影响范围分为三层：视觉/体验层、用户行为/产品层、价值观/世界观层。\n\n- 如果我们希望用户参与进来，那么一个产品其实就是一个世界。游戏是一个世界，社区是一个世界。在一个世界中，就需要有价值观、世界观。我们的审美观会影响我们的价值观，进一步影响我们所创造产品的品质。\n\n# 第5章 在激烈的竞争中寻找产品定位\n\n在第3章的时候，作者谈到如何做产品的差异化竞争，归结起来，也就是如何找准自己的产品定位，而产品经理对产品定位的把我需要大量的经验积累，其中行业市场分析是一个源头，也是最关键的部分。接着作者以豆瓣为例，讲述如何分析市场的竞争局面，他认为在分析市场时，应从三个方面去考虑：1、分析市场的上下游，下游市场在用户基础变大之后，势必会向上游发展，从而更多地影响整个行业；上游市场在掌握了资源后，也势必会向下游发展，去拓展更多的渠道。它们在充分竞争后会达到一个平衡。2、探寻非零和市场，作者此处推荐了一本书《从0到1：开启商业与未来的秘密》。3、分析市场中的变化机会，这个市场未来的变化是怎样的，以及应该如何抓住机会。最后作者介绍如何在市场中找到产品切入点，他认为在做新产品寻找切入点的时候，有两个关键之处：细分和新兴，也就是要找到细分市场，且要有一定的前瞻思维。\n\n# 第6章 好的思维方式\n\n作者认为产品经理在往更高层面发展时，需要能够做到深度思考。本章作者分享了四个思维方式：往重点思考、往本质思考、往上层思考、往不同思考。\n\n往重点思考可以分为几个环节：思考关键目标、思考实现关键目标的关键行动、思考关键行动的关键依赖，然后加以权衡。如果发现关键的东西还很多，那么就要考虑哪些是可以放弃的（学会放弃也很重要）。\n\n往本质思考，即透过现象看本质。此处作者分享了他个人的几点体会：跳出惯性思维（保持好奇心）、一层一层往下多提问、日常实践并与人交流。\n\n往上层思考可分为几个部分：看上层的格局和眼界、思考上层与本层之间的逻辑关系、想象未来的可能性。\n\n往不同思考，作者认为这是一个人非常难能可贵的思维方式，目前也就只有乔布斯和查理芒格有这样的思维方式，并推荐了一本书《穷查理宝典：查理·芒格智慧箴言录》。接着他分享了自己通过实践获得的关于“往不同思考”一些深刻的体会：客观地思考不同、逆向思维、捕捉创新、形成自己独特的思维框架。\n\n## 经典语录\n\n- 思维方式很重要，好的思维方式能让人快速抓住重点、抓住问题的本质、抓中做大/做强的思路。\n\n- 如果我们只思考产品功能设计等表现层，而对业务模式、商业模式等的深度思考较少，那么创新从何而来？\n\n- 学会多问为什么，有助于产品经理跳出现有的思维框架，帮助自己在目标层面思考得更深入，从而找到真正的聚焦点。这应当是一个“先发散，后收敛”的过程。\n\n- 对于一个产品经理来说，最重要的不是学习别人的方法论，而是通过自己的用户洞察能力，敏锐地捕捉到用户需求和商业机会，同时进行深度思考，找到解决思路，不断地总结和迭代自己的方法论并形成闭环，这才是真正重要的事情。\n\n- 乔布斯总能有超出常人的关于产品非常简单而又引领未来的想法；而查理·芒格的逆向思维则非常与众不同，当其他人想着如何成功时，他会思考如何避免各种各样的失败。\n\n- 什么是客观地思考不同呢？就是当我们在思考不同时，要想一想背后的逻辑是否站得住脚，是否是客观存在的，而不只是自己想象臆断的。\n\n# 第7章 产品架构能力\n\n一个好的产品架构（如微信），虽然囊括的功能非常多、涉及的业务非常多，但对于绝大部分用户来说，可以获得一个简单、流畅、清晰的体验；而不好的产品架构则可能会让用户迷路，散乱、冗余感比较强。作者首先提到架构要点：用户易理解、高效易用、尽量简练、扩展性强，其中关于用户易理解这个点，作者以大众点评APP来举例，抛出一个问题：在大众点评首页上方的工具栏中，同时有“美食”和“外卖”两个入口，而在通过“美食”入口进入的页面中，顶部也有“外卖”入口。单从逻辑上来看，美食可以有到店和外卖两种方式，外卖可以隶属于美食下面。那么该APP的首页为何会这么设计呢？此处省略100字...... 作者认为人的天性是懒惰的，让用户在使用产品时的学习成本降低，用户的体验就会很爽。此处，我个人认为，没有完美的产品架构，只有爽快的用户体验。最后作者讲述了信息架构、产品架构和业务架构这三者之间的关系，他认为，业务架构是内核、产品架构是骨架、信息架构是肌理脉络。\n\n## 经典语录\n\n- 在学习培养架构能力的过程中，从交互设计、信息架构开始打好基础，不断地练习、实践，直至熟练掌握产品架构、业务架构，进而深度思考战略架构。\n\n- 产品经理应竭尽全力地让用户能够清晰、方便地找到他们所需要的信息，有时不需要为产品架构做出完美的逻辑，千万不要只为了分类聚合而做产品架构。\n\n- 简练的架构就是将不同类型的需求和功能通过统一的架构组织起来，抽象和通用性是其关键之处，但需要注意的是，我们不能过度追求架构简练，所有的架构都应该满足用户需求和商业需求。有些不能抽象和做成通用功能的模块，就不要去做，过度的抽象会让用户不理解。其中的度需要我们不断地对用户的真实使用场景做测试和研究来把握。\n\n- 最美的架构应是能够用非常简单的话语就阐释清楚的，而不是只有专家才能理解的复杂局面。\n\n- 信息架构是最前端的表现层架构，产品架构是连接业务与用户表现层的产品功能、系统的架构，业务架构则是包含商业逻辑在内的业务运转机制的架构；如果反过来看，其实是从业务架构一步步推导出信息架构的，从而以前端的表现层呈现在用户面前。\n\n![](2.jpg)\n\n# 第8章 懂运营和营销\n\n作者认为如果一个产品经理不具备运营、营销知识，会很快遇到成长瓶颈，在产品从0到1的过程中需要产品、运营、营销三者齐头并进。产品经理通常会具有系统思维，但不一定拥有经营思维，其实具备经营思维也同样重要，接着作者给出了应用经营思维的三个方面：经营用户流量、经营资源、经营价值链。\n\n**经营用户流量的常用招数：**\n\n1、思考用户是谁、研究他们在哪里。\n\n2、寻找热点机遇、赚取流量红利。\n\n3、裂变传播，且要有创新玩法，一群理性派是没办法做出吸引人的社交裂变传播的。\n\n**经营资源的常用思路：**\n\n1、识别资源，要能够灵活、聪明地看待、运用自己拥有的资源。并举了一个例子——网红公司在起步时撮合网红和品牌对接的生意，其实不一定要签约网红才算拥有网红资源，与网红合作也能达到一样的效果。网红有粉丝流量，但未必擅长做与品牌对接、商务合作的事情，因此公司可以将商务谈判能力视为资源，然后寻找缺乏这个资源的网红，再打包寻找有投放广告需求的品牌。\n\n2、整合运用资源，本质是要思考各个资源之间如何配合并产品1+1大于或等于2的效果，其前提就是弄明白各资源的接口（所需要的输入以及能提供的输出）。这里仍以网红公司举例，如果网红公司不能持续提供新的网红，品牌广告主很可能绕过网红公司而自己联系网红。但如果这时候想到网红还有开淘宝店来变现的诉求，而运营淘宝店是一件很费时间的时间，且现在有专业的淘宝代运营人才，则网红公司可以考虑整合淘宝代运营人才来服务更多网红。\n\n3、资源的投入/产出，这里提到产品经理应注意的三个地方：一是要评估资源投入的ROI，二是要避免成为一个功能型产品经理，而应做业务型产品经理，三是要有多条腿走路的经营意识，避免将资源鸡蛋只装在一个篮子里，当然在业务发展明朗后，我们需要再调配资源做重点方向的重点投入，加快业务成长。\n\n**经营价值链：**\n\n一门生意一般来说脱离不了供应链、研发、生产、营销、销售、服务等环节。产品、研发部门生产出产品，经过运营部门培育状态或变成服务，再经过营销部门宣传，最终产生营收。经营价值链就是使这个过程最大限度地实现营收。作者在这里推荐了一本讲竞争战略的书，由价值链概念提出者迈克尔·波特的著作《竞争优势》。\n\n最后作者谈到了品牌的重要性，他认为产品会随着时间流逝经理一个生命周期，从出生到成熟、顶峰，尔后进入衰退期，但品牌是可以超越产品兴衰的限制，能在用户眼中持续更久。\n\n## 经典语录\n\n- 在互联网上，除了流量、资金外，我们的股东、品牌、团队、能力、时间、预期、合作伙伴、竞争对手等都是资源，在经营过程中我们需要有意识地识别它们。\n\n- 如果要将产品高价卖出，则需要相当大的品牌溢价，这在互联网行业中是非常难的（互联网本身就具有普惠性质），相对来说不太可行，因此经营价值链从而不断提高效率、降低成本就十分重要。\n\n- 越是性格分明还带点极端的品牌，越容易与外界划清界限，也就是说喜欢的人很喜欢、讨厌的人很讨厌。因为品牌用户心智一旦建立起来，想要更改是困难而漫长的事情，所以我们最好在初期就构思好我们的品牌边界是泾渭分明的，还是包容性强一些的。\n\n- 在互联网行业中，我更倾向于包容性强一些的品牌边界，因为互联网的特性是连接和规模化，同时行业变化太快，如今的泾渭分明三五年后可能就会导致品牌无法革新、进步而被淘汰。\n\n- 人对自我的探索和表达是无限的，是永不停止的，如果让用户在玩的过程中能沉浸到探索和表达中，那么就会引发用户的共鸣，用户就会很乐意自发地分享。\n\n# 第9章 产品负责人的三个能力\n\n作为一个产品负责人，作者认为应在三个方面逐步地培养和提升：商业嗅觉及推理能力、业务架构及创新能力、善于沟通及领导能力。其中关于商业嗅觉，作者理解它是一种对扩张和赢利的敏锐直觉，无论是做用户规模业务还是营收业务，都应该拥有对扩张的敏锐直觉。接着作者以网易云音乐做评论功能为例来阐述他上述的观点，网易云音乐之所以做评论功能，是出于商业营收上的考虑（以广告作为收入来源之一）。当增加了评论功能后，可让用户养成边听音乐边看评论的习惯，大大增加用户眼球停留在APP上的时长，从而就让网易云音乐拥有了更多的想象空间。然后又剖析了今日头条的高段位打法：利用资讯个性化+视频与其他新闻资讯产品竞争，以至后面又做了头条号（瞄准了微博和微信的定位），把自己变成一个泛内容平台，吸引用户更多的碎片时间。\n\n当产品发展到中期的时候，业务开始变得复杂，同时关注的目标会多起来，此时业务架构就是梳理清楚各个业务之间驱动轮和从动轮分别是什么、如何协同、如何输入/输出、如何将各自的目标完成并且共同服务于大目标。总体来说，业务架构包含两个方面：目标的拆解与分析、各业务是如何服务各目标的以及各业务间的依赖关系是怎样的。作者对网易云音乐的产品架构进行剖析，提到两种思考方式，一种是自上而下的，从目标到业务架构；一种是自下而上的，从某个业务如何做到发散开来。这两种思考方式都很重要，最终它们会在中间相遇、结合，形成一个整体。\n\n![](3.jpg)\n\n接着作者谈到创新能力，他认为在互联网世界里，绝对的创新（即100%创新）是非常难的，他对于互联网产品的创新有两方面理解：\n\n1、联想、借鉴、举一反三，善用他山之石形成自己产品的创新。\n\n2、让用户形成对**产品新特性**的认知。\n\n作者以网易云音乐评论功能为例，阐述这一创新带来用户新的认知。从建立用户认知上，产品、运营、营销本质上是同一种角色，只是在具体做的事情上有一些区分而已。只有这三个维度通力协作、布局，形成合力，才能更好地打通用户认知。\n\n最后作者认为产品负责人在带团队方面，不能有个人英雄主义，应依靠团队的力量，善于向团队提问，给团队赋能等，从而营造一个良好的团队氛围。在这其中谈到了我们常用的头脑风暴，作者认为头脑风暴应当仔细挑选参与的人，然后让每个参与者事先独自思考一段时间，在产生了一定的想法之后再来参与共创，然后在共创的碰撞和思考中激发更多的创意。在此过程中，也更容易观察到哪些成员拥有更好的深度思考特质、哪些成员能更好地运用发散思维，并把大家的特长结合起来。\n\n## 经典语录\n\n- 如果把这里的商业嗅觉抽象出来，即在扩张用户规模时扩展领域，而非在原有领域上过多纠缠。\n\n- 关于扩张最重要的就是要明确产品的核心和边界。\n\n- 如果在一个注意力时间的商业模式中有30%~50%的普通付费用户、5%的高付费用户，那就是比较健康的。\n\n- 作为产品经理，需要在平时的工作和生活中多去钻研大大小小不同的商业模式，分析其中的逻辑，找到其中有共性的部分，然后在实际工作中不断地思考应用来培养自己的商业嗅觉。\n\n- 在挖掘业务深度的阶段（通常是产品从0到1的阶段，或者是拓展新业务的阶段），产品经理不能过于依赖这些业务架构的逻辑思维，还是应该先深入业务，再运用架构思维，以达到最好的效果。\n\n- 有时候用户想得很简单，哪怕只是一些微小层面上的改动也可能对他们的体验产生很大的影响，这些小小的心思在他们看来就是创新。\n\n- 想要给用户不同的感受，就需要一些打破常规的思维方式，可以与市场营销人员、段子手、设计师等“脑洞”比较大的人一起工作，他们的“脑洞”通常会帮助我们开拓自己的思维。\n\n- 太独断则目盲，太兼听则寡断，其中的平衡点会随着自身的经验和阅历增长而逐渐清晰，这是一种人生经验，也适用于产品之道。\n\n- 产品经理应当以产品的想法和创意为主，构建对业务有重要促进作用的产品形态。沟通、项目推进等任务也需要，但它们不能体现产品经理最核心的价值，不应占据产品经理日常工作的重要时间。\n\n- 深度思考和创新能力是培育出来的，而非压迫出来的。\n\n# 第10章 产品之路时学时新\n\n本章作者分享了其自身的经历以及互联网上那些做出了不起产品的人身上观察分析而得出的一些经验总结。\n\n作者认为我们首先应有一个积极开放的心态，而且又要能够辩证地看待自己。开放心态和辩证看待自己是矛盾与和谐之间的一种统一，何时调整自己，何时坚持自己，古人云，“尽信书不如无书”，我们要沉下心来，静静而深入地思考我们看不见的地方。\n\n其次我们在遇到瓶颈时，如何去突破它。作者通过审视自身的经历，发现有规律可循：遇到瓶颈 > 观察当前现实 > 感知其他信息 > 放下纠结 > 内心的自然流现 > 接纳自己的改变 > 创造新的想法 > 形成新的行动 > 突破瓶颈。这个规律接近U型理论，U型理论与儒学经典著作《大学》的思想几乎如出一辙：“知止而后有定，定而后能静，静而后能安，安而后能虑，虑而后能得”。\n\n最后我们应能让自己真正做到自省，而不是知道了很多道理却过不好这一生。作者认为我们在真正学习到和掌握一个新东西的时候，大都会经历四个过程：杂乱 > 有序（树状结构） > 焦点 > 混沌（网状结构），焦点是聚焦的最终形态，但它缺少了发散。而混沌中充满了连接，孕育着创新。从杂乱到焦点，是吸收信息和知识之后逐渐聚焦为本质，而从焦点到混沌，则是本质孕育出无数个触角去主动触达更多的知识、未知、可能性。\n\n作者最后总结到，终身成长是每个人都可以追求并达到的；终身成长有适合普通人习得的方法，只要持续探索，一定能达成。\n\n## 经典语录\n\n- 瓶颈的妙处就在于它始终存在——无论我们跨过多少个瓶颈。也就是说，它本身就是生活的一部分。从表象上来看，当我们遇到瓶颈时，也许尝试一下暂停硬冲的念头或者往后退一步，往往会有不错的效果。从本质上来说，这样的行为其实是我们探索自己内心的表现。如果我们所做的领域是自己熟悉的，那么从自身的思考和想法出发就能得到一些思路和洞察。做产品绝不是完全依赖于研究和数据分析的。 \n\n- **正心、修身、齐家、治业、助天下。**","tags":["产品思维","产品经理"],"categories":["产品思维"]},{"title":"Python configparser用法","url":"/2020/02/20/python-config/","content":"\n我们先新建一个配置文件，假设文件名称叫 test.cfg，文件内容如下：\n\n```shell\n[db]\ndbuser = test\ndbpassword = test123\ndbport = 3308\n \n[email]\nemailto = test@qq.com\n```\n\n*以下代码的运行环境：Win10/Python3.7*\n\n# 读取配置文件的基本操作\n\n- read(filename)：读取文件内容\n- sections()：获取所有section，返回list\n- options(section)：获取该section所有options，返回list\n- items(section)：获取options键值对，返回list\n- get(section,option)：获取section的option值，返回string；getint，getboolean，getfloat同理\n\n在test.cfg文件同级目录下新建一个python文件，内容如下：\n\n```python\n#coding:utf-8\nimport configparser\n\nconfig = configparser.ConfigParser()\nconfig.read(\"test.cfg\")\nprint(config.sections())\nprint(config.options(\"db\"))\nprint(config.items(\"db\"))\nprint(config.get(\"db\", \"dbuser\"))\nprint(config.getint(\"db\", \"dbport\"))\nfor s in config.sections():\n    for items in config.items(s):\n        # 打印键值对\n        print(items)\n```\n\n运行后的结果：\n\n```python\n['db', 'emain']\n['dbuser', 'dbpassword', 'dbport']\n[('dbuser', 'test'), ('dbpassword', 'test123'), ('dbport', '3308')]\ntest\n3308\n('dbuser', 'test')\n('dbpassword', 'test123')\n('dbport', '3308')\n('emailto', 'test@qq.com')\n```\n\n**注意：**在读取配置文件的时候，传入的sections，options要实际存在，否则会报错。\n\n# 写入配置文件的基本操作\n\n- write(filename)：将config对象写入配置文件。如果没有事先read而直接write，则会覆盖原先的文件内容\n- add_section(section)：添加新的section\n- set(section,option,value)：给section中option赋值（新增，或者是修改）\n- remove_setcion(section)：删除某section\n- remove_option(section,option)：删除该section下的option\n\n在test.cfg文件同级目录下新建一个python文件，内容如下：\n\n```python\n#coding:utf-8\nimport configparser\n\nfilename = \"test.cfg\"\nconfig = configparser.ConfigParser()\nconfig.read(filename)\nconfig.add_section(\"user\")\nconfig.set(\"user\", \"name\", \"Root\")\nif \"db\" not in config.sections():\n    config.add_section(\"db\")\nconfig.set(\"db\",\"dbuser\",\"platform\")\nwith open(filename, \"w+\") as f:\n    config.write(f)\n```\n\n**注意：**在对section操作之前，要先判断section是否存在，避免运行时抛异常。\n\n运行后，test.cfg文件内容被修改为：\n\n```bash\n[db]\ndbuser = platform\ndbpassword = test\ndbport = 3308\n \n[email]\nemailto = test@qq.com\n \n[user]\nname = Root\n```\n\n至此，ConfigParser模块的使用就介绍完了，用法比较简单，易上手。\n\n","tags":["python","配置文件","configparser"],"categories":["python"]},{"title":"基于python-opencv的图像比对功能","url":"/2020/02/20/python-cv/","content":"\n有时我们在编写自动化脚本时，会用到图片比对功能，比如：我们需要做一个游戏的辅助脚本，不管是网页游戏还是PC客户端游戏，会需要能够实现自动点击游戏中的一系列图标或图片，达到脚本辅助的目的。\n\n本文介绍的图像比对大概思路是先通过截屏的方式保存完整的屏幕图片，然后再截取需要对比的图标或图片，最后调用python-opencv的相关函数实现图像比对，并输出比对结果（待比对的图标或图片的中心坐标以及置信度）。\n\n实现图像比对需要事先安装的模块有：\n\n- Pillow （python3.x）或 PIL（python2.x）\n- pyscreenshot\n- opencv-python\n- aircv\n\n下面先来介绍下Pillow和PIL，以及它们之间的关系。\n\n# 关于Pillow与PIL\n\n## PIL简介\n\nPIL(Python Imaging Library)是Python一个强大方便的图像处理库，名气也比较大。支持的版本为Python 2.5, 2.6, 2.7。\n\nPIL官方网站：http://www.pythonware.com/products/pil/\n\n## Pillow简介\n\nPillow是PIL的一个派生分支，但如今已经发展成为比PIL本身更具活力的图像处理库，目前的最新版本是7.0.0。由于PIL只支持到Python2.7，所以在Python3上，我们使用Pillow来代替PIL。\n\nPillow的Github主页：https://github.com/python-pillow/Pillow\nPillow的英文文档：https://pillow.readthedocs.io/en/stable/\nPillow的文档中文翻译(对应版本v6.0.0)：https://www.osgeo.cn/pillow/\n\n### Python 3.x 安装Pillow\n\n因为我电脑上同时安装了python2和python3，所以需要使用pip2或pip3来安装python2或python3的模块。如果你的电脑上只安装了一个python版本，那么直接使用`pip`来安装模块就可以了。\n\n```\npip3 install Pillow\n```\n\n安装完成后，使用`from PIL import Image`就完成库的导入了。例如：\n\n```python\nfrom PIL import Image\nim = Image.open(\"bride.jpg\")\n# 加载图像，将其旋转45度，并使用外部查看器（通常是UNIX上的xv，以及Windows上的paint程序）显示它。\nim.rotate(45).show() \n```\n\n# 关于pyscreenshot\n\n在本文一开始的时候，介绍说除了需要安装Pillow或PIL模块之外，还需要安装pyscreenshot。通过名称我们可以大致猜出来，这个模块是一个专门用来截屏的。而在Pillow或PIL模块中，有个ImageGrab模块，该模块主要用于将屏幕或剪贴板的内容复制到PIL图像存储器中，ImageGrab模块内部有个grab函数，功能也是截屏。\n\n这时候你可能会问，既然ImageGrab.grab函数可以截屏，那为什么还要装个pyscreenshot来截屏呢？\n\n要解答这个问题，我们需要看一眼Pillow的官方文档。\n\n![](1.jpg)\n\n[Pillow官方文档](https://pillow.readthedocs.io/en/stable/reference/ImageGrab.html)中写到，ImageGrab模块仅支持在MacOS和Windows上运行，所以如果我们想跨平台，比如在Linux上也能够截屏的话，就不能使用ImageGrab模块了。\n\n那如果想在Linux上截屏的话，就要使用pyscreenshot模块了，而且pyscreenshot模块下也有个grab函数，其用法与Pillow中的ImageGrab.grab()基本一致，也支持全屏幕截图和指定区域截图。\n\n**简单来说，就是pyscreenshot支持跨Windows和Linux平台。**\n\n目前pyscreenshot的最新版本是1.0，2020年1月26日发布的。\n\n根据[pyscreenshot官方文档](https://pyscreenshot.readthedocs.io/en/latest/)，安装该模块之前，需要事先安装下列模块之一：\n\n![](2.jpg)\n\n## Windows上安装pyscreenshot\n\n需要先安装一下Pillow模块，然后再安装pyscreenshot就可以了。\n\n```shell\npip3 install pyscreenshot\n```\n\n## Linux上安装pyscreenshot\n\n需要先安装PyQt4模块，以在 Ubuntu18.04/Python3.7 环境下安装为例：\n\n```shell\nsudo apt-get install python-pip\nsudo pip install pyscreenshot\nsudo apt-get install python-imaging\n# optional back-ends\nsudo apt-get install scrot\nsudo apt-get install imagemagick\nsudo apt-get install python-gtk2\nsudo apt-get install python-qt4\n# optional for examples\nsudo pip install entrypoint2\n```\n\n## pyscreenshot核心函数\n\n这里介绍一下我们接下来需要用到的grab函数。\n\n### grab\n\n源码位于：Python37\\Lib\\site-packages\\pyscreenshot目录下的 init.py 文件\n\n> 函数原型\n\n```\ngrab(bbox=None, childprocess=True, backend=None)\n```\n\n> 函数说明\n\n将屏幕内容复制到PIL图像存储器中，可全屏幕复制，也可以指定区域复制。\n\n> 参数说明\n\n- **bbox** – optional bounding box (x1,y1,x2,y2)\n- **childprocess** – run back-end in new process using popen. This can isolate back-ends from each other and from main process.\n- **backend** – back-end can be forced if set (examples:scrot, wx,..), otherwise back-end is automatic\n\n## pyscreenshot截屏示例代码\n\n```python\nimport pyscreenshot\n\n# 当前文件所在目录的绝对路径\nrootDir = os.path.split(os.path.realpath(__file__))[0]\n\n# 全屏截图\nim = pyscreenshot.grab() #返回的是一个Image对象\nim.show() # 调用的是Pillow模块中的show函数\n\n# 截取指定区域的图片\nim = pyscreenshot.grab(bbox=(10,10,510,510)) # X1,Y1,X2,Y2\n# 将截图保存在当前文件所在目录下，并将图片文件命名为screen.png\nfilepath = os.path.join(rootDir, 'screen.png')\nim.save(filepath) # 调用的是Pillow模块中的save函数\n# 显示截图内容到屏幕上\nim.show()\n```\n\n上述代码中的save函数和show函数，由于它们都属于Pillow模块，所以其源码位于：Python37\\Lib\\site-packages\\PIL\\Image.py\n\n**由此也可以看出pyscreenshot引入了Pillow作为其支撑模块之一。**\n\n参考资料：\n\n- [pyscreenshot官网](https://pypi.org/project/pyscreenshot/1.0/)\n- [Python 截屏模块 pyscreenshot](https://www.oschina.net/p/pyscreenshot)\n- [Python截屏扩展库pyscreenshot安装与使用](https://www.sohu.com/a/237921685_797291)\n\n截屏功能搞定之后，图片比对的功能就已经实现一半了。按照思路，接下来需要再将待比对的两张图片读取出来，然后调用一个图片比对的函数，来实现比对功能，并输出比对结果。\n\n首先介绍下 OpenCV 和 AirCV 这两个东西。\n\n# OpenCV\n\nOpenCV并不是python所独有的一个模块。[OpenCV](https://opencv.org/)是一个基于BSD许可（开源）发行的跨平台计算机视觉库，可以运行在Linux、Windows、Android和Mac OS操作系统上，提供了Python、Ruby、MATLAB等语言的接口，实现了图像处理和计算机视觉方面的很多通用算法。\n\n## OpenCV的版本演化史- From 1.x To 4.0\n\n### OpenCV 1.x\n\nOpenCV 最初基于**C语言**开发，API也都是基于C的，面临内存管理、指针等C语言固有的麻烦。\n\n**2006年10月1.0**发布时，部分使用了C++，同时支持Python，其中已经有了random trees、boosted trees、neural nets等机器学习方法，完善对图形界面的支持。\n\n### OpenCV 2.x\n\n当C++流行起来，OpenCV 2.x发布，其尽量使用C++而不是C，但是为了向前兼容，仍保留了对C API的支持。从2010年开始，2.x决定不再频繁支持和更新C API，而是focus在**C++ API**，C API仅作备份。\n\n在2.0时代，opencv增加了新的平台支持，包括iOS和Android，通过CUDA和openGL实现了GPU加速，为Python和Java用户提供了接口。\n\n### OpenCV 3.x\n\n随着3.x的发布，1.x的C API将被淘汰不再被支持，以后C API可能通过C++源代码自动生成。3.x与2.x不完全兼容，与2.x相比，主要的不同之处在于OpenCV 3.x 的大部分方法都使用了**OpenCL加速**。\n\n从**2017年12月开始的3.4.x**版本，opencv_dnn从opencv_contrib移至opencv，同时OpenCV开始支持C++ 11构建，之后明显感到对**神经网络**的支持在加强，opencv_dnn被持续改进和扩充。\n\n### OpenCV 4.0\n\n**2018年10月4.0.0**发布，OpenCV开始需要支持**C++11**的编译器才能编译，同时对几百个基础函数使用 **\"wide universal intrinsics\"**重写，这些内联函数可以根据目标平台和编译选项映射为SSE2、 SSE4、 AVX2、NEON 或者 VSX 内联函数，获得性能提升。此外，还加入了QR code的检测和识别，以及Kinect Fusion algorithm，DNN也在持续改善和扩充。\n\n## 安装opencv-python模块\n\n安装方式比较简单，只需一行命令：\n\n```\npip3 install opencv-python\n```\n\n参考链接：\n\n- [OpenCV官网](https://opencv.org/)\n- [OpenCV官方文档](https://docs.opencv.org/4.2.0/)\n- [OpenCV Change Logs](https://github.com/opencv/opencv/wiki/ChangeLog)\n- [一文看懂OpenCV 4.0 所有新特性](https://cloud.tencent.com/developer/article/1375617)\n\n# AirCV\n\nAirCV是一个基于**Python-opencv2**的目标定位模块，支持*python2.7及以上版本*。网上关于Aircv的介绍资料相对较少，我在这里做个简单的整理和汇总。\n\n## 安装AirCV模块\n\n我的电脑环境：Win10/Python3.7\n\n由于AirCV是基于**Python-opencv2**开发的（对opencv2中的函数做了一层封装），所以需要先安装好opencv-python模块，然后再安装AirCV，安装命令如下：\n\n```\npip3 install aircv\n```\n\n安装完毕后，可通过`pip3 list`来查看当前所有已安装的模块。\n\n![](3.jpg)\n\n然后在python代码中使用`import aircv`就可以导入aircv模块了。\n\n**FAQ：**import aircv 出现no module named cv2的解决方案\n\n重新安装`opencv-python`模块，然后打开cmd，输入`pip install opencv-python`测试看是否解决。\n\n## AirCV的几个核心函数\n\nAirCV模块的源码就一个文件 init.py，位于：Python37\\Lib\\site-packages\\aircv目录下。\n\n### imread\n\n> 函数原型\n\n```\nimread(filename)\n```\n\n> 函数说明\n\n图片读取\n\n> 参数说明\n\nfilename：待读取图片的文件路径\n\n> 返回值\n\n返回的是一个含（图片高度、宽度、通道数）的三维元组，其实就是numpy.array类型。\n\n---\n\n兴趣延展：**关于返回值的 “一探到底”**\n\n我们可以将imread的返回值，使用shape函数打印出来，例如：\n\n```\nimport aircv\nimg = aircv.imread('test.png') # 读入一张彩色图片\nprint(img.shape) \n```\n\n运行后，会打印出类似下面的结果：\n\n(220, 1000, 3)\n\n上面这个就是一个三维数组，其前面两个值分别是图片的高度和宽度，最后面那个数字3，是代表每个像素点是由BGR三个元素组成。\n\n### find_template\n\n> 函数原型\n\n```\nfind_template(im_source, im_search, threshold=0.5, rgb=False, bgremove=False)\n```\n\n> 函数说明\n\n查找匹配的图片，并返回目标图片的中心点坐标和相似度\n\n> 参数说明\n\n- im_source：源图片\n\n- im_search：待查找的图片\n- threshold：阈值，当相似度小于该阈值时，就会被忽略掉，即返回值为None\n\n> 返回值\n\n- 如果匹配到，则返回目标图片的中心点坐标和相似度，如：(294.3, 13.6), 0.999765。这里可能要注意下，返回的中心点坐标不一定是整数。\n- 如果未匹配到相似图片或相似度小于设定的阈值，则返回None。\n\n### find_all_template\n\n> 函数原型\n\n```\nfind_all_template(im_source, im_search, threshold=0.5, maxcnt=0, rgb=False, bgremove=False)\n```\n\n> 函数说明\n\n查找多个相同的图片，并返回这些相同图片的中心点坐标和相似度\n\n> 参数说明\n\n- im_source：源图片\n- im_search：待查找的图片\n- threshold：阈值，当相似度小于该阈值时，就会被忽略掉，即返回值为None\n- maxcnt：设置最多匹配图片的数量，若设为0，则不限制数量。\n\n> 返回值\n\n- 如果匹配到多个相同图片，则返回包含多个目标图片的中心点坐标和相似度的列表，\n\n  例如：[((294.3, 13.6), 0.999765), ...]\n\n- 如果未匹配到相似图片或相似度小于设定的阈值，则返回空列表[]。\n\n参考链接：\n\n- [aircv源码](https://github.com/NetEaseGame/aircv)\n- [aircv-tags](https://github.com/NetEaseGame/aircv/tags)\n\n------\n\n至此，我们就把Pillow(PIL)、pyscreenshot、opencv、aircv这几个核心模块介绍完了，最后我们一起来利用这几个模块来实现图像比对功能。\n\n# 基于python的图像比对功能代码\n\n```python\nimport os\nimport aircv as ac\nimport pyscreenshot as ImageGrab\n\n# 当前文件所在目录的绝对路径\nrootDir = os.path.split(os.path.realpath(__file__))[0]\n\n\"\"\" 设置截屏区域坐标 \"\"\"\n# 截屏左上角坐标\nleft_up_x = 300\nleft_up_y = 194\n# 截屏右下角坐标\nright_down_x = 1300\nright_down_y = 804\n\n# 图片截屏\ndef screenshot(filepath):\n    im = ImageGrab.grab((left_up_x, left_up_y, right_down_x, right_down_y))\n    im.save(filepath)\n\n# 图像比对，并设置阈值为0.7\ndef matchImg(imgsrc_filepath, imgobj_filepath, threshold=0.7):\n    imsrc = ac.imread(imgsrc_filepath)\n    imobj = ac.imread(imgobj_filepath)\n    match_result = ac.find_template(imsrc, imobj, threshold)\n    if match_result is None:\n        return None, None\n    x = match_result['result'][0]\n    y = match_result['result'][1]\n    # 当前x y为识别图片的中心点，是相对截图坐标的偏移量，所以需要再加上截屏左上角坐标\n    return x+left_up_x, y+left_up_y\n\n# 匹配多个相同图片，并设置阈值为0.9\ndef matchMultipleImg(imgsrc_filepath, imgobj_filepath, threshold=0.9):\n    imsrc = ac.imread(imgsrc_filepath)\n    imobj = ac.imread(imgobj_filepath)\n    match_all_result = ac.find_all_template(imsrc, imobj, threshold)\n    if not match_all_result:\n    \treturn None\n    return match_all_result\n\n# 测试代码\nimgsrc_filepath = os.path.join(rootDir, 'screen.png') # 截屏文件路径\nimgobj_filepath = os.path.join(rootDir, 'search.png') # 待查找图片文件路径\nscreenshot(imgsrc_filepath)\nx, y = matchImg(imgsrc_filepath, imgobj_filepath)\nif x is None or y is None:\n    print('未匹配到图片：%s' % imgobj_filepath)\nelse:\n\tprint('匹配到图片：%s' % imgobj_filepath)\n\tprint('x: %s, y: %s' % (x,y))\n\t\nall_result = matchMultipleImg(imgsrc_filepath, imgobj_filepath)\nif all_result is None:\n    print('未匹配到图片：%s' % imgobj_filepath)\nelse:\n    print('匹配到图片：%s' % imgobj_filepath)\n    print(all_result)\n    for result in all_result:\n        x = result['result'][0]\n        y = result['result'][1]\n        # 此时的x，y是相对坐标，打印的时候别忘了加上截屏的左上角坐标，变成绝对坐标\n        print('(%s, %s)' % (x+left_up_x,y+left_up_y)) \n```\n\n运行后，会得到类似下面的结果：\n\n```python\n匹配到图片：D:\\python_demo\\search.png\nx: 344.0, y: 646.5\n匹配到图片：D:\\python_demo\\search.png\n[{'result': (44.0, 452.5), 'rectangle': ((9, 423), (9, 482), (79, 423), (79, 482)), 'confidence': 0.9926632046699524}, {'result': (120.0, 452.5), 'rectangle': ((85, 423), (85, 482), (155, 423), (155, 482)), 'confidence': 0.9902418255805969}, {'result': (44.0, 555.5), 'rectangle': ((9, 526), (9, 585), (79, 526), (79, 585)), 'confidence': 0.9793710112571716}]\n(344.0, 646.5)\n(420.0, 646.5)\n(344.0, 749.5)\n```\n\n上述演示了查找目标图片和找出多个相同图片位置的方法，其实使用aircv不仅可以实现在大图中找小图，而且还可以识别小图中的信息，比如识别出图片中的文字信息。这个功能可以用来识别一些网站上的动态验证码，关于这块，网上有个现成的帖子，供大家学习和参考：[aircv 大图找小图 并识别小图中信息](https://blog.csdn.net/qq_37550440/article/details/87364362)\n\n------\n\n到这里，本文的介绍就全部结束了。其实本文介绍的图像比对功能，我在很久之前做项目的时候就已经实现过，只是当时没有进行及时的梳理和总结，所以一直对这个功能里面所涉及到的知识点不那么清晰，在脑子里基本上是一团浆糊。\n\n这次通过写博客的方式，我将所有涉及到的知识点以及可以延展的点都重新梳理了一遍，发现比之前要清晰很多，而且所有的知识点也都能串起来了。\n\n虽然写博客往往需要花费大量的时间和精力，真正坐下来、静下心来写，但是我觉得写博客是一个利人利己、能够双赢的做法：一方面尽可能的给后来者一些参考，略尽绵薄之力，尽可能缩短他们走弯路的时间，加快学习效率；另一方面对自己脑袋中的知识点做个规整，把它们尽可能多的串起来，把思路都理顺，变成自己真正掌握了的知识点。","tags":["python","pyscreenshot","Pillow","opencv","aircv"],"categories":["python"]},{"title":"Python logging模块使用","url":"/2020/02/20/python-log/","content":"\n# logging模块简介\n\nlogging模块是Python内置的标准模块，主要用于输出运行日志，可以设置输出日志的等级、日志保存路径、日志文件回滚等；相比print，具备如下优点：\n\n1、可以通过设置不同的日志等级，在release版本中只输出重要信息，而不必显示大量的调试信息；\n\n2、print将所有信息都输出到标准输出中，严重影响开发者从标准输出中查看其它数据；logging则可以由开发者决定将信息输出到什么地方，以及怎么输出；\n\n# logging模块使用\n\n## logging的日志等级\n\n在Python3.7中，logging模块将日志等级设为以下几类：\n\n- logging.CRITICAL：特别糟糕的事情，如内存耗尽、磁盘空间为空 \n- logging.ERROR：发生错误时，如IO操作失败或者连接问题 \n- logging.WARNING：发生很重要的事件，但是并不是错误时，如用户登录密码错误 \n- logging.INFO：处理请求或者状态变化等日常事务 \n- logging.DEBUG：调试过程中使用DEBUG等级，如算法中每个循环的中间状态\n\n这几类等级的排序：CRITICAL > ERROR > WARNING > INFO > DEBUG\n\n**重点说明：**\n\n- 设置了日志等级之后，调用**比设置等级低的日志函数**，其日志内容不会输出到日志文件中。\n- 默认情况下python的logging模块会将日志打印到了标准输出中，且只显示大于等于WARNING级别的日志，这说明python将默认的日志级别设置为WARNING。\n\n## 将日志输出到控制台\n\n```python\nimport logging\n\nlogging.basicConfig(level = logging.INFO,format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(__name__)\n\n# 测试代码\nlogger.info(\"Start print log\")\nlogger.debug(\"Do something\")\nlogger.warning(\"Something maybe fail.\")\nlogger.info(\"Finish\")\n```\n\n运行后，控制台输出以下内容：\n\n```shell\n2020-02-20 11:20:21,187 - __main__ - INFO - Start print log\n2020-02-20 11:20:21,187 - __main__ - WARNING - Something maybe fail.\n2020-02-20 11:20:21,187 - __main__ - INFO - Finish\n```\n\n## 将日志写入指定文件\n\n导入logging模块，创建一个FileHandler，并对输出消息的格式进行设置，将其添加到logger，然后将日志写入到指定的文件中。\n\n```python\nimport logging\n\nlogger = logging.getLogger(__name__)\nlogger.setLevel(level = logging.INFO)\n\nhandler = logging.FileHandler(\"log.txt\")\nhandler.setLevel(logging.INFO)\nformatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\nhandler.setFormatter(formatter)\nlogger.addHandler(handler)\n\n# 测试代码\nlogger.info(\"Start print log\")\nlogger.debug(\"Do something\")\nlogger.warning(\"Something maybe fail.\")\nlogger.info(\"Finish\")\n```\n\nlog.txt中的日志内容：\n\n```shell\n2020-02-20 11:23:39,875 - __main__ - INFO - Start print log\n2020-02-20 11:23:39,875 - __main__ - WARNING - Something maybe fail.\n2020-02-20 11:23:39,875 - __main__ - INFO - Finish\n```\n\n> 关于logging.Formatter的参数说明：\n\n- %(levelno)s：打印日志级别的数值 \n- %(levelname)s：打印日志级别的名称 \n- %(pathname)s：打印当前执行程序的路径，其实就是sys.argv[0] \n- %(filename)s：打印当前执行程序名 \n- %(funcName)s：打印日志的当前函数 \n- %(lineno)d：打印日志的当前行号 \n- %(asctime)s：打印日志的时间 \n- %(thread)d：打印线程ID \n- %(threadName)s：打印线程名称 \n- %(process)d：打印进程ID \n- %(message)s：打印日志信息\n\n## 将日志同时输出到控制台和日志文件\n\n基于上面的代码，在logger中添加StreamHandler，则可以将日志输出到控制台上。\n\n```python\nimport logging\n\nlogger = logging.getLogger(__name__)\nlogger.setLevel(level = logging.INFO)\n\nhandler = logging.FileHandler(\"log.txt\")\nhandler.setLevel(logging.INFO)\nformatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\nhandler.setFormatter(formatter)\nlogger.addHandler(handler)\n\n# 将日志也输出到控制台上 \nconsole = logging.StreamHandler()\nconsole.setLevel(logging.INFO)\nlogger.addHandler(console)\n\n# 测试代码\nlogger.info(\"Start print log\")\nlogger.debug(\"Do something\")\nlogger.warning(\"Something maybe fail.\")\nlogger.info(\"Finish\")\n```\n\n这样我们就可以在控制台上看到与文件中一样的日志内容。\n\n从上面的代码中，可以发现，logging有一个日志处理的主对象（如：上面代码中的 logger ），其他的处理方式都是通过addHandler函数添加进去的。\n\n## logging中常用的Handler\n\n### StreamHandler\n\n> 函数原型\n\n```\nclass logging.StreamHandler(stream=None)\n```\n\n> 函数说明\n\n日志信息会输出到指定的stream中，可以是sys.stderr，sys.stdout或者文件。\n\n> 参数说明\n\n如果stream参数为空，则默认输出到sys.stderr。\n\n### FileHandler\n\n> 函数原型\n\n```\nclass logging.FileHandler(filename, mode='a', encoding=None, delay=False)\n```\n\n> 函数说明\n\n继承自StreamHandler，功能是将日志信息输出到磁盘文件上。\n\n> 参数说明\n\n- mode参数默认为append；\n\n- 若delay参数为true时，文件直到emit方法被执行才会打开。默认情况下，日志文件可以无限增大。\n\n### WatchedFileHandler\n\n> 函数原型\n\n```\nclass logging.handlers.WatchedFileHandler(filename, mode='a', encoding=None, delay=False)\n```\n\n> 函数说明\n\n- 位于logging.handlers模块中。\n- 该函数用于监视文件的状态。如果文件被改变了，那么就关闭当前流，重新打开文件，创建一个新的流。\n- newsyslog或者logrotate的使用会导致文件改变。\n- 这个函数是专门为linux/unix系统设计的，因为在windows系统上，正在被打开的文件是不会被改变的。\n\n> 参数说明\n\n该函数参数和FileHandler相同。\n\n### RotatingFileHandler\n\n> 函数原型\n\n```\nclass logging.handlers.RotatingFileHandler(filename, mode='a', maxBytes=0, backupCount=0, encoding=None, delay=False)\n```\n\n> 函数说明\n\n- 位于logging.handlers模块。\n- 支持**循环生成日志文件**。\n\n> 参数说明\n\n- filename: 自定义日志文件的路径以及文件名。\n- 参数maxBytes和backupCount允许日志文件在达到maxBytes时rollover，即当文件大小达到或者超过maxBytes时，就会新建一个日志文件。上述这两个参数，其中任何一个为0时，rollover都不会发生，也就是文件没有maxBytes限制。\n- backupCount参数是指备份数目，也就是日志最多能保留多少个文件。其文件命名则会在filename后面加上.0到.n的后缀，比如filename参数填error.log，当error.log大小达到maxBytes字节后，会自动再新建一个文件，并命名叫error.log.1，当error.log.1大小达到maxBytes字节后，会再新建一个文件error.log.2，以此类推下去。\n\n### TimedRotatingFileHandler\n\n> 函数原型\n\n```\nclass logging.handlers.TimedRotatingFileHandler(filename, when='h', interval=1, backupCount=0, encoding=None, delay=False, utc=False, atTime=None)\n```\n\n> 函数说明\n\n- 位于logging.handlers模块。\n- 支持定时生成新日志文件。\n\n> 参数说明\n\n- filename：日志文件名的前缀prefix。\n\n- when：是一个字符串，用于描述定时周期的基本单位，字符串的值及意义如下：\n\n   'S'：秒\n   'M'：分钟\n   'H'：小时\n   'D'：天\n   'W0'-'W6'：工作日(0=星期一)\n   'midnight'：凌晨\n\n- interval：设置间隔周期，单位由when参数指定，如：when='D'，interval=1，表示每天产生一个日志文件。\n- backupCount：表示日志文件的保留个数，超过数量就会丢弃掉老的日志文件；不写则全保存。\n- utc：表示UTC时间，如果utc为true，则启用UTC时间，反之则使用本机时间。\n\n除了上述这些参数之外，TimedRotatingFileHandler还有一个比较重要的成员变量 **suffix** 。\n\n`suffix`是指日志文件名的后缀，`suffix`中通常带有格式化的时间字符串，`filename`和`suffix`由“.”连接构成文件名。\n\n例如：filename=\"runtime\"， suffix=\"%Y-%m-%d.log\"，那么生成的文件名就是 runtime.2020-02-20.log\n\n## 按天保存单独的日志文件\n\n通常我们在运行中大型python程序时，日志最好是使用按天保存的方式，这样查看起来会很方便，也不会因为日志内容积累太多而不好打开。\n\n说到按周期保存文件，我们很容易会想到使用`TimedRotatingFileHandler`函数来实现。没错，就是它。\n\n```python\nimport os\nimport logging\nfrom logging.handlers import TimedRotatingFileHandler\n\n# 当前文件所在目录（绝对路径）\nrootDir = os.path.split(os.path.realpath(__file__))[0]\n\nlogger = logging.getLogger(__name__)\nlogger.setLevel(level = logging.INFO)\n\nformatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n\n# 在当前文件所在目录下，新建logs目录，用来存放log文件\nlog_path = os.path.join(rootDir,'logs')\nif not os.path.exists(log_path):\n\tos.makedirs(log_path)\nfilename = os.path.join(log_path,'test')\nhandler = TimedRotatingFileHandler(filename, when='midnight', interval=1)\nhandler.setFormatter(formatter)\nhandler.setLevel(logging.INFO)\nhandler.suffix = \"%Y-%m-%d_%H-%M-%S.log\"\nlogger.addHandler(handler)\n\n# 测试代码\nlogger.info(\"Start print log\")\nlogger.debug(\"Do something\")\nlogger.warning(\"Something maybe fail.\")\nlogger.info(\"Finish\")\n```\n\n运行这段代码之后，会发现在该python文件所在目录下创建了一个logs目录，并在logs目录里面创建了一个log文件。\n\n**重要说明：**\n\n大家可能会发现上述代码，在调用TimedRotatingFileHandler时，传入的when参数值是'midnight'，那为什么不传'D'呢？它不也可以表示按天为单位周期来生成日志吗？**其实传'D'也是可以的，但有个条件要满足**：就是该python脚本会一直运行不会停止，比如长期在后台运行。\n\n那为什么会有这么一个奇怪的要求呢？\n\n这个就要看看TimedRotatingFileHandler源码（源码位于：Python37\\Lib\\logging\\handlers.py）在时间计算这块是怎么实现的了。\n\n贴上TimedRotatingFileHandler类的 init 函数的部分代码：\n\n```python\nself.extMatch = re.compile(self.extMatch, re.ASCII)\n    self.interval = self.interval * interval # multiply by units requested\n    if os.path.exists(filename):\n        t = os.stat(filename)[ST_MTIME]\n    else:\n        t = int(time.time())\n    self.rolloverAt = self.computeRollover(t) # 计算何时分割日志\n```\n\n从上面代码可以发现，TimedRotatingFileHandler是根据当前文件的修改时间或当前时间戳来判断是否需要把日志分割开来，而每次初始化TimedRotatingFileHandler这个类，时间就会重新计算一次。\n\n所以，如果项目是持续运行的，那么这个类只会初始化一次，这时通过传入参数when='D' 是可以正常按天来分割日志的。而只要python脚本一重启，那这个时间就会重新算，日志分割时间也就会推迟了。\n\n然后我们再阅读下computeRollover函数源码，发现如果传参when='midnight'，那么它会计算当前时间到凌晨零点的秒数，然后每次写日志时都会判断有没有过凌晨，一旦过了凌晨就会自动分割日志。\n\n---\n\n到这里，关于python logging模块的内容就介绍完了。总的来说，logging模块用起来还是相当方便的，功能也比较强大，值得我们好好深入学习和使用。\n\n参考链接：\n\n- [python logging模块](https://www.cnblogs.com/dahu-daqing/p/7040764.html)\n\n- [Python自带TimedRotatingFileHandler巨坑，日志无法按天分割，使用需谨慎](https://blog.csdn.net/weixin_38107388/article/details/90639151)\n- [Python官方文档-logging.handlers](https://docs.python.org/zh-cn/3.7/library/logging.handlers.html)\n\n","tags":["python","日志"],"categories":["python"]},{"title":"python自动化脚本实现模拟鼠标和键盘输入","url":"/2020/02/18/python-auto-operation/","content":"\n# Windows上实现自动化脚本\n\npython在windows上的生态做的比较好，各种依赖包模块也比较齐全，所以在windows上实现自动化脚本相对容易一些，相关的实现文章和文档也比较多。我一开始做自动化脚本就是在windows系统上弄的，在这过程中也踩了一些坑，特于此整理，以备后查。\n\n运行环境：Win10/Python3.7\n\n主要模块：win32gui，利用pip安装 pywin32即可。\n\n## 模拟鼠标点击的关键代码和说明\n\n**使用的主要函数：** `win32api.mouse_event`\n\n> 函数原型\n\n```c\nVOID mouse_event(\n   DWORD dwFlags, // motion and click options\n   DWORD dx, // horizontal position or change\n   DWORD dy, // vertical position or change\n   DWORD dwData, // wheel movement\n   ULONG_PTR dwExtraInfo // application-defined information\n);\n```\n\n> 参数说明\n\ndwFlags：标志位集，指定点击按钮和鼠标动作的多种情况。**这里主要介绍鼠标点击的一些组合**：\n\n- MOUSEEVENTF_LEFTDOWN：表明接按下鼠标左键。\n- MOUSEEVENTF_LEFTUP：表明松开鼠标左键。\n- MOUSEEVENTF_RIGHTDOWN：表明按下鼠标右键。\n- MOUSEEVENTF_RIGHTUP：表明松开鼠标右键。\n- MOUSEEVENTF_MIDDLEDOWN：表明按下鼠标中键。\n- MOUSEEVENTF_MIDDLEUP：表明松开鼠标中键。\n- MOUSEEVENTF_WHEEL：在Windows NT中如果鼠标有一个轮(wheel)，表明鼠标轮被移动。移动的数量由**dwData**给出。\n\ndx：指定鼠标沿x轴的绝对位置。\n\ndy：指定鼠标沿y轴的绝对位置。\n\ndwData：如果**dwFlags**为MOUSEEVENTF_WHEEL，则用dwData来指定鼠标轮移动的数量。\n\n- dwData为正值：表明鼠标轮向前转动，即远离用户的方向；\n- dwData为负值：表明鼠标轮向后转动，即朝向用户。\n- 一个轮击(即滚动一次)定义为WHEEL_DELTA，即120。\n\n**注意：**在使用鼠标轮(wheel)时，如果想实现多次连续滚动，建议使用循环语句，且每次执行后稍微停顿(sleep)一下。\n\n> 示例代码\n\n```python\nimport win32con\nimport win32api\n\n# 向下滚动一次，即一个轮击\nwin32api.mouse_event(win32con.MOUSEEVENTF_WHEEL, 0, 0, -120, win32con.WHEEL_DELTA)\n```\n\n**以下是模拟鼠标点击的关键代码：**\n\n```python\nimport time\nimport win32gui\nimport win32con\nimport win32api\n\n# 移动鼠标到指定位置\ndef mouse_move(x,y):\n    win32api.SetCursorPos((x, y))  # 设置鼠标位置(x, y)\n    \n# 鼠标单击左键\ndef mouse_click(x=None,y=None):\n    if not x is None and not y is None:\n        mouse_move(x,y)\n        time.sleep(0.05)\n    win32api.mouse_event(win32con.MOUSEEVENTF_LEFTDOWN, 0, 0, 0, 0)\n    win32api.mouse_event(win32con.MOUSEEVENTF_LEFTUP, 0, 0, 0, 0)\n    \n# 鼠标双击左键\ndef mouse_dclick(x=None,y=None):\n    if not x is None and not y is None:\n        mouse_move(x,y)\n        time.sleep(0.05)\n    win32api.mouse_event(win32con.MOUSEEVENTF_LEFTDOWN, 0, 0, 0, 0)\n    win32api.mouse_event(win32con.MOUSEEVENTF_LEFTUP, 0, 0, 0, 0)\n    win32api.mouse_event(win32con.MOUSEEVENTF_LEFTDOWN, 0, 0, 0, 0)\n    win32api.mouse_event(win32con.MOUSEEVENTF_LEFTUP, 0, 0, 0, 0)\n    \n# 鼠标滚轮向下滑动\ndef mouse_slide(slide_times):\n    for i in range(slide_times):\n        win32api.mouse_event(win32con.MOUSEEVENTF_WHEEL,0,0,-120,win32con.WHEEL_DELTA)\n        time.sleep(1)\n\n# 测试代码\nmouse_click(500, 280)\nmouse_dclick(500, 280)\nmouse_slide(3) # 鼠标滚轮向下滑动3次\n```\n\n参考链接：\n\n- [python中调用windowsAPI实现鼠标滑轮滚动操作](http://blog.sina.com.cn/s/blog_53f023270101ors4.html)\n- [如何使用python来模拟鼠标点击（将通过实例自动化模拟在360浏览器中自动搜索\"python\"）](https://www.cnblogs.com/huidaoli/p/7398392.html)\n\n## 模拟键盘输入的关键代码和说明\n\n**使用的主要函数：** `win32api.keybd_event`\n\n> 函数原型\n\n```c\nkeybd_event(bVk,  bScan,  dwFlags,  dwExtraInfo);\n```\n\n> 参数说明\n\nbVk：定义一个虚拟键码，键码值必须在1～254之间（键盘键码对照表请见下方代码中的VK_CODE）。\n\nbScan：定义该键的硬件扫描码，一般设置为0即可。\n\ndwFlags：定义函数操作的一个标志位。置为0表示该健被按下，置为KEYEVENTF_KEYUP表示该健被释放。\n\ndwExtraInfo：定义与击键相关的附加的32位值，一般设置为0即可。\n\n> 示例代码\n\n```python\nimport win32api\nimport win32con\n\nwin32api.keybd_event(0x0D, 0, 0, 0)     # 按下enter键\nwin32api.keybd_event(0x0D, 0, win32con.KEYEVENTF_KEYUP, 0)  #释放按键\n```\n\n**以下是模拟按键输入的关键代码：**\n\n```python\nimport time\nimport win32gui\nimport win32con\nimport win32api\n\nVK_CODE = {\n    'backspace':0x08,\n    'tab':0x09,\n    'clear':0x0C,\n    'enter':0x0D,\n    'shift':0x10,\n    'ctrl':0x11,\n    'alt':0x12,\n    'pause':0x13,\n    'caps_lock':0x14,\n    'esc':0x1B,\n    'spacebar':0x20,\n    'page_up':0x21,\n    'page_down':0x22,\n    'end':0x23,\n    'home':0x24,\n    'left_arrow':0x25,\n    'up_arrow':0x26,\n    'right_arrow':0x27,\n    'down_arrow':0x28,\n    'select':0x29,\n    'print':0x2A,\n    'execute':0x2B,\n    'print_screen':0x2C,\n    'ins':0x2D,\n    'del':0x2E,\n    'help':0x2F,\n    '0':0x30,\n    '1':0x31,\n    '2':0x32,\n    '3':0x33,\n    '4':0x34,\n    '5':0x35,\n    '6':0x36,\n    '7':0x37,\n    '8':0x38,\n    '9':0x39,\n    'a':0x41,\n    'b':0x42,\n    'c':0x43,\n    'd':0x44,\n    'e':0x45,\n    'f':0x46,\n    'g':0x47,\n    'h':0x48,\n    'i':0x49,\n    'j':0x4A,\n    'k':0x4B,\n    'l':0x4C,\n    'm':0x4D,\n    'n':0x4E,\n    'o':0x4F,\n    'p':0x50,\n    'q':0x51,\n    'r':0x52,\n    's':0x53,\n    't':0x54,\n    'u':0x55,\n    'v':0x56,\n    'w':0x57,\n    'x':0x58,\n    'y':0x59,\n    'z':0x5A,\n    'numpad_0':0x60,\n    'numpad_1':0x61,\n    'numpad_2':0x62,\n    'numpad_3':0x63,\n    'numpad_4':0x64,\n    'numpad_5':0x65,\n    'numpad_6':0x66,\n    'numpad_7':0x67,\n    'numpad_8':0x68,\n    'numpad_9':0x69,\n    'multiply_key':0x6A,\n    'add_key':0x6B,\n    'separator_key':0x6C,\n    'subtract_key':0x6D,\n    'decimal_key':0x6E,\n    'divide_key':0x6F,\n    'F1':0x70,\n    'F2':0x71,\n    'F3':0x72,\n    'F4':0x73,\n    'F5':0x74,\n    'F6':0x75,\n    'F7':0x76,\n    'F8':0x77,\n    'F9':0x78,\n    'F10':0x79,\n    'F11':0x7A,\n    'F12':0x7B,\n    'F13':0x7C,\n    'F14':0x7D,\n    'F15':0x7E,\n    'F16':0x7F,\n    'F17':0x80,\n    'F18':0x81,\n    'F19':0x82,\n    'F20':0x83,\n    'F21':0x84,\n    'F22':0x85,\n    'F23':0x86,\n    'F24':0x87,\n    'num_lock':0x90,\n    'scroll_lock':0x91,\n    'left_shift':0xA0,\n    'right_shift ':0xA1,\n    'left_control':0xA2,\n    'right_control':0xA3,\n    'left_menu':0xA4,\n    'right_menu':0xA5,\n    'browser_back':0xA6,\n    'browser_forward':0xA7,\n    'browser_refresh':0xA8,\n    'browser_stop':0xA9,\n    'browser_search':0xAA,\n    'browser_favorites':0xAB,\n    'browser_start_and_home':0xAC,\n    'volume_mute':0xAD,\n    'volume_Down':0xAE,\n    'volume_up':0xAF,\n    'next_track':0xB0,\n    'previous_track':0xB1,\n    'stop_media':0xB2,\n    'play/pause_media':0xB3,\n    'start_mail':0xB4,\n    'select_media':0xB5,\n    'start_application_1':0xB6,\n    'start_application_2':0xB7,\n    'attn_key':0xF6,\n    'crsel_key':0xF7,\n    'exsel_key':0xF8,\n    'play_key':0xFA,\n    'zoom_key':0xFB,\n    'clear_key':0xFE,\n    '+':0xBB,\n    ',':0xBC,\n    '-':0xBD,\n    '.':0xBE,\n    '/':0xBF,\n    '`':0xC0,\n    ';':0xBA,\n    '[':0xDB,\n    '\\\\':0xDC,\n    ']':0xDD,\n    \"'\":0xDE,\n    '`':0xC0\n}\n# 模拟键盘输入，单个按键\ndef single_key_input(key_name):\n    win32api.keybd_event(VK_CODE[key_name], 0, 0, 0) # 按下该健\n    win32api.keybd_event(VK_CODE[key_name], 0, win32con.KEYEVENTF_KEYUP, 0) # 释放该健\n    time.sleep(0.05)\n    \n# 模拟键盘输入，多个按键组合\ndef multiple_key_input(key_array):\n    if len(key_array) == 0:\n        return\n        \n    for i in range(0, len(key_array), 1): # 按顺序按下\n        win32api.keybd_event(VK_CODE[key_array[i]], 0, 0, 0)\n        print(\"enter: %s\" % key_array[i])\n        time.sleep(1)\n    for i in range(len(key_array)-1, -1, -1): #按倒序释放\n        win32api.keybd_event(VK_CODE[key_array[i]], 0, win32con.KEYEVENTF_KEYUP, 0)\n        print(\"up: %s\" % key_array[i])\n        time.sleep(1)\n    time.sleep(0.05)\n\n# 模拟键盘输入字符串\ndef string_key_input(str=''):\n    for c in str:\n        win32api.keybd_event(VK_CODE[c], 0, 0, 0)\n        win32api.keybd_event(VK_CODE[c], 0, win32con.KEYEVENTF_KEYUP, 0)\n        time.sleep(0.01)\n\n# 测试代码\nsingle_key_input('9')\nmultiple_key_input(['ctrl', 'F4'])\nstring_key_input('python')\n```\n\n参考链接：\n\n- [keybd_event模拟键盘输入](https://blog.csdn.net/qq_29360495/article/details/53006082)\n\n- [Vitual keystroke example](https://gist.github.com/chriskiehl/2906125)\n\n同时，网上也有一些关于如何模拟鼠标点击和键盘输入的文章，可以参考下面的链接：\n\n- [Python实现自动挂机脚本（基础篇）](https://blog.csdn.net/zydarChen/article/details/77587967)\n- [用python做一个游戏辅助脚本，完整思路](https://www.cnblogs.com/reader/p/10111777.html)\n\n# 实现跨平台自动化脚本（Windows/Linux）\n\n由于pywin32无法在linux系统上安装加载，所以如果想在linux系统上实现自动化脚本，需要寻找其它的替代方案。\n\n通过网上查阅资料发现，有一个模块也可以实现模拟操作鼠标和键盘，它就是PyUserInput，最新版本0.1.11。\n\n- [PyUserInput官网](https://pypi.org/project/PyUserInput/)\n- [PyUserInput的GitHub](https://github.com/PyUserInput/PyUserInput)\n\n其实我们要实现模拟操作鼠标和键盘，需要用到pymouse和pykeyboard这两个模块，而PyUserInput模块将它们俩打包在一起了，所以我们只需要安装PyUserInput模块就可以了（这里可能要翻车了，因为我在windows上尝试过，如果只装PyUserInput，不装pymouse的话，是无法成功 import pymouse 的）。\n\n以下涉及到的所有命令的运行环境：\n\n- Windows环境：Win10/Python3.7\n- Linux环境：Ubuntu18.04/Python3.7\n\n## PyUserInput简介\n\nPyUserInput是一个跨平台、使用python操作鼠标和键盘的模块，非常方便使用。支持的平台及依赖如下：\n\n- Linux - Xlib (python-xlib)\n- Mac - Quartz, AppKit\n- Windows - pywin32, pyHook, pymouse\n\n### 简剖PyUserInput\n\n通过阅读PyUserInput源码（其实是pymouse和pykeboard源码，源码均在Python37\\Lib\\site-packages目录下）和官网信息，可以得知，\n\n- 在windows平台上，PyUserInput基于pywin32模块，封装了win32api中的mouse_event和keybd_event等核心函数，从而实现了模拟鼠标输入和键盘输入的功能，也就是pymouse和pykeyboard模块。\n- 在linux平台上，PyUserInput基于Xlib库，封装出pymouse和pykeyboard模块，可运行支持X11的linux平台上。\n\n**相关说明：**\n\n- X11 中的 X 指的是 X 协议，11 指的是采用 X 协议的第 11 个版本。\n- Linux 的图形化界面，底层都是基于 X 协议。\n\n## PyUserInput安装\n\n在windows环境下，我们需要先安装3个依赖包，依次为pywin32、pyHook和pymouse。\n\n由于我的Win10电脑上同时安装了python2和python3，所以在输入pip命令时需要区别开来。\n\n> 安装pywin32\n\n```\npip3 install pywin32\n```\n\n> 安装pyHook\n\npyHook通过pip命令无法安装，所以需要下载whl格式的安装包（whl格式本质上是一个压缩包，里面包含了py文件，以及经过编译的pyd文件），可以通过这里下载到pyHook安装包：https://www.lfd.uci.edu/~gohlke/pythonlibs/#pyhook\n\n![](1.png)\n\n选择适合自己环境的安装包。这里由于我的电脑是Win10 64位系统，使用的是Python3.7，所以我选择的是\n\npyHook‑1.5.1‑cp37‑cp37m‑win_amd64.whl\n\n然后使用pip命令安装pyHook：\n\n```\npip3 install D:\\pyHook‑1.5.1‑cp37‑cp37m‑win_amd64.whl #假设whl文件在D盘根目录下\n```\n\n> 安装pymouse\n\n```\npip3 install pymouse\n```\n\n这时，3个依赖包都已经安装完毕，下面开始安装PyUserInput：\n\n```shell\npip3 install PyUserInput==0.1.11\n或\npip3 install PyUserInput\n```\n\n安装完成后，可通过命令`pip3 list`查看python3下面已经安装的所有模块。\n\n参考链接：\n\n- [PyMouse、PyKeyboard用python操作鼠标和键盘](https://www.cnblogs.com/guohu/p/11314920.html)\n- [Win10 Python3.5 安装pymouse（pyuserinput）报错坑](https://blog.csdn.net/zhusongziye/article/details/79241410)\n\n## 使用pymouse模拟鼠标点击\n\npymouse模块的基本用法：\n\n```python\n# import the module\nfrom pymouse import PyMouse\n\n# instantiate an mouse object\nm = PyMouse()\n\n# move the mouse to int x and int y (these are absolute positions)\nm.move(200, 200)\n\n# click works about the same, except for int button possible values are 1: left, 2: right, 3: middle\nm.click(500, 300, 1)\n\n# get the screen size\nm.screen_size()\n# (1024, 768)\n\n# get the mouse position\nm.position()\n# (500, 300)\n```\n\n是不是感觉用起来很简单？其实就是这么简单哈。**不过这里有个地方可能需要稍微注意一下，**就是click这个函数。\n\n通过看pymouse的源码我们可以知道，click的函数原型其实是这样的：\n\n```python\ndef click(self, x, y, button=1, n=1):\n        \"\"\"\n        Click a mouse button n times on a given x, y.\n        Button is defined as 1 = left, 2 = right, 3 = middle.\n        \"\"\"\n```\n\n最后一个参数是代表点击鼠标多少次，但我个人测试了一下这个参数，发现并不灵敏，达不到预期效果。所以建议大家在需要模拟鼠标双击的时候，最好自己写一个函数，调2次click，中间稍微sleep一下，这样效果会更好。\n\n**我当时在使用pymouse的时候，遇到过一个小坑或一个可能可以优化的点，在这里也跟大家分享一下：**\n\n我们先找到pymouse源码中的click函数、press函数和release函数，源码内容如下（以Windows的pymouse源码为例，Linux的也可做类似修改）：\n\n> click函数源码（base.py文件）\n\n```python\ndef click(self, x, y, button=1, n=1):\n        \"\"\"\n        Click a mouse button n times on a given x, y.\n        Button is defined as 1 = left, 2 = right, 3 = middle.\n        \"\"\"\n\n        for i in range(n):\n            self.press(x, y, button)\n            self.release(x, y, button)\n```\n\n> press函数源码（windows.py文件）\n\n```python\ndef press(self, x, y, button=1):\n        buttonAction = 2 ** ((2 * button) - 1)\n        self.move(x, y)\n        win32api.mouse_event(buttonAction, x, y)\n```\n\n> release函数源码（windows.py文件）\n\n```python\ndef release(self, x, y, button=1):\n        buttonAction = 2 ** ((2 * button))\n        self.move(x, y)\n        win32api.mouse_event(buttonAction, x, y)\n```\n\n这3个函数源码比较简单，我们可以看到，press函数和release函数中都有move函数，这个是用来移动鼠标指针到指定坐标的函数，在press函数和release函数中放一个move函数，不免让人觉得奇怪。按正常的逻辑，应该把move放在click函数中，press和release就干好press和release的活就好了，也符合高内聚低耦合的设计理念。所以我对它们进行了简单改造，改造后代码如下（click函数中增加了move函数调用，顺带sleep一下，给个缓冲时间；press和release中删除了move函数调用）：\n\n> click函数（修改后）\n\n```python\nfrom time import sleep\ndef click(self, x, y, button=1, n=1):\n        \"\"\"\n        Click a mouse button n times on a given x, y.\n        Button is defined as 1 = left, 2 = right, 3 = middle.\n        \"\"\"\n\n        for i in range(n):\n            self.move(x, y)\n            sleep(0.05)\n            self.press(x, y, button)\n            self.release(x, y, button)\n```\n\n> press函数（修改后）\n\n```python\ndef press(self, x, y, button=1):\n        buttonAction = 2 ** ((2 * button) - 1)\n        #self.move(x, y)\n        win32api.mouse_event(buttonAction, x, y)\n```\n\n> release函数（修改后）\n\n```python\ndef release(self, x, y, button=1):\n        buttonAction = 2 ** ((2 * button))\n        #self.move(x, y)\n        win32api.mouse_event(buttonAction, x, y)\n```\n\n这样修改之后，会显得逻辑上更顺一点，可能也是自我感觉顺一点吧，也许pymouse作者觉得他那种方式更好，这个就仁者见仁智者见智了，凡事没有绝对的对错好坏之分，只要合适就好，哈哈。\n\n## 使用pykeyboard模拟键盘输入\n\npykeyboard模块的基本用法：\n\n```python\nfrom pykeyboard import PyKeyboard\n\nk = PyKeyboard()\n\n# pressing a key\nk.press_key('H')\n# which you then follow with a release of the key\nk.release_key('H')\n# or you can 'tap' a key which does both\nk.tap_key('e')\n# note that that tap_key does support a way of repeating keystrokes with a interval time between each\nk.tap_key('l',n=2,interval=5)\n# and you can send a string if needed too\nk.type_string('o World!')\n### Hello World!\n```\n\npykeyboard也支持输入各种功能键和数字键：\n\n```python\nk.tap_key(k.function_keys[5])  # Tap F5\nk.tap_key(k.numpad_keys['Home'])  # Tap 'Home' on the numpad\nk.tap_key(k.numpad_keys[5], n=3)  # Tap 5 on the numpad, thrice\n```\n\npykeyboard还支持各种组合键的输入：\n\n```python\n# Create an Alt+Tab combo\nk.press_key(k.alt_key)\nk.tap_key(k.tab_key)\nk.release_key(k.alt_key)\n```\n\n参考链接：[PyMouse、PyKeyboard 用python操作鼠标和键盘](https://www.cnblogs.com/guohu/p/11314920.html)\n\n# 脚本后台定时自启\n\n一般我们写完自动化脚本以后，可能需要让它能够定时在后台自启，下面我们一起来看看这块如何实现。\n\n## Windows系统上定时启动\n\n在windows上定时启动python脚本，有个比较简便的方式：**使用windows系统自带的 “任务计划程序”** ，具体操作可参考这篇文章《[windows创建定时任务执行python脚本](https://blog.csdn.net/shw800/article/details/78678665)》。\n\n## Linux系统上定时启动\n\n安装`crontab`，此处以`centos系统`为例：\n\n```shell\nyum install crontabs\n```\n\n**创建脚本文件**\n\n```shell\ntouch test.sh\nchmod 777 test.sh\nvi test.sh\n# 填写如下内容\n/usr/bin/Rscript /root/ETL_code/R_oracle_mysql.R\n```\n\n**添加定时任务**\n\n```shell\ncrontab -e\nSHELL=/bin/bash\nPATH=/sbin:/bin:/usr/sbin:/usr/bin\nMAILTO=root\nHOME=/\n\n*/6 * * * * ./home/test.sh  # 定时间隔6分钟执行一次test.sh脚本\n```\n\n**启动定时任务**\n\n```shell\nservice crond restart # 重启定时任务， 有restart和reload两个命令\nservice crond status  # 查看执行报错情况 \n```\n\n**列出定时任务列表**\n\n```shell\ncrontab -l\n```\n\n**查看运行结果**\n\n```shell\ntail -f /var/log/cron\n```\n\n**将cron设置为开机自启**\n\n```shell\nvi /etc/rc.local\n# 填写如下内容\n/bin/systemctl start crond.service\n```\n\n参考链接：\n\n- [Linux crontab命令-菜鸟教程](https://www.runoob.com/linux/linux-comm-crontab.html)\n- [Linux crontab命令详解](https://www.cnblogs.com/ftl1012/p/crontab.html)","tags":["自动化脚本","python"],"categories":["python"]},{"title":"python使用的基础知识","url":"/2020/02/17/python/","content":"\n# Python简介\n\nPython是由Guido van Rossum于1989年底发明，第一个公开发行版发行于1991年。Python是一种解释型、面向对象、动态数据类型的高级程序设计语言，它具有卓越的通用性、高效性、平台移植性和安全性。近几年Python在数据挖掘，人工智能等领域较为流行。\n\n# Python2和Python3\n\n因为早期的 Python版本在基础方面设计存在着一些不足之处，所以在2008 年的时候 Guido van Rossum 又重新开发 Python 3.0（被称为Python 3000，或简称Py3k），Python3在设计的时候很好地解决了这些遗留问题， 并且在性能上也有了一定的提升， 然而 Python3 带来的最大的问题就是不完全向后兼容，当时向后兼容的版本是Python2.6。Python开发团队无法一下子就让所有项目和类库都转到 Python3.0 上面。 所以，两个版本就进入了长期并行开发和维护的状态。但是就更新速度来说 ，Python3更新速度远快于Python2的速度，因为Python2目前主要以维护为主，Python3是未来的趋势，但从目前形势来看，Python2和Python3应该会长期并存，就像现在的WinXP、Win7、Win10一样。\n\n## 学习Python 2还是Python 3？\n\n对于纠结是学python2还是python3的朋友，推荐你看一篇文章：https://blog.csdn.net/qq_39521554/article/details/80855086 。其实我刚开始学python的时候，也曾纠结过这个问题。当时主流用的还是python2，所以我没有在这个问题上纠结太久（当你不知道该如何二选一时，那么跟着主流走就对了）。\n\n# 同时安装Python2和Python3\n\n这里介绍下如何同时安装Python2和Python3，以及安装好之后如何使用，如何避免两个版本间的命令冲突。\n\n当前Windows下稳定版Python如下：\n\n[Python 2 Release - Python 2.7.16](https://www.python.org/ftp/python/2.7.16/python-2.7.16.amd64.msi)（64位操作系统）\n\n[Python 3 Release - Python 3.7.3](https://www.python.org/ftp/python/3.7.3/python-3.7.3-amd64.exe)（64位操作系统）\n\n如果上面两个版本不满足需求，可到[Python官网](https://www.python.org/)，下载其他Python安装文件。\n\n安装步骤这里就省去了，注意在安装过程中可以选择让安装程序来设置python的环境变量，当然也可以等安装以后，自己再去我的电脑\\>属性>高级系统设置>高级>环境变量>系统变量>Path里设置环境变量。\n\n当python2和python3都安装完以后，可以看到无论是python2还是python3，python可执行文件都叫python.exe，那此时我们在cmd窗口里输入python，会进入哪个版本的python命令行中呢？其实在cmd下输入python得到的版本号取决于环境变量里哪个版本的python路径更靠前，毕竟windows是按照顺序查找的。\n\n这就带来一个问题了，如果你一会想用python2运行一个脚本，一会又想用python3运行另一个脚本，你怎么做？来回改环境变量显然很麻烦。\n\n> 网上有个简单粗暴的办法：把两个python.exe改名，一个改成python2.exe，一个改成python3.exe。这样做固然可以，但修改可执行文件的方式，毕竟不是很好的方法。\n\n这里介绍一个我觉得比较合适的解决办法：\n\n> 借用py的一个参数来调用不同版本的Python，即 py -2调用python2，py -3调用的是python3。\n\n- 当python脚本需要python2运行时，只需在**脚本最前面**添加一行`#! python2`，然后运行py xxx.py即可。\n\n- 当python脚本需要python3运行时，只需在**脚本最前面**添加一行`#! python3`，然后运行py xxx.py即可。\n\n有人可能会问，那我要用pip安装依赖包的时候该怎么办呢？\n\n> 其实这个也很简单。我们可以看到在python2和python3的安装目录下都有一个**Scripts目录**（如果你安装好python之后，没有发现这个Scripts目录，那就去python官网下载一个最新版本的python安装包），而python2的Scripts目录里有个pip2.exe，python3的Scripts目录里有个pip3.exe。那么我们直接在cmd里执行`pip2 install xxx`就是安装python2的依赖包，执行`pip3 install xxx`就是安装python3的依赖包。\n\n# 更改Python依赖包的下载源\n\n当我们使用pip来下载依赖包的时候，会发现下载速度比较慢，这是因为python默认使用的是官方下载源，这个下载源的地址在国外，所以最好更改为国内的下载源，即添加一个pip的配置文件。以下描述是基于windows系统上的操作：\n\n1、按照pip的官方说明文档，它的配置文件应该放在%APPDATA%/pip/目录下，配置文件名称是pip.ini，我们先按下win+R键。或者在开始菜单上点右键，点运行。然后在出来的窗口中输入%APPDATA%，然后点击确定。\n\n2、我们可能会发现该目录下并没有pip目录，那我们就手动创建一个。\n\n3、pip目录创建好以后，进入到这个目录中，然后新建一个pip.ini文件，并在文件中输入以下内容：\n\n```\n[global]\ntime-out=60\nindex-url = https://mirrors.aliyun.com/pypi/simple\n[install]\ntrusted-host = mirrors.aliyun.com\n```\n\n**注：**[global] 区域配置的是下载链接和超时时间，而[install] 区域配置的是安装时信任的地址。这里我写的是阿里云提供的pip下载源，其它的几个国内pip下载源地址如下：\n\n```bash\n# 阿里云 \nhttp://mirrors.aliyun.com/pypi/simple/\n\n# 中国科技大学 \nhttps://pypi.mirrors.ustc.edu.cn/simple/\n \n# 豆瓣(douban) \nhttp://pypi.douban.com/simple/\n \n# 清华大学 \nhttps://pypi.tuna.tsinghua.edu.cn/simple/\n \n# 中国科学技术大学 \nhttp://pypi.mirrors.ustc.edu.cn/simple/\n```\n\n4、pip.ini文件写好之后，点击保存。然后重新打开一个cmd命令行窗口，使用pip安装任意一个模块，这个时候就能看到，使用的是阿里云的下载地址了，下载速度也快很多。\n\n参考链接：https://jingyan.baidu.com/article/3d69c55127775af0cf02d79e.html\n\n# 查找python的安装目录\n\n有时候时间一长，我们自己也忘记当初把python安装到哪个位置了，那么如果想查看python的安装目录，只需进入到python命令行界面，然后依次输入以下内容即可：\n\n```\nimport sys\npath = sys.executable\nprint(path)\n```\n\n然后就会打印出python的安装目录了。\n\n![](1.jpg)\n\n# python一键获取依赖包和安装依赖包\n\n## 获取依赖包\n\n一键获取依赖包有两种方法：\n\n**第一种方法：**获取环境中所有安装的包\n\n打开命令提示符，在某条路径下输入 `pip freeze > ./requirements.txt`\n\n这时就会生成一个requirements.txt文件\n\n**第二种方法：**根据某一个项目的 import 语句来生成依赖\n\n打开命令提示符，将路径切换到需要生成依赖的项目的根目录下，依次输入：\n\n```\npip install pipreqs\npipreqs ./\n```\n\n执行完以后，在这个项目下会生成一个requirements.txt文件，里面记录了该项目所用到的依赖。\n\n## 安装依赖包\n\n获得了依赖包之后，我们就可以在新环境下安装依赖包的模块，执行以下命令即可：\n\n```\npip install -r requirements.txt\n```\n\n# 关于python的除法操作\n\n我们知道，在python中，除法有两种运算符，'/'和'//'，我们通常把'/' 叫做精确除，'//' 叫做地板除，它们在python2和python3上的表现结果也不太一样。\n\n**精确除和地板除的解释：**\n\n精确除：\n\n- 在python2中，当被除数和除数都是整数时，得到的结果是被整除后的整数，舍弃小数部分，与C语言里面的除法处理方式一样。\n\n- 在python3中，无论被除数和除数是整数还是浮点数，得到的商总是真实结果，总是得到保留尾数的浮点数。\n\n地板除：是指无论被除数和除数是整数还是浮点数，得到的商都不保留浮点数的尾数。\n\n在python2中，无论是'/' 还是 '//'，\n\n- 当被除数和除数都是整数时，那么结果也是整数；\n- 当被除数和除数两者中有任何一个是浮点数时，那么结果也一定是浮点数。只是如果用 '//' 运算符的话，操作的结果是整除后的结果，虽然结果仍是浮点数，但其尾数被舍去了。\n\n```\n以python2.7为例：\n>>> 5 / 2 = 2\n>>> 5 // 2 = 2\n>>> 5.0 / 2 = 2.5\n>>> 5.0 // 2 = 2.0\n```\n\n在python3中，为了与python2做个对比，这里特地加了一个 `4 / 2` 的计算。通过对比我们可以看出，无论被除数能否被整除，'/' 运算符操作的结果都是保留小数部分的，都是浮点数。\n\n```\n以python3.7为例：\n>>> 4 / 2 = 2.0\n>>> 5 / 2 = 2.5\n>>> 5 // 2 = 2\n>>> 5.0 / 2 = 2.5\n>>> 5.0 // 2 = 2.0\n```\n\n**总结：**无论是python2还是python3，如果想得到某个整数被整除后的结果，使用 '//' 就可以了。","tags":["python"],"categories":["python"]},{"title":"智能家居物联网平台环境搭建","url":"/2020/02/05/smart-home/","content":"\n# MQTT简介\n\nMQTT（Message Queuing Telemetry Transport，消息队列遥测传输协议），是一种基于发布/订阅（publish/subscribe）模式的\"轻量级\"通讯协议，该协议构建于TCP/IP协议上，由IBM在1999年发布。MQTT最大优点在于，可以以极少的代码和有限的带宽，为连接远程设备提供实时可靠的消息服务。作为一种低开销、低带宽占用的即时通讯协议，使其在物联网、小型设备、移动应用等方面有较广泛的应用。\n\nMQTT是一个基于客户端-服务器的消息发布/订阅传输协议。MQTT协议是轻量、简单、开放和易于实现的，这些特点使它适用范围非常广泛。在很多情况下，包括受限的环境中，如：机器与机器（M2M）通信和物联网（IoT）。其在，通过卫星链路通信传感器、偶尔拨号的医疗设备、智能家居、及一些小型化设备中已广泛使用。\n\n# Mosquitto简介\n\nMosquitto是最常用的开源MQTT实现，它实现了MQTT3.1协议的消息代理服务器（broker），提供轻量级、支持可发布/可订阅的的消息推送模式，使设备对设备之间的短消息通信变得简单，比如现在应用广泛的低功耗传感器，手机、嵌入式计算机、微型控制器等移动设备。Mosquitto由MQTT协议创始人之一的Andy Stanford-Clark开发，它为我们提供了非常棒的轻量级数据交换的解决方案。官方网站：http://mosquitto.org/ 和 github项目地址：https://github.com/eclipse/mosquitto\n\n# Domoticz简介\n\nDomoticz是一个轻量级、开源的智能家居系统，通过它你可以监测和控制各种设备比如：灯、开关 ，各种传感器、仪表比如： 温度、雨、风、紫外线、电、气体、水 等等， 还可以向任一移动设备发送通知或警告。Domoticz支持Linux、Windows、树莓派及各种嵌入式设备。Domoticz中文站点：https://www.domoticz.cn/ 和 [wiki手册](https://www.domoticz.cn/wiki/Domoticz%E6%89%8B%E5%86%8C)\n\n<span id=\"inline-blue\">下面让我们开始一步步地搭建智能家居物联网平台吧！</span>\n\n# 更改ubuntu系统安装源\n\n由于ubuntu系统默认使用的是国外安装源，在下载安装包过程中速度可能会比较慢，所以建议将其更改为国内安装源。\n\n1、修改/etc/apt/sources.list文件，建议将现有的sources.list备份下。\n\n将sources.list文件内容替换如下：\n\n```shell\ndeb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse\n \ndeb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse\n \ndeb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse\n \ndeb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse\n \ndeb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse\n```\n\n2、更新软件包\n\n```shell\nsudo apt-get update\nsudo apt-get upgrade\n```\n\n# mosquitto环境搭建\n\n搭建mosquitto环境通常有两种方式，一种是通过mosquitto源码安装部署，一种是通过docker容器化部署，下面将分别介绍这两种搭建方式。\n\n## 通过下载源码安装部署\n\n### 下载和安装mosquitto\n\n1、如果你是在Linux系统上安装Mosquitto，建议大家使用源码安装，最新的源码可从http://mosquitto.org/files/source/ 获取。我这里下载的是当前最新版本：mosquitto-1.6.8。\n\n2、下载后解压出来。这里有个需要注意的地方：**默认情况下Mosquitto的安装需要OpenSSL的支持；如果不需要SSL，则需要关闭config.mk里面的某些与SSL功能有关的选项（WITH_TLS、WITH_TLS_PSK）。**\n\n3、请确保已安装make、gcc、g++、openssl等依赖包。\n\n4、安装mosquitto：cd到mosquitto源码根目录下，执行 `make install`。\n\n5、安装完毕后，会发现系统命令行里有mosquitto、mosquitto_passwd、mosquitto_pub和mosquitto_sub四个工具，分别用于启动代理服务、管理密码、发布消息和订阅消息。\n\n![](1.jpg)\n\n### mosquitto用户配置和权限管理\n\nmosquitto支持匿名登陆和用户名登陆，在正式使用时，建议使用用户名登陆，以保证系统整体安全性。\n\nmosquitto中可以添加多个用户，只有使用用户名和密码登陆服务器才允许用户进行订阅与发布操作。可以说用户机制是mosquitto重要的安全机制，增强服务器的安全性。\n\n**用户与权限配置有3处需要修改：**\n\n1、mosquitto中最最最重要的配置文件mosquitto.conf\n2、pwfile.example (保存用户名与密码)\n3、aclfile.example (保存权限配置)\n\n#### 用户配置\n\ncd到/etc/mosquitto目录下，找到mosquitto.conf.example文件，将其cp一份，名称设为`mosquitto.conf`，并打开该文件。\n\n```shell\n$ cd /etc/mosquitto\n$ cp mosquitto.conf.example mosquitto.conf\n$ vim mosquitto.conf\n```\n\n1、找到allow_anonymous字段，这个字段的作用是：是否开启匿名用户登录，默认为true。打开此项配置（将前面的 # 号去掉）之后将其值改为false。\n\n```\nallow_anonymous false\n```\n\n2、找到password_file字段，这个字段是告诉服务器你要配置的用户将存放在哪里。打开此配置并指定password_file的文件路径（注意是绝对路径）\n\n```\npassword_file /etc/mosquitto/pwfile.example （这里的路径根据自己文件实际路径填写）\n```\n\n3、找到user字段，这个字段是指当前服务器的登录用户名称，这里我使用的登录用户是root，所以需要将它的值改为root，否则在后续启动mosquitto时会报错：`Error: Invalid user 'mosquitto'.`\n\n```\nuser root\n```\n\n4、创建用户名和密码，此处我们来创建两个用户：admin 和 mosquitto_test。先创建admin用户，在命令行窗口输入以下命令：\n\n```shell\n$ mosquitto_passwd -c /etc/mosquitto/pwfile.example admin\n```\n\n会提示需连续输入两次密码，创建成功。\n\n*命令解释： -c 是指创建一个用户，/etc/mosquitto/pwfile.example 是将用户创建到 pwfile.example 文件中，admin 是用户名。*\n\n再创建mosquitto_test用户，输入以下命令：\n\n```\nmosquitto_passwd /etc/mosquitto/pwfile.example mosquitto_test\n```\n\n同样会提示需连续输入两次密码。\n\n**注意第二次创建mosquitto_test用户时不用加 -c 。如果加了 -c，则会把第一次创建的admin用户给覆盖掉。**\n\n至此，两个用户创建成功，用户信息都保存在 pwfile.example 文件中。\n\n![](2.png)\n\n**mosquitto_passwd命令的基本用法：**\n\n- mosquitto_passwd -c：每次都只会生成只包含一个用户的文件。\n\n*用法：mosquitto_passwd -c passwordfile username*\n\n- mosquitto_passwd -b：必须在控制台输入明文的密码，且每次只是在pwfile.example中新增一个用户，并不会覆盖之前已生成的用户。\n\n*用法：mosquitto_passwd -b passwordfile username password*\n\n- mosquitto_passwd -D：删除一个用户。\n\n*用法：mosquitto_passwd -D passwordfile username*\n\n此时所有客户端连接 mosquitto 服务都需要输入用户名和密码。\n\n#### 权限管理\n\nMosquitto 权限是根据 topic 控制的，类似目录管理。你可以设定每个用户的订阅/发布权限，也可以设定每个用户可访问的topic范围，从而达到权限控制的目的。\n\n1、给刚刚我们创建的两个用户配置不同的权限（假定已经创建了admin 和 mosquitto_test这两个用户）\n\n- 将 admin 设置为订阅权限，并且只能访问的主题为\"root/topic/#\"\n- 将 mosquitto_test 设置为发布权限，并且只能访问的主题为\"root/topic/#\"\n\n这样一来，由于他们的权限不同，如果用 admin 进行发布是不会成功的，反过来用 mosquitto_test 进行订阅同样不会接受到任何信息。\n\n2、设置权限配置文件\n\n打开mosquitto.conf文件，找到acl_file字段，这个字段是告诉服务器你要配置的权限将存放在哪里。打开此配置并指定acl_file的文件路径（注意是绝对路径）\n\n```\nacl_file /etc/mosquitto/aclfile.example（这里的路径根据自己文件实际路径填写）\n```\n\n3、增加权限配置（假设我们的权限配置文件是aclfile.example）\n\n打开配置文件 aclfile.example，并添加如下配置信息：\n\n```\nuser admin\ntopic read root/topic/#\nuser mosquitto_test\ntopic write root/topic#\n```\n\n说明：read -- 订阅权限 、write -- 发布权限。\n\n添加完毕后，保存退出。\n\n至此 admin 、 mosquitto_test 两个用户的权限已配置完成。\n\n### mosquitto启动和停止\n\nmosquitto默认使用的端口是1883。如果希望修改端口，则需修改mosquitto.conf文件中的 port 字段值。\n\n![](3.png)\n\n一切准备就绪后，启动mosquitto：\n\n```shell\nmosquitto -c /etc/mosquitto/mosquitto.conf      ##前台运行\n或\nmosquitto -c /etc/mosquitto/mosquitto.conf -d   ##后台运行\n```\n\n停止mosquitto：使用kill命令强制终止即可。\n\n参考链接：\n\n- https://www.cnblogs.com/Paul-watermelon/p/10400758.html\n- https://www.cnblogs.com/saryli/p/9820532.html\n\n## 通过docker容器化部署\n\n*注：应事先在机器上安装好docker环境，且保证docker已经正常启动。*\n\n### 查询镜像\n\n ```\ndocker search mosquitto\n ```\n\n选择STARS数最多的 eclipse-mosquitto\n\n### 拉取镜像\n\n```\ndocker pull eclipse-mosquitto\n```\n\n### 查看镜像\n\n```\ndocker images eclipse-mosquitto\n```\n\n### 创建目录文件，用于容器目录挂载\n\n#### 在宿主机环境下创建目录\n\n```\nmkdir -p /mosquitto/config\nmkdir -p /mosquitto/data\nmkdir -p /mosquitto/log\n```\n\n#### 初始化用户密码文件\n\n```\ntouch /mosquitto/config/pwfile.conf\nchmod -R 755 /mosquitto/config/pwfile.conf\n```\n\n**注**：这里先生成一个空文件，后续会进到容器里面使用*mosquitto_passwd*命令来自动生成用户密码。\n\n#### 初始化权限管理文件\n\n```\nvi /mosquitto/config/aclfile.conf\n```\n\n在文件中添加以下内容（此处假设会创建admin和mosquitto_test这两个用户）\n\n```\nuser admin\ntopic read root/topic/#\nuser mosquitto_test\ntopic write root/topic#\n```\n\n说明：read – 订阅权限 、write – 发布权限。\n\n#### 初始化mosquitto配置文件\n\n```\nvi /mosquitto/config/mosquitto.conf\n```\n\n在配置文件中输入以下内容\n\n```shell\npersistence true\npersistence_location /mosquitto/data\n# 设置log路径\nlog_dest file /mosquitto/log/mosquitto.log\n\n# 设置log类型\n#log_type error\n#log_type warning\n#log_type notice\n#log_type information\nlog_type all\n\n# 是否保存客户端的连接和断开连接的信息到日志\nconnection_messages true\n\n# 是否设置日志时间戳\nlog_timestamp true\n\n# 设置时间戳格式\nlog_timestamp_format %Y-%m-%dT%H:%M:%S\n\n# 是否开启匿名模式\nallow_anonymous false\n\n# 指定用户密码文件\npassword_file /mosquitto/config/pwfile.conf\n\n# 指定权限管理文件\nacl_file /mosquitto/config/aclfile.conf\n\n# 设置启用websocket协议\nlistener 61614\nprotocol websockets\n\n# For MQTT v5 clients, it is possible to have the server send a \"server\n# keepalive\" value that will override the keepalive value set by the client.\n# This is intended to be used as a mechanism to say that the server will\n# disconnect the client earlier than it anticipated, and that the client should\n# use the new keepalive value. The max_keepalive option allows you to specify\n# that clients may only connect with keepalive less than or equal to this\n# value, otherwise they will be sent a server keepalive telling them to use\n# max_keepalive. This only applies to MQTT v5 clients. The maximum value\n# allowable is 65535. Do not set below 10.\n#max_keepalive 65535\n\n# Set the keepalive interval for this bridge connection, in seconds.\n#keepalive_interval 60\n```\n\n#### 添加目录权限\n\n```\nchmod -R 755 /mosquitto\nchmode -R 777 /mosquitto/log #日志目录要最大权限\n```\n\n### 启动镜像\n\n```\ndocker run -it --name=mosquitto --privileged -p 1883:1883 -p 9001:9001 -v /mosquitto/config:/mosquitto/config -v /mosquitto/data:/mosquitto/data -v /mosquitto/log:/mosquitto/log -d eclipse-mosquitto\n```\n\n### 进入docker容器\n\n```\ndocker exec -it mosquitto sh\n```\n\n### 生成用户密码\n\n使用*mosquitto_passwd*命令创建用户密码，第一个admin是用户名，第二个admin是密码\n\n```\nmosquitto_passwd -b /mosquitto/config/pwfile.conf admin admin\nmosquitto_passwd -b /mosquitto/config/pwfile.conf mosquitto_test mosquitto_test\n```\n\n### 重启mosquitto容器\n\n```\ndocker restart mosquitto\n```\n\n### 在宿主机查看mosquitto是否正常启用\n\n查看容器是否正常重启\n\n```\ndocker ps\n```\n\n![](4.jpg)\n\n查看mosquitto服务是否正常启动\n\n```\nps aux |grep mosquitto\n```\n\n![](5.jpg)\n\n查看mosquitto服务运行日志\n\n```\ncat /mosquitto/log/mosquitto.log\n```\n\n![](6.jpg)\n\n至此，mosquitto环境就搭建完成了。我们知道，单单只有一个broker是不行的，我们还需要一个可以进行家居控制的工具，接下来我们开始搭建这个可视化的工具Domoticz。\n\n# domoticz环境搭建\n\n本文开头简单介绍了domoticz是个啥东东，其中说到了domoticz支持linux系统。经本人亲身测试，domoticz在centos系统上支持的不是很好，比如在安装domoticz的时候，centos系统无法使用命令`curl -L install.domoticz.cn | bash`来一键式安装domoticz，不会出现所谓的安装界面。所以最终选择在**ubuntu 18.04 64系统**上安装domoticz，总的来说，domoticz在ubuntu系统上的适配做的比较好。\n\n安装domoticz通常有两种方式：一种是直接通过命令行安装，一种是下载源码后，编译源码来安装。网上大多数安装教程介绍的是通过命令行来安装，参考链接：https://blog.csdn.net/why19940926/article/details/88372645，下面重点介绍通过编译源码来安装domoticz。\n\n## 下载源码\n\n假定你已经更改了ubuntu系统安装源，并已经更新了系统软件包。\n\n当前最新稳定版是v4.10717，但有人说最新版不是很稳定，推荐使用v3.8153。\n\n参考链接：https://www.domoticz.cn/forum/viewtopic.php?f=4&t=2\n\n为保险起见，这里使用了某人推荐的v3.8153版本（v3.0系列的最后一个稳定版本），下载地址如下：\n\nhttps://github.com/domoticz/domoticz/tree/3.8153\n\n## 安装相关依赖库和工具\n\n```shell\n$ apt-get install build-essential nano cmake git libboost-dev libboost-thread-dev libboost-system-dev\n$ apt-get install libsqlite3-dev curl libcurl4-openssl-dev libssl-dev libusb-dev zlib1g-dev python3-dev\n```\n\n## 编译源码\n\ncd到domoticz源码根目录下，输入以下命令：\n\n```shell\n$ cmake -DCMAKE_BUILD_TYPE=Release .\n$ make\n```\n\n**说明：**在低配电脑上进行编译可能需要10-15分钟。如果你的电脑拥有多核CPU，可以通过给`make`命令增加'-j'标识来使用更多核心，这样会快很多。四核CPU可以使用`make -j4`代替`make`。\n\n## 启动domoticz\n\ncd到domoticz源码根目录下，输入以下命令：\n\n```shell\n$ ./domoticz\n```\n\n然后在浏览器中输入IP:8080即可访问domoticz的Web控制界面，会发现Web前端的版本号是v3.5876，而本次下载的domoticz源码版本号是v3.8153，注意不要把这两者弄混淆了。\n\n![](7.jpg)\n\n**说明：**domoticz默认使用的端口是8080，如果需要更改端口号，可在启动domoticz时，使用参数 `-www` 来指定端口号，如：`./domoticz -www 8090`\n\n还可通过命令`./domoticz -h`来查看详细用法。\n\n参考链接：\n\n- https://www.domoticz.cn/wiki/Linux\n- https://www.domoticz.cn/wiki/Install.txt\n\n# 搭建过程中的常用工具\n\n## 查看系统端口被占用情况\n\n使用netstat命令查看端口占用情况：\n\n```shell\n$ apt-get install net-tools ##安装netstat\n$ netstat -nultp            ##查看所有tcp、udp的端口使用情况\n```\n\n参数说明：\n\n- -t (tcp) 仅显示tcp相关选项 \n\n- -u (udp)仅显示udp相关选项 \n\n- -n 拒绝显示别名，能显示数字的全部转化为数字 \n\n- -l 仅列出在Listen(监听)的服务状态 \n\n- -p 显示建立相关链接的程序名\n\n例如查看 8000 端口的情况，使用以下命令：\n\n```shell\n$ netstat -nultp | grep 8000\n```\n\n## 如何对正在运行的docker容器增加端口映射\n\n通常在docker run创建并运行容器的时候，可以通过-p指定端口映射规则。但是，我们经常会遇到刚开始忘记设置端口映射或者设置错了需要修改。当docker start运行容器后并没有提供一个-p选项或设置，让你来修改指定端口映射规则。那么这种情况我们该怎么处理呢？\n\n**方法一：**删掉当前的容器，重新创建一个新容器（加上新的端口映射）。\n\n- 优点：简单快捷，在测试环境使用较多。\n- 缺点：如果是数据库镜像，那重新建一个又要重新配置一次，就比较麻烦了。\n\n**方法二：**修改容器配置文件，重启docker服务。\n\n- 优点：没有副作用，操作简单。\n- 缺点：需要重启整个docker服务，如果在同一个宿主机上运行着多个容器服务的话，就会影响其他容器服务。\n\n- 具体方法如下：\n\n1. 利用`docker ps`命令查看当前容器的**CONTAINER ID**，一般只会显示出该ID的一部分内容。\n\n![](8.jpg)\n\n2. 打开hostconfig.json文件，文件路径是：/var/lib/docker/containers/*[**CONTAINER ID**]*/hostconfig.json。\n\n![](9.jpg)\n\n该json文件中有一个节点是PortBindings，这里面包含所有的映射端口内容，只需在这里面新增相应的端口映射即可。例如：1883/tcp对应的是容器内部的1883端口，HostPort对应的是映射到宿主机的端口1883。按需新增/修改端口后，使用命令`systemctl restart docker`重启docker服务，再启动相应容器就可以了。\n\n**方法三：**利用docker commit构建一个新镜像，再创建一个新容器。\n\n- 优点：不会影响宿主机上的其他容器。\n- 缺点：管理起来显得比较混乱，总体来说没有第二种方法那么直观。","tags":["mosquitto","domoticz","mqtt"],"categories":["物联网"]},{"title":"在ubuntu18.04上安装微信","url":"/2019/11/15/wechat-wine/","content":"\n一提到在linux系统上使用微信，大家可能第一反应就是用微信网页版。我刚开始也是这么想的，但现实是残酷的。当我尝试使用微信网页版登录时，发现已无法正常登录。在网上搜了下，得知微信网页版后续将会关闭。\n\n下面是我从网上搜到的**关于微信网页版受限**的资料，仅供参考。\n\n**一、第一次开始限制**\n\n在2017年9月份开始，腾讯已经开始限制新注册的微信号禁止登录网页版微信，老的微信号则不受影响，可以自行验证。用新注册的微信号登录微信网页版，会提示：\n\n![](1.png)\n\n**二、第二次完全屏蔽与限制**\n而从2019年7月份开始，腾讯疑似彻底关闭了网页版微信登录入口，通过https://wx.qq.com  或 https://wx2.qq.com  登录网页版的微信都会有如下类似提示信息，不管是新注册的微信号，还是老的微信号都是如此。\n\n```xml\n<error>\n   <ret>1203</ret>\n   <message>为了你的帐号安全，此微信号不能登录网页微信。你可以使用Windows微信或Mac微信在电脑端登录。\n      Windows微信下载地址：https://pc.weixin.qq.com\n      Mac微信下载地址：https://mac.weixin.qq.com\n   </message>\n</error>\n```\n\n既然微信网页版这条路不通，那我们就再尝试其它的路子吧。\n\n于是紧接着想到了用[electronic-wechat](https://github.com/geeeeeeeeek/electronic-wechat/releases)，`electronic-wechat`是托管在 github 中的一款第三方开源微信客户端，但它也是基于微信网页版API封装的一个客户端。既然现在微信网页版已经不能用了，那么`electronic-wechat`也就不能再正常使用了。\n\n至此，上述两条路都不通，那么还有没有其它的路呢？\n\n<span id = \"inline-blue\">这时候想到了Wine。</span> **那什么是Wine？**\n\n## 关于Wine\n\n**Wine**是一个在x86、x86-64的类UNIX系统下运行微软Windows程序的\"兼容层\"。Wine可以运行在Linux、Mac、FreeBSD和Solaris上，在Wine中运行的Windows程序，就如同运行原生Linux程序一样，不会有模拟器那样的性能问题。**Wine**是\"Wine Is Not an Emulator\"的递归缩写，所以**它并不是模拟器**，而是用兼容模式调用DLLs以运行Windows程序。\n\n接下来我们就开始安装和使用它吧。\n\n## 安装Wine\n\n1、创建一个Wine目录，如：放在`/opt`目录下，并给予777权限。\n\n```shell\n$ cd /opt\n$ sudo mkdir Wine\n$ sudo chmod 777 Wine\n```\n\n2、进入Wine目录，clone项目`deepin-wine`到本地。\n\n```shell\n$ git clone https://gitee.com/wszqkzqk/deepin-wine-for-ubuntu.git\n```\n\n3、安装Wine\n\n```shell\n$ cd deepin-wine-for-ubuntu\n$ sudo ./install.sh\n```\n\n至此，我们完成了Wine的安装，接下来安装微信。\n\n## 安装微信\n\n### 下载deepin发布的微信软件包\n\n这里有两种下载方式：\n\n1、从gitee上下载，可能需要登录gitee后才能下载：https://gitee.com/wszqkzqk/deepin-wine-containers-for-ubuntu/raw/master/deepin.com.wechat_2.6.8.65deepin0_i386.deb\n\n2、从网盘上下载，我已经把微信安装包上传到了我的网盘中：\n\n```\n链接：https://pan.baidu.com/s/15FtAPH4P8JQagLTDMcEGdw \n提取码：9mzx\n```\n\n### 用dpkg安装微信软件包\n\n将上面下载到的wechat安装包（`deepin.com.wechat_2.6.8.65deepin0_i386.deb`）copy到刚才创建的Wine目录下，然后执行如下命令：\n\n```shell\nsudo dpkg -i deepin.com.wechat_2.6.8.65deepin0_i386.deb\n```\n\n<span id = \"inline-blue\">至此，微信安装完成。</span> 此时可以在系统应用列表中看到**微信图标**，单击运行即可。\n\n## 常见问题\n\n### 系统是非中文语言环境，会出现微信登录后显示乱码\n\n**解决方法：**在`/opt/deepinwine/tools/run.sh`中添加LC_ALL=\"zh_CN.UTF-8\"，重启微信。由于我的ubuntu系统语言是中文的，所以在安装时没有遇到这种问题。\n\n### 微信中无法输入中文\n\n当时我安装完微信后，满怀欣喜登录微信，结果发现不能输入中文，但我明明已经装了**搜狗输入法**。于是从网上搜索一番，找到了解决方案：\n\n搜狗输入法属于Fcitx框架，我们只需重启Fcitx服务就可以了，如下图所示：\n\n![](2.png)\n\n如果重启Fcitx服务后，发现仍然无法输入中文，就重启下系统，然后再登录微信，会发现可以正常输入中文了。\n\n参考链接：\n\n<https://gitee.com/wszqkzqk/deepin-wine-for-ubuntu>\n\n<https://zhuanlan.zhihu.com/p/73033900>\n\n\n\n","tags":["ubuntu","微信","wine"],"categories":["linux系统"]},{"title":"基于Centos7搭建Maven私有仓库","url":"/2019/11/14/maven-nexus/","content":"\n## 为什么要搭建Maven私服\n\n我们知道Maven仓库分为本地仓库和远程仓库，那么远程仓库又可以分为中央仓库、私服、其他远程仓库。在远程仓库中，默认的是中央仓库，中央仓库是Maven核心自带的远程仓库。\n\n当Maven根据pom中指定坐标寻找构件时，它首先会查看本地仓库。\n\n- 如果本地仓库存在此构件，则直接使用；\n- 如果本地仓库不存在此构件，Maven会去远程仓库查找，在发现需要的构件之后，下载到本地仓库再使用。\n\n那么既然有了中央仓库，为什么还要搭建私服呢？\n\n- 如果没有私服，我们所需的所有构件都需要通过maven的中央仓库和第三方的Maven仓库下载到本地，而一个团队中的所有人都重复的从maven仓库下载构件，那么无疑加大了仓库的负载和浪费了外网带宽，如果网速慢的话，还会影响项目的整体进程。\n- 我们知道，很多情况下，项目的开发都是在内网进行的。如果没有私服，项目连接不到maven远程仓库怎么办？开发的公共构件怎么让其它的项目使用？\n\n所以为了节省带宽和时间以及让公共构件能够在多个项目上使用，需要在局域网内架设一个私有的仓库服务器，用其代理所有外部的远程仓库。\n\n![](1.png)\n\n从上图我们得知，nexus是Maven私服的一种，也是常用的Maven私服，nexus目前被超过10万个开发团队所使用。\n\n<span id = \"inline-blue\">下面我们就开始搭建一个Nexus私服。</span>\n\n## 安装jdk\n\n`Nexus` 需要 `jdk`环境。在安装前需要确认你的 `centos` 机器上是否已经安装了 `jdk` ， 如果没有安装，则可以执行以下命令安装：\n\n```bash\nyum install java\n```\n\n安装完成后，可以使用如下命令查看 `jdk` 的版本号\n\n```bash\njava -version\n```\n\n## 下载Nexus\n\n可以到[Nexus官网](https://www.sonatype.com/nexus-repository-oss)去下载，或直接输入如下命令：\n\n```bash\nwget https://sonatype-download.global.ssl.fastly.net/nexus/3/nexus-3.16.1-02-unix.tar.gz\n```\n\n> 但由于网络问题，一般下载的比较慢。当时我也是遇到了这种问题，后来通过其它渠道下载到了nexus安装包，并放到了网盘上，供大家下载。\n\n```\n链接: https://pan.baidu.com/s/1KpQGcFkESiey1ouOAHP3OA \n提取码: 5yxy\n```\n\nnexus安装包下载好之后，解压到指定位置，比如解压到`/opt`目录下：\n\n```bash\ntar zxvf nexus-3.16.1-02-unix.tar.gz -C /opt\n```\n\n## 配置nexus环境变量\n\n打开`/etc/profile`文件，在文件末尾添加nexus环境变量，内容如下：\n\n```shell\n# maven nexus\nexport MAVEN_HOME=/opt/nexus-3.16.1-02\nexport PATH=$PATH:$MAVEN_HOME/bin\n```\n\n保存退出，重新加载配置文件，让配置生效：\n\n```shell\nsource /etc/profile\n```\n\n## 启动Nexus\n\n由于刚才配置了nexus环境变量，所以此时可以在任意目录下，输入以下命令来启动nexus：\n\n```\nnexus start\n```\n\n启动之后的效果如下：\n\n![](2.png)\n\n此时nexus服务就启动了，nexus的默认端口是8081。此时我们可以在浏览器中访问一下：\n\n```\nhttp://你的服务器IP:8081\n```\n\n如果你使用的是阿里云，那么你需要在阿里云安全组中配置开启8081端口，否则在浏览器中会访问失败。\n\n如果你配置开启8081端口后，仍然启动nexus服务失败，则有可能你的8081端口被其它进程占用了。此时你可以使用以下命令来查看当前哪些端口被占用：\n\n```\nnetstat -tulnp ## 查看系统端口占用情况\nnetstat -tulnp | grep 8081 ## 查看8081端口的占用情况\n```\n\nnetstat命令各个参数说明如下：\n\n- -t : 指明显示TCP端口 \n\n- -u : 指明显示UDP端口 \n\n- -l : 仅显示监听套接字(所谓套接字就是使应用程序能够读写与收发通讯协议(protocol)与资料的程序) \n\n- -n : 不进行DNS轮询，显示IP(可以加速操作) \n\n- -p : 显示进程标识符和程序名称，每一个套接字/端口都属于一个程序\n\n如果发现8081端口已被占用，则需要重新为 `nexus` 指定端口。端口的配置文件是 `nexus-default.properties` ，在`nexus`目录下的 `etc` 目录，如下所示：\n\n![](3.png)\n\n打开`nexus-default.properties`文件，修改如下内容：\n\n```shell\napplication-port=未被占用的端口\n## 如：application-port=8084\n```\n\n重启Nexus服务：\n\n```\nnexus restart\n```\n\n至此，nexus端口的修改就完成了。\n\n## 设置Nexus服务开机自启\n\n```bash\n$ ln -s /opt/nexus-3.16.1-02/bin/nexus /etc/init.d/nexus3\n$ chkconfig --add nexus3\n$ chkconfig nexus3 on\n```\n\n## Nexus常用命令\n\n> 启动Nexus\n\n```\nnexus start\n```\n\n> 停止Nexus\n\n```\nnexus stop\n```\n\n> 重启Nexus\n\n```\nnexus restart\n```\n\n> 查看Nexus状态\n\n```\nnexus status\n```\n\n最后分享下我遇到的一个坑：Nexus服务在刚开始启动时，比较耗CPU，一个双核4G的阿里云服务器，在刚启动Nexus服务时，CPU最高飙升到85%，持续10秒左右在50%以上，大概1分钟之后，CPU恢复正常，在1%左右的水平，内存占用在1.2G左右。","tags":["centos","maven","nexus"],"categories":["web开发"]},{"title":"基于centos7.6搭建Gitlab服务","url":"/2019/11/12/gitlab/","content":"\n**特别说明：我是在服务器防火墙关闭状态下搭建的gitlab服务。**\n\n**centos7版本对防火墙进行加强，启用firewalld，不再使用原来的iptables**\n\n可用`firewall-cmd` 或 `firewalld`命令查看当前服务器防火墙状态：\n\n```shell\n$ firewall-cmd --state\n或\n$ systemctl status firewalld\n```\n\n## 安装Gitlab\n\n### 安装相关依赖\n\n```shell\nyum -y install policycoreutils openssh-server openssh-clients postfix\n```\n\n### 启动postfix，并设置为开机自启\n\n*目的：支持 gitlab 邮件发送功能*\n\n```shell\nsystemctl enable postfix && systemctl start postfix\n```\n\n若此时出现如下报错信息：\n\n![](1.png)\n\n**解决方法：**\n\n打开 **/etc/postfix/main.cf** 文件，并修改内容如下：\n\n```\ninet_interfaces = all\ninet_protocols = ipv4\n```\n\n重新输入`systemctl enable postfix && systemctl start postfix`，会发现不再报错。\n\n## 下载和安装gitlab社区版rpm包\n\n下载路径：[gitlab-ce-10.5.2-ce.0.el7.x86_64.rpm](https://packages.gitlab.com/gitlab/gitlab-ce/packages/el/7/gitlab-ce-10.5.2-ce.0.el7.x86_64.rpm)\n\n*注意：根据自己的linux系统选择合适的包*\n\n```\nEL是Red Hat Enterprise Linux的简写 \n- EL6软件包用于在Red Hat 6.x, CentOS 6.x, and CloudLinux 6.x进行安装 \n- EL5软件包用于在Red Hat 5.x, CentOS 5.x, CloudLinux 5.x的安装 \n- EL7 软件包用于在Red Hat 7.x, CentOS 7.x, and CloudLinux 7.x的安装\n```\n\n下载好之后，输入命令 `rpm -ivh gitlab-ce-10.5.2-ce.0.el7.x86_64.rpm` 进行安装。\n\n## 修改访问Gitlab的URL\n\n打开 `/etc/gitlab/gitlab.rb` 文件，修改 `external_url` 的值，可以使用自定义域名，也可以是IP地址+端口号。如： `external_url 'http://105.13.44.103:1028'`，修改完之后，保存即可。\n\n## 重置并启动Gitlab\n\n**重置命令：**`gitlab-ctl reconfigure`\n\n*注：第一次预计需要几分钟*\n\n![](2.png)\n\n**启动：** `gitlab-ctl restart`\n\n## 浏览器访问Gitlab\n\n在浏览器中输入刚才在`gitlab.rb`文件中配置的URL，访问Gitlab。\n\n第一次登陆时，系统会要求你输入密码（此时用户名默认为root）。\n\n<span id=\"inline-blue\">至此，Gitlab的搭建就完成了，下面看一下如何在Gitlab里创建和配置项目。</span>\n\n## 在Gitlab里创建和配置项目\n\n### 配置Gitlab用户邮箱\n\n首先注册一个gitlab账号，在注册过程中填上自己的邮箱地址。\n\n### 添加用户侧电脑的key到Gitlab上\n\n先确保你的电脑上已安装Git，打开Git Bash，在bash中输入：\n\n```shell\nssh-keygen -t rsa -C “yourEmail@example.com”  ## 后面那个是输入自己的邮箱 \n```\n\n再在 ~/.ssh/id_rsa.pub中复制其中的内容，在*User Settings* - *SSH Keys*中添加刚才复制的内容。\n\n![](3.png)\n\n### 将用户侧电脑上已存在的项目上传到Gitlab上\n\n1、先在Gitlab上创建一个空项目，如：test\n\n2、打开本地Git Bash，cd到你需要上传的项目目录下，配置局部的用户名和邮箱地址（为了防止对全局的用户名和邮箱造成影响）\n\n```shell\n$ cd ~/your project                       \n$ git config user.name  \"username\"      \n$ git config user.email \"email\"\n```\n\n3、执行git命令，将本地项目上传到Gitlab上\n\n```shell\ngit init\ngit remote add origin git@10.3.1.12:zhepan/test.git\ngit add .\ngit commit -m \"gitlab-test\"\ngit push -u origin master\n```\n\n至此，可以到浏览器刷新test项目，发现已经上传成功。 \n\n## 常见问题和常用操作\n\n### 在执行 `git push -u origin master` 时可能会报如下错误：\n\n```bash\ngit@xxx's password:\nPermission denied, please try again.\ngit@xxx's password:\nPermission denied, please try again.\ngit@xxx's password:\ngit@xxx: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).\nfatal: Could not read from remote repository.\n\nPlease make sure you have the correct access rights\nand the repository exists.\n```\n\n**但此时我确实已经在本地生成了公私钥文件，而且密码输入的也是正确的。为什么还会报`Permission denied`呢？**\n\n这是因为我在生成公钥时使用了自定义的名称（如：gitlab_id_rsa、gitlab_id_rsa.pub）而不是 id_rsa 和 id_rsa.pub，于是我将生成的密钥文件进行改名，再执行git push操作，就可以了。\n\n### firewalld和firewall-cmd的使用方法\n\n**使用firewalld操控防火墙**（防火墙的开启、关闭、开机自启等）\n\n> 开启防火墙\n\n```shell\nsystemctl start firewalld\n```\n\n> 关闭防火墙\n\n```shell\nsystemctl stop firewalld\n```\n\n> 设置开机启动防火墙\n\n```shell\nsystemctl enable firewalld.service\n```\n\n> 设置开机禁用防火墙\n\n```shell\nsystemctl disable firewalld.service\n```\n\n> 查询防火墙状态\n\n```shell\nsystemctl status firewalld\n```\n\n**使用firewall-cmd配置端口**\n\n> 查询防火墙状态\n\n```shell\nfirewall-cmd --state\n```\n\n> 查看所有已开放的端口\n\n```shell\nfirewall-cmd --zone=public --list-ports\n```\n\n> 重新加载配置，更新防火墙规则\n\n```shell\nfirewall-cmd --reload\n```\n\n**对端口和通道进行配置**（修改配置后要重启防火墙）\n\n> 添加一个端口，并开启协议通道\n\n```shell\nfirewall-cmd --zone=public --add-port=80/tcp --permanent \n## 添加80端口，--zone表示作用域，--add-port是标识添加的端口和访问类型，--permanent表示设置为永久\nfirewall-cmd --zone=public --add-service=http --permanent \n## 开启http通道\n```\n\n> 移除某个端口\n\n```shell\nfirewall-cmd --zone=public --remove-port=80/tcp --permanent\n```\n\n> 重启防火墙（修改配置后要重启防火墙）\n\n```shell\nfirewall-cmd --reload\n```\n\n> 查看某个端口的开通状态\n\n```shell\nfirewall-cmd --zone=public --query-port=80/tcp\n```\n","tags":["centos","gitlab"],"categories":["web开发"]},{"title":"搭建私有化docker镜像仓库","url":"/2019/11/09/docker-image-repo/","content":"\n## 背景\n\n- 公司或个人项目代码不能公开，如何共享镜像或快速发布？\n- 在国内直接拉取官方镜像非常缓慢。如何才能快速取官方基础镜像呢？\n- 国内的网络环境下，项目在 `CI/CD` 过程中拉取镜像可能会花费比较多的时间，如何能加快拉取镜像的速度？\n\n没错，搭建私有镜像仓库吧。\n\n## 方案选择\n\n搭建私有镜像仓库有几种方式：\n\n1、官方 `registry` 方案，推荐使用 `registry:2` v2 版本的镜像\n\n2、`harbor` 方案， 则是在官方的基础上增加了权限控制、界面化等功能\n\n本次我们采用<span id=\"inline-blue\">harbor方案</span>进行搭建，操作系统为<span id=\"inline-blue\">Centos7.6 64位</span>。\n\n## 系统环境及配置要求\n\n| 资源 | 配置      | 说明       |\n| ---- | --------- | ---------- |\n| CPU  | 2核 起步  | 4核 更佳   |\n| Mem  | 4GB 起步  | 8GB 更佳   |\n| Disk | 40GB 起步 | 160GB 更佳 |\n\n注：硬盘主要用于存储镜像，镜像量大可以考虑加大。\n\n**软件要求**\n\n| 软件           | 版本           | 说明                                                         |\n| -------------- | -------------- | ------------------------------------------------------------ |\n| Python         | 2.7 以上       | Linux 服务器基本都安装了 2.7 版本，可以输入命令 `python` 确认是否已安装 |\n| Docker         | 1.10 以上      | 下面会介绍如何安装                                           |\n| Docker Compose | 1.6.0 以上     | 下面会介绍如何安装                                           |\n| Openssl        | 推荐用最高版本 | 生成证书，自备证书的忽略                                     |\n\n**注：这里使用的是HTTP方式搭建，所以openssl暂时没有用到。**\n\n## 安装Docker及Docker Compose（如已安装，请跳过此步）\n\n1、安装之前，先清除之前安装的旧版本 docker，如果有的话\n\n```shell\n$ sudo yum remove docker \\\n                  docker-client \\\n                  docker-client-latest \\\n                  docker-common \\\n                  docker-latest \\\n                  docker-latest-logrotate \\\n                  docker-logrotate \\\n                  docker-selinux \\\n                  docker-engine-selinux \\\n                  docker-engine\n```\n\n2、使用 repository 安装 docker ce\n\n```shell\n$ sudo yum install -y yum-utils device-mapper-persistent-data lvm2  ## 安装基础依赖包\n$ sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo ## 使用阿里源，速度杠杠的\n$ sudo yum install docker-ce  ## 直接运行会默认安装最新版\n```\n\n*注：如果想安装指定版本的docker-ce，可以先用命令查看版本号，然后再安装指定版本。*\n\n```shell\n$ sudo yum list docker-ce --showduplicates | sort -r ##查看版本号\n$ sudo yum install docker-ce-<VERSION STRING> ##安装指定版本，\n## 例如：yum install docker-ce-18.06.3.ce\n```\n\n3、安装docker-compose\n\ndocker-compose存放在github上，但由于国内访问github不太稳定，所以可从daocloud上进行下载。\n\n```shell\n$ curl -L https://get.daocloud.io/docker/compose/releases/download/1.24.1/docker-compose-`uname -s`-`uname -m` > /usr/local/bin/docker-compose\n$ chmod +x /usr/local/bin/docker-compose\n```\n\n*注：你可以通过修改上述URL中的版本（如：1.24.1），可以自定义您需要的版本。*\n\n4、启动docker（**这一步很重要**）\n\n```shell\n$ sudo systemctl start docker\n```\n\n## 开始搭建镜像仓库\n\n搭建步骤：\n\n- 下载`habor安装器`\n- 修改配置文件 `harbor.cfg`\n- 运行 `install.sh` 执行安装，此 shell 脚本内部会调用`./prepare`生成相关配置文件，再调用 `docker-compose` 来进行镜像拉取及启动。\n\n`harbor` 有两种方式进行安装，分为离线和在线。如果网络环境不佳，可以选择离线安装。\n\n这里选择在线方式（拉取远程镜像）安装：\n\n### 下载安装器\n\n```shell\n$ wget https://storage.googleapis.com/harbor-releases/release-1.6.0/harbor-online-installer-v1.6.3.tgz\n```\n\n解压安装程序：\n\n```shell\n$ tar -zxvf harbor-offline-installer-v1.6.3.tgz\n```\n\n### 修改harbor.cfg文件\n\n```shell\n$ cd harbor\n$ vim harbor.cfg\n```\n\n修改以下部分：\n\n```shell\nhostname = 本机IP地址 ##修改为自己的本机IP地址，如果是想通过外网访问的话，这里的IP地址要写成本机公网IP地址。\nharbor_admin_password = 登录密码 ##修改harbor的admin用户的密码\n```\n\n*注意：如果当前使用的服务器是从阿里云或其它云上购买的云主机，应注意在实例安全组中开放80端口。*\n\n为了方便后续管理，这里将harbor运行过程中产生的数据统一放在一个目录（/data/harbor）下面。\n\n创建/data/harbor目录：\n\n```shell\n$ mkdir -p /data/harbor\n```\n\n打开harbor.cfg文件并修改：\n\n```shell\nsecretkey_path = /data/harbor ##因为下面会修改docker-compose.yml文件中的secretkey，这里是为了保持这两个文件中的secretkey路径一致\n```\n\n### 修改docker-compose.yml文件\n\n将文件中的相关路径更改为/data/harbor，可直接使用如下配置：\n\n```yml\nversion: '2'\nservices:\n  log:\n    image: goharbor/harbor-log:v1.6.3\n    container_name: harbor-log \n    restart: always\n    volumes:\n      - /data/harbor/log/:/var/log/docker/:z\n      - ./common/config/log/:/etc/logrotate.d/:z\n    ports:\n      - 127.0.0.1:1514:10514\n    networks:\n      - harbor\n  registry:\n    image: goharbor/registry-photon:v2.6.2-v1.6.3\n    container_name: registry\n    restart: always\n    volumes:\n      - /data/harbor/registry:/storage:z\n      - ./common/config/registry/:/etc/registry/:z\n      - ./common/config/custom-ca-bundle.crt:/harbor_cust_cert/custom-ca-bundle.crt:z\n    networks:\n      - harbor\n    environment:\n      - GODEBUG=netdns=cgo\n    depends_on:\n      - log\n    logging:\n      driver: \"syslog\"\n      options:  \n        syslog-address: \"tcp://127.0.0.1:1514\"\n        tag: \"registry\"\n  postgresql:\n    image: goharbor/harbor-db:v1.6.3\n    container_name: harbor-db\n    restart: always\n    volumes:\n      - /data/harbor/database:/var/lib/postgresql/data:z\n    networks:\n      - harbor\n    env_file:\n      - ./common/config/db/env\n    depends_on:\n      - log\n    logging:\n      driver: \"syslog\"\n      options:  \n        syslog-address: \"tcp://127.0.0.1:1514\"\n        tag: \"postgresql\"\n  adminserver:\n    image: goharbor/harbor-adminserver:v1.6.3\n    container_name: harbor-adminserver\n    env_file:\n      - ./common/config/adminserver/env\n    restart: always\n    volumes:\n      - /data/harbor/config/:/etc/adminserver/config/:z\n      - /data/harbor/secretkey:/etc/adminserver/key:z\n      - /data/harbor/:/data/:z\n    networks:\n      - harbor\n    depends_on:\n      - log\n    logging:\n      driver: \"syslog\"\n      options:  \n        syslog-address: \"tcp://127.0.0.1:1514\"\n        tag: \"adminserver\"\n  ui:\n    image: goharbor/harbor-ui:v1.6.3\n    container_name: harbor-ui\n    env_file:\n      - ./common/config/ui/env\n    restart: always\n    volumes:\n      - ./common/config/ui/app.conf:/etc/ui/app.conf:z\n      - ./common/config/ui/private_key.pem:/etc/ui/private_key.pem:z\n      - ./common/config/ui/certificates/:/etc/ui/certificates/:z\n      - /data/harbor/secretkey:/etc/ui/key:z\n      - /data/harbor/ca_download/:/etc/ui/ca/:z\n      - /data/harbor/psc/:/etc/ui/token/:z\n    networks:\n      - harbor\n    depends_on:\n      - log\n      - adminserver\n      - registry\n    logging:\n      driver: \"syslog\"\n      options:  \n        syslog-address: \"tcp://127.0.0.1:1514\"\n        tag: \"ui\"\n  jobservice:\n    image: goharbor/harbor-jobservice:v1.6.3\n    container_name: harbor-jobservice\n    env_file:\n      - ./common/config/jobservice/env\n    restart: always\n    volumes:\n      - /data/harbor/job_logs:/var/log/jobs:z\n      - ./common/config/jobservice/config.yml:/etc/jobservice/config.yml:z\n    networks:\n      - harbor\n    depends_on:\n      - redis\n      - ui\n      - adminserver\n    logging:\n      driver: \"syslog\"\n      options:  \n        syslog-address: \"tcp://127.0.0.1:1514\"\n        tag: \"jobservice\"\n  redis:\n    image: goharbor/redis-photon:v1.6.3\n    container_name: redis\n    restart: always\n    volumes:\n      - /data/harbor/redis:/var/lib/redis\n    networks:\n      - harbor\n    depends_on:\n      - log\n    logging:\n      driver: \"syslog\"\n      options:  \n        syslog-address: \"tcp://127.0.0.1:1514\"\n        tag: \"redis\"\n  proxy:\n    image: goharbor/nginx-photon:v1.6.3\n    container_name: nginx\n    restart: always\n    volumes:\n      - ./common/config/nginx:/etc/nginx:z\n    networks:\n      - harbor\n    ports:\n      - 80:80\n      - 443:443\n      - 4443:4443\n    depends_on:\n      - postgresql\n      - registry\n      - ui\n      - log\n    logging:\n      driver: \"syslog\"\n      options:  \n        syslog-address: \"tcp://127.0.0.1:1514\"\n        tag: \"proxy\"\nnetworks:\n  harbor:\n    external: false\n```\n\n### 部署harbor\n\ncd到harbor目录下执行，\n\n```shell\n$ ./install.sh ##安装Harbor\n```\n\n接下来会经历4个Step，最终会输出类似如下信息，则表示安装成功，此时可以在浏览器中输入网址访问了。\n\n![](1.png)\n\n## 访问Harbor\n\n在浏览器中输入网址，输入账号和密码，登录Harbor。\n\n账号是admin，密码是刚才在`harbor.cfg`文件中设置的 `harbor_admin_password` 值。\n\n## 进行推送和拉取镜像测试\n\n1、在Harbor上新建一个项目，比如：onlytest\n\n![](2.jpg)\n\n2、因为 docker 默认不允许用非 `HTTPS` 方式推送镜像，所以如果你的镜像仓库是以HTTP方式访问，则需要修改下daemon.json文件并重启docker。\n\n打开`/etc/docker/daemon.json`（如果该文件不存在，就新建一个），修改以下内容：\n\n```json\n{\n  \"registry-mirror\": [\n    \"https://registry.docker-cn.com\"\n  ],\n  \"insecure-registries\": [\n    \"你的镜像仓库IP:端口\"\n  ]\n}\n```\n\n输入 `systemctl restart docker` 重启docker。\n\n3、登录私有docker镜像仓库\n\n```shell\n$ docker login 仓库IP:端口\n```\n\n输入Username 和 Password，完成登录操作。\n\n3、修改待推送的镜像名称\n\n```shell\n$ docker tag 镜像ID 镜像名称:TAG名称\n## 如：docker tag ba5877dc9bec 192.168.199.100:5000/onlytest/alpine:v0.1\n```\n\n4、将镜像推送到私有镜像仓库\n\n```shell\n$ docker push 镜像名称:镜像TAG\n## 如：docker push 192.168.199.100:5000/onlytest/alpine:v0.1\n```\n\n然后你会在刚才在Harbor上新建的项目中看到推送的镜像。\n\n![](3.jpg)\n\n5、将刚才推送上去的镜像拉取到本地\n\n> 先删除刚才第4步中推送到仓库里的本地镜像，方便下面验证pull操作。\n\n```shell\n$ docker rmi 镜像仓库IP:端口/你在Harbor上建的项目/镜像名称:TAG名称\n## 如：docker rmi 192.168.199.100:5000/onlytest/alpine:v0.1\n```\n\n> 拉取远程私有仓库镜像到本地\n\n```shell\n$ docker pull 镜像仓库IP:端口/你在Harbor上建的项目/镜像名称:TAG名称\n## 如：docker pull 192.168.199.100:5000/onlytest/alpine:v0.1\n```\n\n在本地用`docker images`查看拉取的镜像，会发现镜像已经拉取下来了。\n\n**注：如果需要登出私有镜像仓库，可使用 `docker logout`登出。**\n\n```shell\n$ docker logout 镜像仓库IP:端口\n## 如：docker logout 192.168.199.100:5000\n```\n\n## 常见问题\n\n### 修改了harbor.cfg中的hostname后，运行 ./install.sh 时报如下错误：\n\n```shell\nPlease set hostname and other necessary attributes in harbor.cfg first. DO NOT use localhost or 127.0.0.1 for hostname, because Harbor needs to be accessed by external clients.\nPlease set --with-notary if needs enable Notary in Harbor, and set ui_url_protocol/ssl_cert/ssl_cert_key in harbor.cfg bacause notary must run under https.\nPlease set --with-clair if needs enable Clair in Harbor\n```\n\n**原因：**是由于在修改hostname值的时候，将原先的hostname那行注释掉了，然后新增了一行hostname，如：\n\n```shell\n#hostname = reg.mydomain.com\nhostname = 192.168.174.136\n```\n\n**解决方法：**在原始的脚本基础上直接修改hostname值，**不要再新增一行hostname**。\n\n### 每次修改harbor.cfg文件都需要重启harbor才会生效，操作方法如下：\n\n```shell\n$ docker-compose down ##停止和移除所有harbor相关的容器\n$ ./prepare ##重新配置harbor\n$ docker-compose up -d ##创建容器并启动harbor\n```\n\n然后可以运行命令 `docker ps`看下容器状态。\n\n### 在重启harbor过程中，输入`docker-compose up -d`时报错：\n\n```bash\nCreating network \"harbor_harbor\" with the default driver\nERROR: Failed to Setup IP tables: Unable to enable SKIP DNAT rule:  (iptables failed: iptables --wait -t nat -I DOCKER -i br-4e0466e6358e -j RETURN: iptables: No chain/target/match by that name.\n (exit status 1))\n```\n\n此时需要重启docker，输入命令 `systemctl restart docker`，再输入`docker-compose up -d`，成功启动harbor。\n\n### 在搭建过程中（比如在输入`docker-compose up`命令时）遇到如下错误：\n\n```shell\nERROR: Couldn't connect to Docker daemon at http+docker://localunixsocket - is it running?\n\nIf it's at a non-standard location, specify the URL with the DOCKER_HOST environment variable.\n```\n\n导致这个问题的**原因实在多**，所以把可能的解决方法都列出来，我想总有一款适合您。\n\n1、docker服务没启动，那就启动\n\n```shell\n$ sudo systemctl start docker     // 或者 sudo service docker start\n$ docker-compose up\n```\n\n2、docker服务启动了，但是一些缓存影响了\n\n*那就重启*\n\n```shell\n$ sudo systemctl restart docker   // 或者 sudo service docker restart\n$ docker-compose up\n```\n\n3、当前用户不在docker用户组\n\n*那就把自己加到docker用户组*\n\n```shell\n$ sudo gpasswd -a ${USER} docker\n$ docker-compose up\n```\n\n*添加到`docker`用户组后要重新登录shell再`up`*\n\n4、也许用sudo可能有效\n\n```shell\n$ sudo docker-compose up\n```\n\n5、docker-compose版本太老了\n\n*那就更新版本*\n\n```shell\n$ curl -L https://get.daocloud.io/docker/compose/releases/download/1.24.1/docker-compose-`uname -s`-`uname -m` > /usr/local/bin/docker-compose\n```\n\n*点击查看[docker-compose官方安装教程](https://docs.docker.com/compose/install/#install-compose)（可能需要梯子）或 登录[daocloud查看安装教程](http://get.daocloud.io/#install-compose)（推荐）*\n\n","tags":["docker","私有化"],"categories":["docker"]},{"title":"docker基本用法","url":"/2019/07/16/docker-usage/","content":"\n### docker基本操作\n\n#### 查看docker概要\n\n```\ndocker info\n```\n\n#### 查看docker帮助文档\n\n```\ndocker -help\n```\n\n#### 查看docker状态\n```\nsystemctl status docker\n```\n\n#### 启动docker\n```\nsystemctl start docker\n```\n\n#### 关闭docker\n```\nsystemctl stop docker\n```\n\n#### 重启docker\n\n```\nsystemctl restart docker\n```\n\n### docker镜像操作\n\n#### 查看镜像列表\n\n```\ndocker images\n```\n\n#### 搜索镜像\n\n```\ndocker search 镜像名称\n```\n\n#### 配置docker镜像加速器\n\n拉取镜像 默认是从 Docker Hub 镜像仓库上进行获取的，即 [https://hub.docker.com/，](https://hub.docker.com/%EF%BC%8C) 由于国内无法拉取或者会非常慢，我们可以修改拉取地址为一些国内的镜像。\n关于拉取地址的配置在：etc/docker/daemon.json\n\n我们修改其即可\n\n```json\n{ \n\t\"registry-mirrors\": [\n\t\t\"https://docker.mirrors.ustc.edu.cn\"\n \t] \n}\n```\n\n#### docker镜像拉取、删除\n\n拉取镜像\n\n```bash\ndocker pull 镜像名称\n```\n\n删除镜像\n\n```\ndocker rmi 镜像ID\n```\n\n删除所有镜像\n\n```\ndocker rmi `docker images -q`\n```\n\n### docker容器操作\n\n#### 查看容器\n\n查看正在运行的容器\n\n```\ndocker ps\n```\n\n查看所有容器（包含正在运行的容器以及之前启动过的容器）\n\n```\ndocker ps -a\n```\n\n查看最后一次运行的容器\n\n```\ndocker ps -l\n```\n\n查看停止的容器\n\n```\ndocker ps -f status=exited\n```\n\n#### 容器创建\n\n创建交互式容器：当退出容器（如输入Ctrl + C 或 exit）时，容器就关闭了。\n\n```\ndocker run -it --name=容器名称 镜像名称\n```\n\n如果需要做端口映射（比如将宿主机的某个端口映射到容器中的某个端口上），则要加上-p参数。\n\n```\ndocker run -it --name=容器名称 -p 8888:8080 镜像名称\n```\n\n如果要映射多个端口，则加上多个-p参数即可，如：\n\n```\ndocker run -it --name=容器名称 -p 8888:8080 -p 1080:1080 镜像名称\n```\n\n创建守护式容器：当退出容器（如输入Ctrl + C 或 exit）时，容器依然处于运行状态。\n\n```\ndocker run -id --name=容器名称 -p 8888:8080 镜像名称\n```\n\n在创建完守护式容器后，并未直接进入到容器中，所以需要再输入下面的命令来进入容器内。\n\n```\ndocker exec -it 容器名称 /bin/bash\n```\n\n#### 容器启动\n\n```\ndocker start 容器名称/容器ID\n```\n\n#### 容器停止\n\n```\ndocker stop 容器名称/容器ID\n```\n\n#### 容器删除\n\n删除单个容器\n\n```\ndocker rm 容器名称/容器ID\n```\n\n删除所有容器\n\n```\ndocker rm `docker ps -a -q`\n```\n\n*注意：只能删除已经关闭的容器*\n\n ### docker部署操作\n\n#### docker文件拷贝\n\n将需要放在docker容器内的文件拷贝到容器中，在宿主机命令行中输入：\n\n```\ndocker cp 宿主机待拷贝的文件 容器名称:容器目录\n如：docker cp ./test.txt ubuntu01:/home\n```\n\n#### docker目录挂载\n\n在创建容器的时候，我们可以将宿主机的某个目录映射到容器内的目录，这样如果修改宿主机某个目录的文件内容，容器内对应的文件内容也会随之改变。\n\n在创建容器时添加参数 `--privileged=true`\n\n```\ndocker run -id -v 宿主机目录:容器目录 --name=容器名称 --privileged=true 镜像名称\n如：docker run -id -v /home/test:/root/test --name=ubuntu01 --privileged=true ubuntu_image\n```\n\n#### docker备份\n\n第一步：将容器保存为镜像\n\n```\ndocker commit 容器名称 保存的新镜像名称\n```\n\n如需修改TAG，则输入以下命令，然后用`docker images`会发现有两个镜像ID一样但镜像名称不同的镜像。\n\n```\ndocker tag 镜像ID 镜像名称:TAG名称\n```\n\n第二步：将镜像打包备份\n\n```\ndocker save 镜像名称 -o 打包后的文件名称\n如：docker save iamge_name -o ./pack_name.tar\n```\n\n将镜像打包后就可以进行迁移和部署了。\n\n#### 镜像加载/部署\n\n```\ndocker load -i 镜像文件名称\n```\n\n### 推送自己的镜像\n\n首先检查按照镜像仓库的规定修改镜像名称和镜像TAG：\n\n```\ndocker tag 镜像ID 镜像名称:TAG名称\n如：docker tag ba5877dc9bec 127.0.0.1:5000/ubuntu:v0.1\n```\n\n然后登录镜像仓库，根据提示输入用户名和密码：\n\n```\ndocker login 镜像仓库IP\n```\n\n最后将自己的镜像push到镜像仓库：\n\n```\ndocker push 镜像名称:镜像TAG\n```\n\n**注意事项：**\n\n如果你不想使用 `127.0.0.1:5000` 作为仓库地址，比如想让本网段的其他主机也能把镜像推送到私有仓库。你就得把例如 `192.168.199.100:5000` 这样的内网地址作为私有仓库地址，这时你会发现无法成功推送镜像。\n\n这是因为 docker 默认不允许非 `HTTPS` 方式推送镜像。我们可以通过 Docker 的配置选项来取消这个限制。\n\n如果您的宿主机系统是Ubuntu、Debian、Centos等系统，请在 `/etc/docker/daemon.json` 中写入如下内容（如果文件不存在请新建该文件），此处以 `192.168.199.100:5000` 为例：\n\n```json\n{\n  \"registry-mirror\": [\n    \"https://registry.docker-cn.com\"\n  ],\n  \"insecure-registries\": [\n    \"192.168.199.100:5000\"\n  ]\n}\n```\n\n然后输入`systemctl restart docker`重启docker。\n\n对于Windows、MacOS系统，则可在Docker for Windows 、Docker for Mac客户端软件的设置中编辑 `daemon.json`文件， 增加和上述一样的仓库地址即可。\n\n### Dockerfile的基本用法\n\n#### Dockerfile文件格式说明\n\n1、Dockerfile整体就两类语句组成：\n\n- \\# Comment 注释信息\n- Instruction arguments 指令 参数，一行一个指令。\n\n2、Dockerfile文件名首字母必须大写。\n\n3、Dockerfile指令不区分大小写，但是为方便和参数做区分，通常指令使用大写字母。\n\n4、Dockerfile中指令按顺序从上至下依次执行。\n\n5、Dockerfile中第一个非注释行必须是FROM指令，用来指定制作当前镜像依据的是哪个基础镜像。\n\n6、Dockerfile中需要调用的文件必须跟Dockerfile文件在同一目录下，或者在其子目录下，父目录或者其它路径无效。\n\n#### 用Dockerfile构建镜像\n\n```bash\n$ docker build -t 镜像名称:TAG名称 .\n```\n\n命令说明：\n\n- build -t 指定通过Dockerfile来创建镜像\n- . 表示在当前路径寻找Dockerfile文件\n\n创建完成后，可用`docker images`查看新创建的镜像。\n\n#### 运行镜像\n\n```shell\n$ docker run -id --name=容器名称 -p 8888:8080 镜像名称:镜像TAG\n$ docker exec -it 容器名称 /bin/bash\n```\n\n*注：此时是将宿主机的 8888 端口映射到容器中的 8080 端口上。如果是临时测试，可以在运行容器时加上`--rm`参数，这样在退出容器以后，容器就被自动删除了。如果不加`--rm` ，则退出容器后，容器只是停止运行，而数据依然被保留。*\n\n更多关于Dockerfile的详细介绍，请参考链接：https://www.cnblogs.com/ccbloom/p/11174186.html，这里写的非常详细。\n\n### Docker Compose基本用法\n\nDocker Compose是一个定义和运行多容器应用的单机编排工具。通过Docker Compose你可以使用一个单一的YAML文件来配置多个应用服务，通过一条命令，就可以将所有配置的服务全部启动起来。\n\n在介绍docker compose之前，我们先简单了解下YAML文件：\n\n**YAML（Yet Another Markup Language）**（发音 /ˈjæməl/ ）是一种基于Unicode容易阅读，容易和脚本语言交互的，用来表达资料序列的编程语言。\n\n#### yml的基本语法\n\n1、yml文件以缩进代表层级关系\n\n2、缩进不允许使用tab，只能使用空格\n\n3、空格的个数不重要，只要相同层级的元素左对齐即可\n\n4、大小写敏感\n\n5、数据格式为，名称:(空格)值\n\n6、‘#’表示注释，且只能单行注释，注释内容是从#开始处到行尾\n\n7、破折号后面跟一个空格（a dash and space）表示列表。\n\n#### yml支持的数据格式\n\n1、对象：键值对的集合(key:value)\n\n- 字符串不用使用双引号或单引号圈起来\n- 双引号圈住时不会转义字符串中的特殊字符\n- 单引号圈住时会转义字符串中的特殊字符\n\n2、数组：一组按顺序排列的值\n\n> 多行写法\n\n数组名:\n\n​       - 元素1\n\n​       - 元素2\n\n​       - 元素3\n\n> 单行写法：\n\n数组名: [元素1,元素2,元素3]\n\n3、字面量：单个的、不可再分的值（数字、字符串、布尔值）\n\n> 以上内容的参考链接：\n\n- https://blog.csdn.net/wingsb/article/details/85270529\n- https://blog.csdn.net/zyp1376308302/article/details/81223890\n- https://www.cnblogs.com/hellxz/p/11039514.html\n\n关于docker compose的用法，在网上有很多的介绍，具体可以参考这个：https://www.cnblogs.com/breezey/p/9426085.html\n\n这里只简单介绍下常用的一些命令以及我自己在使用过程中的一些经验。\n\n#### docker-compose 常用命令\n\n*说明：docker-compose命令必须在 docker-compose.yml 文件所在目录下执行才有效*\n\n**有两种方式可以有效运行docker-compose命令**\n\n1、在docker-compose.yml文件所在目录下执行docker-compose命令：\n\n```\ndocker-compose up    ##前台运行\n或\ndocker-compose up -d ##后台运行\n```\n\n2、使用 `-f` 参数指定compose文件，例如：\n\n```\ndocker-compose -f /opt/test-compose.yml up    ##前台运行\n或\ndocker-compose -f /opt/test-compose.yml up -d ##后台运行\n```\n\n| 命令                                        | 说明                                                         |\n| ------------------------------------------- | ------------------------------------------------------------ |\n| docker-compose up -d                        | 构建并启动所有容器                                           |\n| docker-compose up -d -\\-build               | 在dockerfile更新后，会自动更新image                          |\n| docker-compose up -d nginx                  | 构建并启动nignx容器                                          |\n| docker-compose exec nginx bash              | 登录到nginx容器中                                            |\n| docker-compose down                         | 删除所有容器,镜像                                            |\n| docker-compose ps                           | 显示所有容器                                                 |\n| docker-compose restart nginx                | 重启nginx容器                                                |\n| docker-compose run nginx ping www.baidu.com | 在nginx容器上执行ping命令                                    |\n| docker-compose build nginx                  | 构建nginx镜像                                                |\n| docker-compose build --no-cache nginx       | 构建nginx镜像过程中不使用缓存                                |\n| docker-compose logs nginx                   | 查看nginx容器的日志                                          |\n| docker-compose logs -f nginx                | 查看nginx容器的实时日志                                      |\n| docker-compose config  -q                   | 验证（docker-compose.yml）文件配置。<br>配置正确时，不输出任何内容；<br>文件配置错误，输出错误信息。 |\n| docker-compose pause nginx                  | 暂停nginx容器                                                |\n| docker-compose unpause nginx                | 恢复nginx容器                                                |\n| docker-compose rm nginx                     | 删除容器（删除前必须关闭容器）                               |\n| docker-compose stop nginx                   | 停止nignx容器                                                |\n| docker-compose start nginx                  | 启动nignx容器                                                |\n\n> 参考链接：\n\n- https://www.cnblogs.com/minseo/p/11548177.html\n- https://blog.csdn.net/weixin_30546933/article/details/96719086\n\n- https://blog.csdn.net/yanxilou/article/details/99648359\n\n#### docker-compose.yml配置文件说明\n\n其实网上有很多关于配置文件的说明，这里就不再做详细介绍。这里介绍一下docker-compose如何通过文件来声明默认的docker容器环境变量。\n\n*Docker Compose支持使用声明默认环境变量的`.env`文件启动，这个文件的位置需要与 docker-compose.yml 同级目录。我们只需要在同级目录下创建`.env`文件来指定默认的环境变量，这些变量可以部分或完整作为配置的内容，大大简化我们的配置，以及一处修改多处生效的目的。*\n\n##### 语法规则\n\n- .env文件中的每一行都是`KEY=VAL`格式\n- 以`#`开头的内容将被注释\n- 忽略空白行\n- `.env`中的KEY可以在`docker-compose.yml`中作为某个`VAL`的一部分\n\n##### 测试\n\n这里拿个nginx做测试吧，我们最后使用`docker-compose config`进行查看当前环境生效的配置。\n\n1、新建并进入目录`test`，创建`docker-compose.yml`文件\n\n```shell\n$ mkdir test\n$ cd test\n$ vim docker-compose.yml\n```\n\n2、往`docker-compose.yml`文件中写入如下内容：\n\n```yaml\nversion: \"3\"\nservices: \n    mynginx: \n        image: nginx:${TAG}\n        ports: \n            - 80:80\n```\n\n3、如果我们此时直接启动`docker-compose config` 我们会得到如下输出：\n\n```shell\n$ docker-compose config\nWARNING: The TAG variable is not set. Defaulting to a blank string.\nservices:\n  mynginx:\n    image: 'nginx:'\n    ports:\n    - 80:80/tcp\nversion: '3.0'\n```\n\n*如你所见，由于引用的变量TAG不存在，而被当成空字符串进行赋值。*\n\n4、创建`.env`文件并在文件中添加如下内容：\n\n```shell\n# .env the default environment config file\nTAG=1.7.9\n```\n\n5、再次启动`docker-compose config`\n\n```shell\n$ docker-compose config\nservices:\n  mynginx:\n    image: nginx:1.7.9\n    ports:\n    - 80:80/tcp\nversion: '3.0'\n```\n\n此时会发现变量TAG被.env文件中的字符串赋值。\n\n**注意：**这个默认的环境变量配置的优先级略低，如果是从docker-compose run命令中传入相同的KEY，则yml配置文件中的值会被覆盖。\n\n> 参考链接：\n\n- https://www.cnblogs.com/breezey/p/9426085.html\n- https://blog.csdn.net/qq_36148847/article/details/79427878\n- https://www.cnblogs.com/hellxz/p/11039514.html\n\n### 实战经验\n\n目前 Docker 官方已开始推荐使用 `Alpine` 替代之前的 `Ubuntu` 做为基础镜像环境。`Alpine` 操作系统是一个面向安全的轻型 `Linux` 发行版。`Alpine` 提供了自己的包管理工具 `apk`，可以通过 `https://pkgs.alpinelinux.org/packages` 网站上查询包信息，也可以直接通过 `apk` 命令直接查询和安装各种软件。\n\nAlpine Docker 镜像也继承了 Alpine Linux 发行版的这些优势。相比于其他 Docker镜像，它的容量非常小，仅仅只有 5 MB 左右（对比 Ubuntu 系列镜像接近 200 MB），且拥有非常友好的包管理机制。\n\n#### 拉取Alpine基础镜像\n\n```\ndocker pull alpine\n```\n\n#### 进入Alpine Docker容器\n\n如果使用之前提到的进入ubuntu docker容器的方式：\n\n```\ndocker exec -it 容器名称 /bin/bash\n```\n\n会遇到下面类似的报错：\n\n```\nOCI runtime exec failed: exec failed: container_linux.go:348: starting container process caused \"exec: \\\"/bin/bash\\\": stat /bin/bash: no such file or directory\": unknown\n```\n\n这是因为Alpine中没有`bash`。所以需要这样登录：\n\n```\ndocker exec -it 容器名称 sh\n```\n\n#### 在Alpine中安装软件包\n\n```\napk add --no-cache <package>\n```\n\n#### 如何清除docker镜像列表中带有<none\\>:<none\\>的镜像\n\n我们在构建过Docker镜像的电脑上查看本地镜像列表，有可能看到下图红框中的镜像，即在列表中展示为<none\\>:<none\\>，如下图所示：\n\n![](1.jpg)\n\n这种镜像在Docker官方文档中被称作dangling images，指的是没有标签并且没有被容器使用的镜像。\n\n**下面我们来简单梳理下dangling images是怎么产生的，结合上面那张图来看：**\n\n1、第一次构建镜像时生成的镜像ID为079dbd67f9f4，此镜像会被构建工具加上标签bolingcavalry/eureka-server:0.0.1-SNAPSHOT；\n2、第二次构建镜像时生成的镜像ID为e40a97f764ef，此镜像会被构建工具加上标签bolingcavalry/eureka-server:0.0.1-SNAPSHOT，\n3、此时Docker会自动移除079dbd67f9f4的标签，那么这时候079dbd67f9f4就变成了dangling images，即在镜像列表中展示为<none\\>:<none\\>。\n\n**dangling images产生的愿意我们已经知道了，那么我们该如何清理它们呢？**\n\n执行命令`docker image prune`即可批量删除dangling images。\n\n**刚才我们说满足dangling images需要两个条件：没有标签、且不再被容器使用，那么如果一个镜像没有标签，但仍在被容器使用，此时用 prune 命令会把它删除吗？**\n\n答案是，不会把它删除的。docker image prune是用来清理dangling images的，如果某个镜像正在被使用，那就不算是dangling images，也就不会被prune清理掉。","tags":["docker","docker-compose"],"categories":["docker"]},{"title":"手机在ROOT过程中踩得一些坑","url":"/2019/05/26/root-exp/","content":"\n**手机型号：**HM Note 1S-红米Note4G电信版\n\n**系统版本：**Android4.4.4\n\n**MIUI版本：**MIUI9.2稳定版\n\n**一切以一次无意中的版本升级开始 ~~~**\n\n今天由于某种原因，不小心点击了系统更新，把版本升级到了MIUI9.2版本，需要重新root手机，之前我使用kingroot来root手机，虽然重启了几次，但最终还是成功root了。\n\n手机版本升级完之后，我从浏览器中下载了kingroot，在root的过程中，手机也重启了好几次，不过经过一番折腾，最终root成功。root成功以后，为了让手机运行不那么卡顿，我把手机中的一些系统软件给删掉了，还删了一些所谓的核心系统软件，比如：邮件、计算器、小米相关的软件，其中就把小米账号给删了。删除完毕后，我准备通过USB调试一些android程序，发现入坑了。当我打开开发者模式后，尝试打开USB调试（安全设置）选项时，系统提示说要登录小米账号。顿时懵逼了，小米账号？不是刚刚被我手贱给删了吗？！后来折腾了一会，想各种办法绕过小米账号，最终发现这条路是不通的。一番苦思冥想，在手机上下载了一份最新版本完整包，把整个系统都重新安装了一遍，总算把小米账号软件给折腾回来了。\n\n“新”手机重启后，提示需要输入小米账号和密码来激活设备，此时我知道又遇到了一个坑，因为我忘了小米账号的密码。然后我登录小米账号（id.mi.com），重置了密码，顺便把网站上的设备管理中的红米设备给删除了。这样就完事了吗？我只能说太天真了。这里插一句，我登录小米云服务（i.mi.com）之后，发现我的红米手机里的通讯录、短信、照片全部在云服务里保存了一份，我自己都不知道是什么时候传到上面的，只能说小米太贼了。我赶忙将这些都删掉了，天知道这些信息是不是已经被小米卖了？！好了，继续说这个激活的坑吧，重置密码+云端删除设备后，重启手机，还是提示要激活设备，输入密码，提示RPC错误（看来又踩了一个坑）。这次是彻底没辙，然后就打电话个小米客服，客服说你登录小米云服务，找到“查找设备”，点击“关闭查找手机”，然后重启你的手机（保证你手机里的SIM卡可以联网），就可以不用激活设备了。我照做一番之后，果真解决了，不需要激活设备了。接下来root手机，登录小米账号，打开USB调试模式，再也不敢删除小米账号软件了，多么惨痛的教训啊。\n\n总结一下这些坑：\n\n1、手机root用kingroot，root过程中手机会重启几次。\n\n2、打开USB调试前，需要先登录小米账号。\n\n3、手机root后，不要删除小米账号等你看不懂/拿不准的系统软件。\n\n4、关闭小米云服务，防止手机资料被上传到云端。\n\n5、没事别随便升级MIUI版本和系统，且用且珍惜。\n\n","tags":["root","红米手机"],"categories":["android系统"]},{"title":"Shadowsocks客户端《从入门到放弃》—— 使用v2ray替代","url":"/2018/12/16/v2ray/","content":"\n## 信息更新：2019-10-03\n\n前两天突然发现不能科学上网了，怀疑是shadowsocks的服务（用的是cfb的加密方式）被封禁了，后来网上查了一下，确实如此。所以换成了v2ray的方式，v2ray是目前比较稳定的使用方式，虽然速度不是很快，但能满足基本的需求。就像一个博客上写的，虽然有很多加速的方式，但建议大家不要折腾，**能用**总比**加速之后被封**好得多。\n\n## 为何放弃使用Shadowsocks客户端\n\n其实我最开始接触的翻墙软件是Shadowsocks。一开始从官网下载了Windows 4.1.2客户端版本，用着也挺不错，但后来发现，每次运行Shadowsocks客户端的时候，只要使用Foxmail发邮件，Foxmail必崩。这就让我无法在Windows上同时使用Shadowsocks和Foxmail，但v2ray的及时出现，挽救了这一切~~~\n\n## 什么是v2ray\n\n在介绍v2ray之前，先说说ProjectV，Project V 是一个工具集合，它可以帮助你打造专属的基础通信网络。Project V 的核心工具称为`v2ray`，其主要负责网络协议和功能的实现，与其它 Project V 通信。v2ray 可以单独运行，也可以和其它工具配合，以提供简便的操作流程。更多细节请点击 [v2ray官网](https://www.v2ray.com/) 查阅。\n\n## v2ray 和 Shadowsocks的区别\n\nv2ray 更像是一个集成工具，它集合了多种多样的协议（包括 Socks、HTTP、Shadowsocks、VMess 等）和功能，对个人用户而言像是一个工具箱，可以使用各种各样的工具组合。对开发者而言像是一个脚手架，可以在此基础上开发扩充自己需要的功能而节省开发时间。\n\nv2ray的主要特性有：\n\n- 多入口多出口: 一个 v2ray 进程可并发支持多个入站和出站协议，每个协议可独立工作。\n\n- 可定制化路由: 入站流量可按配置由不同的出口发出。轻松实现按区域或按域名分流，以达到最优的网络性能。\n\n- 多协议支持: v2ray 可同时开启多个协议支持，包括 Socks、HTTP、Shadowsocks、VMess 等。每个协议可单独设置传输载体，比如 TCP、mKCP、WebSocket 等。\n\n- 隐蔽性: v2ray 的节点可以伪装成正常的网站（HTTPS），将其流量与正常的网页流量混淆，以避开第三方干扰。\n\n- 反向代理: 通用的反向代理支持，可实现内网穿透功能。\n\n- 多平台支持: 原生支持所有常见平台，如 Windows、Mac OS、Linux，并已有第三方支持移动平台。\n\n## 安装和使用v2ray\n\n*这方面的材料比较多，在此推荐一篇v2ray的安装和使用教程：https://yuan.ga/v2ray-complete-tutorial/ ，请自行查阅。如果您已经搭建好科学上网的服务端，只是单纯想安装和使用v2ray客户端进行科学上网的话，请参阅下一章节的简易教程：**基于v2ray搭建客户端代理***\n\n为防止上述v2ray的教程被封，下面简单说明下v2ray的服务端搭建方法（基于CentOS 7 64位系统）：\n\nV2Ray 官方维护并提供了适用于大多数主流系统的自动安装脚本，只需一行命令即可完成安装，当你想要更新V2Ray 的时候同样只需要运行下面一行命令。\n\n```bash\nbash <(curl -L -s https://install.direct/go.sh)\n# 上列命令会自动安装 V2Ray，然后执行下面命令运行V2Ray\nsystemctl start v2ray\n```\n\n![](8.png)\n\n当你使用脚本自动安装结束后，此时服务端的部署已经完成了，脚本不仅安装了 V2Ray，还在配置中随机生成了一个 5 位数端口以及 UUID 供我们直接使用，所以我们无需进一步配置服务端，这时已经获得了三个必要的信息：IP、端口（Port）、id（UUID）。\n\n安装完成后会新增下列文件：\n\n- /usr/bin/v2ray/v2ctl：V2Ray 工具，用于给程序自身调用\n- /usr/bin/v2ray/v2ray：V2Ray 核心程序\n- /etc/v2ray/config.json：配置文件\n- /usr/bin/v2ray/geoip.dat：IP 数据文件，V2Ray 路由功能时有用，下同\n- /usr/bin/v2ray/geosite.dat：域名数据文件\n\n之后就可以使用 <span id=\"inline-blue\"> systemctl start|restart|stop|status v2ray</span>  查看和控制 V2Ray 的运行。\n\n## 在Android上安装和使用v2ray客户端\n\nAndroid上的客户端推荐使用**BifrostV**，可从Google Play商店中下载。BifrostV的整体布局设计模仿了安卓版Shadowsocks，当你使用过安卓版Shadowsocks，再使用这个软件时就不存在太多障碍了。BifrostV支持 VMess、Shadowsocks、SOCKS 等协议，也就是说上述协议的连接只要一个客户端就可以搞定了。BifrostV中有少量广告（设置中有关闭广告选项，但需要Google Play的支持），希望用户可以理解开发者的劳动成果，包容那点广告或选择捐赠支持开发者。\n\n在使用BifrostV时，有个功能比较实用：首页->点击“+”号->手动设置，在配置页面的最下面有个`分应用模式`。\n\n![](1.png)\n\n开启`分应用模式`后，可以选择哪些APP走VPN，哪些APP不走VPN。如下图所示，Twitter需要走VPN，那么就把该APP选中；WPS Office不需要走VPN，那么就不用勾选它。\n\n![](2.png)\n\n可惜的是，v2ray在iPhone和iPad等iOS设备上，目前还没有官方客户端。不过还是一些第三方APP可以使用的，具体可参考该链接：https://ssr.tools/295 。\n\n## 在Windows上搭建v2ray客户端代理\n\n此处以Windows10系统为例，讲述如何通过v2ray搭建客户端代理，并使用chrome浏览器科学上网。\n\n### 安装v2ray客户端\n\n1、通过Github下载v2ray客户端，打开链接：https://github.com/v2ray/v2ray-core/releases ，往下浏览可找到Windows平台的v2ray客户端。如果您的系统是32位的，请选择并下载v2ray-windows-32.zip；如果您的系统是64位的，请选择并下载v2ray-windows-64.zip。\n\n2、下载完毕后，将zip包解压到任意目录下，然后打开解压后的目录，找到config.json文件并打开。\n\n![](3.png)\n\n### 配置config.json\n\n此处分别以vmess和shadowsocks为例，讲述如何配置config.json。\n\n- 以**vmess**为例（其中传输协议为TCP）：把当前config.json文件内容清空，将以下内容复制到config.json文件中。\n\n```json\n{\n    \"log\":{\n        \"loglevel\": \"warning\"\n      },\n    \"inbounds\":[\n        {\n            \"listen\": \"127.0.0.1\",\n            \"port\": 1080,\n            \"protocol\": \"socks\",\n            \"domainOverride\": [\"tls\",\"http\"],\n            \"settings\": {\n              \"auth\": \"noauth\",\n              \"udp\": true\n            },\n            \"tag\":\"instag_1080\"\n        }\n    ],\n    \"outbounds\":[\n        {\n            \"protocol\": \"vmess\",\n            \"settings\": {\n            \"vnext\": [\n                {\n                    \"address\": \"替换成你的IP\",\n                    \"port\": 替换成你的端口号,\n                    \"users\": [\n                        {\n                        \"id\": \"替换成你的UUID\",\n                        \"level\": 1,\n                        \"alterId\": 修改成你的ID，注意与你在服务端设置的alterId保持一致\n                        }\n                    ]\n                }\n            ]\n            },\n            \"streamSettings\": {\n                \"network\": \"tcp\",\n                \"sockopt\": {\n                    \"mark\": 0,\n                    \"tcpFastOpen\": true,\n                    \"tproxy\": \"off\"\n                  }\n                },\n            \"mux\": {\"enabled\": false},\n            \"tag\": \"outstag_1080\"\n        }\n    ],\n    \"routing\":{\n        \"domainStrategy\": \"IPIfNonMatch\",\n        \"rules\": [\n            {\n                \"type\": \"field\",\n                \"inboundTag\": [\n                    \"instag_1080\"\n                ],\n                \"outboundTag\": \"outstag_1080\"\n            }\n        ],\n        \"balancers\": []\n    }\n}\n```\n\n- 以**shadowsocks**为例：把当前config.json文件内容清空，将以下内容复制到config.json文件中。\n\n```json\n{\n    \"log\":{\n        \"loglevel\": \"warning\"\n      },\n    \"inbounds\":[\n        {\n            \"listen\": \"127.0.0.1\",\n            \"port\": 1080,\n            \"protocol\": \"socks\",\n            \"domainOverride\": [\"tls\",\"http\"],\n            \"settings\": {\n              \"auth\": \"noauth\",\n              \"udp\": true\n            },\n            \"tag\":\"instag_1080\"\n        }\n    ],\n    \"outbounds\":[\n        {\n            \"protocol\": \"shadowsocks\",\n            \"settings\": {\n              \"servers\": [\n                {\n                  \"address\": \"替换成你的IP\",\n                  \"port\": 替换成你的端口号,\n                  \"method\": \"替换成你的加密方式\",\n                  \"password\": \"替换成你的密码\",\n                  \"ota\": false,\n                  \"level\": 0\n                }\n              ]\n            },\n            \"streamSettings\": {},\n            \"mux\": {\n              \"enabled\": false,\n              \"concurrency\": 8\n            },\n            \"tag\":\"outstag_1080\"\n        }\n    ],\n    \"routing\":{\n        \"domainStrategy\": \"IPIfNonMatch\",\n        \"rules\": [\n            {\n                \"type\": \"field\",\n                \"inboundTag\": [\n                    \"instag_1080\"\n                ],\n                \"outboundTag\": \"outstag_1080\"\n            }\n        ],\n        \"balancers\": []\n    }\n}\n```\n\n### 运行v2ray客户端\n\n打开v2ray客户端安装目录，双击wv2ray.exe运行即可。\n\n*v2ray.exe 和 wv2ray.exe 的区别：前者是以命令行窗口的形式在前台显示，后者则没有窗口。*\n\n### 设置v2ray客户端开机自启动\n\n1、按下快捷键：Win+R，输入`shell:startup`，回车，此时会打开一个文件夹，在这个文件夹里放入的任何程序，都会在开机时自动运行。\n\n*Windows键(Winkey)，简称“Win键”，是在计算机键盘左下角 Ctrl 和 Alt 键之间的按键，图案是 Microsoft Windows 的视窗图标。 现在大多数运行 Windows 的 PC 键盘上都有这个按键。*\n\n2、打开v2ray客户端安装目录，找到wv2ray.exe，创建它的快捷方式，并将该快捷方式放到上面打开的那个文件夹里。\n\n![](4.jpg)\n\n### 安装Proxy SwitchyOmega插件\n\n打开chrome浏览器，去[Github下载](https://github.com/FelisCatus/SwitchyOmega/releases)最新版安装包，或直接[本地下载](https://github.com/FelisCatus/SwitchyOmega/releases/download/v2.5.20/SwitchyOmega_Chromium.crx)文件进行安装。更多信息请访问[Proxy SwitchyOmega官网](https://www.switchyomega.com/download/)查阅。\n\n*在 Chrome 地址栏输入 chrome://extensions 打开扩展程序，拖动 .crx 后缀的 SwitchyOmega 安装文件到扩展程序中进行安装。*\n\n### 配置Chrome浏览器代理模式\n\n1、安装完Proxy SwitchyOmega插件后，会发现chrome浏览器右上方有个小圆圈的标志，点击该小圆圈，单击`选项`按钮，进入SwitchyOmega配置界面，参照下图，修改情景模式。\n\n![](5.jpg)\n\n2、点击`auto switch`按钮，单击`编辑源代码`，然后将里面的内容清空，并将以下内容拷贝进去。\n\n```json\n[SwitchyOmega Conditions]\n@with result\n\n*.v2ray.com +127.0.0.1-1080\n*.iissnan.com +127.0.0.1-1080\n*.hexo.io +127.0.0.1-1080\n*.typora.io +127.0.0.1-1080\n*.doorbell.io +127.0.0.1-1080\n*.docker.com +127.0.0.1-1080\n*.atavi.com +127.0.0.1-1080\n*.jquery.com +127.0.0.1-1080\n*.bootstrapcdn.com +127.0.0.1-1080\n*.apache.org +127.0.0.1-1080\n*.instadp.net +127.0.0.1-1080\n*.golang.org +127.0.0.1-1080\n*.fontawesome.com +127.0.0.1-1080\n*.intercom.io +127.0.0.1-1080\n*.carbonads.net +127.0.0.1-1080\n*.icons8.com +127.0.0.1-1080\n*.icons8.cn +127.0.0.1-1080\n*.gr-assets.com +127.0.0.1-1080\n*.goodreads.com +127.0.0.1-1080\n*.bittiger.io +127.0.0.1-1080\n*.packagecontrol.io +127.0.0.1-1080\n*.sublimetext.com +127.0.0.1-1080\n*.margo.sh +127.0.0.1-1080\n*.color-themes.com +127.0.0.1-1080\n*.pocketgophers.com +127.0.0.1-1080\n*.contentful.com +127.0.0.1-1080\n*.userstyles.org +127.0.0.1-1080\n*.scrimba.com +127.0.0.1-1080\n*.heroku.com +127.0.0.1-1080\n*.cloudflare.com +127.0.0.1-1080\n*.gitbooks.io +127.0.0.1-1080\n*.autopilothq.com +127.0.0.1-1080\n*.evgnet.com +127.0.0.1-1080\n*.godoc.org +127.0.0.1-1080\n*.travis-ci.org +127.0.0.1-1080\n*.apple.com +127.0.0.1-1080\n*.herokuapp.com +127.0.0.1-1080\n*.twimg.com +127.0.0.1-1080\n*.redis.io +127.0.0.1-1080\n*.mozilla.net +127.0.0.1-1080\n*.mozilla.org +127.0.0.1-1080\n*.swagger.io +127.0.0.1-1080\n*.adguard.com +127.0.0.1-1080\n*.visual-paradigm.com +127.0.0.1-1080\n*.*.github.io +127.0.0.1-1080\n*.stackoverflow.com +127.0.0.1-1080\n*.javaworld.com +127.0.0.1-1080\n*.russellluo.com +127.0.0.1-1080\n*.golangprograms.com +127.0.0.1-1080\n*.forestapp.cc +127.0.0.1-1080\n*.kotlinlang.org +127.0.0.1-1080\n*.kotl.in +127.0.0.1-1080\n*.tampermonkey.net +127.0.0.1-1080\n*.zdassets.com +127.0.0.1-1080\n*.zendesk.tv +127.0.0.1-1080\n*.evernote.com +127.0.0.1-1080\n*.uptodown.com +127.0.0.1-1080\n*.yandex.ru +127.0.0.1-1080\n*.yastatic.net +127.0.0.1-1080\n*.jshell.net +127.0.0.1-1080\n*.usesfathom.com +127.0.0.1-1080\n*.jsfiddle.net +127.0.0.1-1080\n*.segment.com +127.0.0.1-1080\n*.atlassian.com +127.0.0.1-1080\n*.bitbucket.org +127.0.0.1-1080\n*.staticfile.org +127.0.0.1-1080\n*.go-zh.org +127.0.0.1-1080\n*.molunerfinn.com +127.0.0.1-1080\n*.explainshell.com +127.0.0.1-1080\n*.ipfs.io +127.0.0.1-1080\n*.yastatic.com +127.0.0.1-1080\n*.yandex.com +127.0.0.1-1080\n*.cryptokitties.co +127.0.0.1-1080\n*.myeoskit.com +127.0.0.1-1080\n*.pixelmaster.io +127.0.0.1-1080\n*.steemit.com +127.0.0.1-1080\n*.okex.com +127.0.0.1-1080\n*.eos.io +127.0.0.1-1080\n*.douban.com +127.0.0.1-1080\n*.xclient.info +127.0.0.1-1080\n*.golangweekly.com +127.0.0.1-1080\n*.awsstatic.com +127.0.0.1-1080\n*.amazon.com +127.0.0.1-1080\n*.amazonaws.com +127.0.0.1-1080\n*.greasyfork.org +127.0.0.1-1080\n*.openuserjs.org +127.0.0.1-1080\n*.basicattentiontoken.org +127.0.0.1-1080\n*.adex.network +127.0.0.1-1080\n*.gitbook.io +127.0.0.1-1080\n*.github.com +127.0.0.1-1080\n*.skyao.io +127.0.0.1-1080\n*.readthedocs.io +127.0.0.1-1080\n*.gobyexample.com +127.0.0.1-1080\n*.go-database-sql.org +127.0.0.1-1080\n*.t.co +127.0.0.1-1080\n*.sourcegraph.com +127.0.0.1-1080\n*.linkerd.io +127.0.0.1-1080\n*.staruml.io +127.0.0.1-1080\n*.jfrog.com +127.0.0.1-1080\n*.google.com +127.0.0.1-1080\n*.time.graphics +127.0.0.1-1080\n*.zupzup.org +127.0.0.1-1080\n*.blockchain.com +127.0.0.1-1080\n*.discord.gg +127.0.0.1-1080\n*.colobu.com +127.0.0.1-1080\n*.technologyreview.com +127.0.0.1-1080\n*.jianshu.com +127.0.0.1-1080\n*.gowalker.org +127.0.0.1-1080\n*.hashingit.com +127.0.0.1-1080\n*.unic.ac.cy +127.0.0.1-1080\n*.cloudfront.net +127.0.0.1-1080\n*.coursera.org +127.0.0.1-1080\n*.quoracdn.net +127.0.0.1-1080\n*.quora.com +127.0.0.1-1080\n*.medium.com +127.0.0.1-1080\n*.ipictheaters.com +127.0.0.1-1080\n*.101blockchains.com +127.0.0.1-1080\n*.michelsen.dk +127.0.0.1-1080\n*.launchd.info +127.0.0.1-1080\n*.jetbrains.com +127.0.0.1-1080\n*.wireshark.org +127.0.0.1-1080\n*.gomods.io +127.0.0.1-1080\n*.bootcss.com +127.0.0.1-1080\n*.githubusercontent.com +127.0.0.1-1080\n\n* +direct\n```\n\n拷贝完成后，其效果应如下图所示：\n\n![](6.jpg)\n\n3、在当前页面下，点击下方`添加规则列表`按钮，选择`AutoProxy`，并输入规则列表网址：<https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt>，点击`立即更新情景模式`，等待规则列表更新，最后单击左侧的`应用选项`按钮。最终其效果应如下图所示：\n\n![](7.jpg)\n\n此时，在chrome浏览器中输入：www.google.com ，发现谷歌可以正常访问了。\n","tags":["Win10","shadowsocks","v2ray"],"categories":["科学上网"]},{"title":"Ubuntu系统下，使用systemd配置开机启动的方法","url":"/2018/11/05/linux-quick-run/","content":"\n从Ubuntu16.04开始，不再使用initd来管理系统，而改用systemd。\n\n## systemd介绍\n\nsystemd默认会读取/etc/systemd/system目录下的配置文件，而该目录下的文件又会链接到/lib/systemd/system目录下的文件。\n\n## 使用systemd配置开机启动\n\n下面**以Ubuntu18.04为例**，配置开机启动。为了与之前的Ubuntu开机启动的方式保持一致，我们希望仍然在/etc/rc.local 文件中配置开机启动程序。具体操作如下：\n\n### 1. 配置rc-local.service文件\n\n一般系统安装完之后，/lib/systemd/system目录下会有rc-local.service文件，即我们所需要的配置文件。\n\n打开 rc-local.service文件，可以看到类似以下内容：\n\n```shell\n#  SPDX-License-Identifier: LGPL-2.1+\n#\n#  This file is part of systemd.\n#\n#  systemd is free software; you can redistribute it and/or modify it\n#  under the terms of the GNU Lesser General Public License as published by\n#  the Free Software Foundation; either version 2.1 of the License, or\n#  (at your option) any later version.\n\n# This unit gets pulled automatically into multi-user.target by\n# systemd-rc-local-generator if /etc/rc.local is executable.\n[Unit]\nDescription=/etc/rc.local Compatibility\nDocumentation=man:systemd-rc-local-generator(8)\nConditionFileIsExecutable=/etc/rc.local\nAfter=network.target\n\n[Service]\nType=forking\nExecStart=/etc/rc.local start\nTimeoutSec=0\nRemainAfterExit=yes\nGuessMainPID=no\n```\n\n**一般来说，正常的启动文件主要分成三部分**\n\n- [Unit] 段：启动顺序与依赖关系 \n- [Service] 段：启动行为,如何启动，启动类型 \n- [Install] 段：定义如何安装这个配置文件，即怎样做到开机启动\n\n可以看出，/etc/rc.local 的启动顺序是在network后面，但是显然它少了 [Install] 段，也就是，没有定义如何做开机启动，所以我们需要在后面加上 [Install] 段：\n\n```shell\n[Install]  \nWantedBy=multi-user.target  \nAlias=rc-local.service\n```\n\n配置好之后，文件内容是这样的：\n\n![](1.png)\n\n然后保存退出。\n\n### 2. 配置rc.local文件\n\n因为Ubuntu18.04系统默认是没有 /etc/rc.local 文件的，所以需要我们手动创建，并赋予其可执行权限：\n\n```shell\n$ sudo touch /etc/rc.local\n$ sudo chmod 755 /etc/rc.local\n```\n\n打开rc.local文件，添加以下内容：\n\n```shell\n#!/bin/sh -e\n#\n# rc.local\n#\n# This script is executed at the end of each multiuser runlevel.\n# Make sure that the script will \"exit 0\" on success or any other\n# value on error.\n#\n# In order to enable or disable this script just change the execution\n# bits.\n#\n# By default this script does nothing.\n\nexit 0\n```\n\n接着就可以在里面添加我们所需要的开机启动程序命令，可以直接写命令，也可以执行Shell脚本文件sh。\n\n这里我们先写一个测试命令`echo \"this just a test\" > /usr/local/text.log`，以验证脚本是否生效，注意命令一定要写在`exit 0`之前。\n\n测试命令添加完之后，文件内容是这样的：\n\n![](2.png)\n\n### 3. 为rc.local.service创建软链接\n\n通过`ls`命令可以看到，`/lib/systemd/system/rc.local.service`是一个软链接，链接到`/lib/systemd/system/rc-local.service`，而且 systemd 是默认读取 /etc/systemd/system 下的配置文件,，所以我们还需要在 /etc/systemd/system 目录下创建一个软链接，链接到`/lib/systemd/system/rc.local.service`，如下：\n\n```shell\nsudo ln -s /lib/systemd/system/rc.local.service /etc/systemd/system/ \n```\n\n此时在/etc/systemd/system目录下会看到生成了一个软链接 rc.local.service。\n\n### 4. 重启系统，验证测试脚本\n\n执行`reboot`命令重启系统，查看/usr/local目录，会发现生成了一个text.log，说明开机启动已配置成功。\n","tags":["ubuntu","开机自启","systemd"],"categories":["linux系统"]},{"title":"搬瓦工搭建Shadowsocks过程中的常见注意事项","url":"/2018/11/05/ss-bbr-vps/","content":"\n## 使用搬瓦工VPS搭建Shadowsocks服务\n\n在搬瓦工上搭建Shadowsocks服务的教程请参考[这里](https://www.wervps.com/we/2252.html)（之前有个大神写的博客，里面介绍的很详细，不过据说被hexie了，已经打不开了）。下面我主要说一些注意事项，以备参考，避免踩坑。\n\n## 购买VPS时的注意事项\n\n### 选择购买哪种VPS？\n\n如果只是用于科学上网，那么不需要购买太高配置的VPS，19.99美元/年的完全够用，1年100多块钱，算是很划算的了。\n\n![](1.png)\n\n### 选择KVM or OpenVZ ？\n\nKVM和OpenVZ是两种不同的VPS虚拟技术。\n\n- OpenVZ是基于Linux内核和作业系统的操作系统级虚拟化技术。OpenVZ允许物理服务器运行多个操作系统，被称虚拟专用服务器（VPS，Virtual Private Server）或虚拟环境（VE, Virtual Environment）。\n\n- KVM是嵌入在Linux操作系统标准内核中的一个虚拟化模块，它能够将一个Linux标准内核转换成为一个VMM，嵌有KVM模块的Linux标准内核可以支持通过kvm tools来进行加载的GuestOS。所以在这样的操作系统平台下，计算机物理硬件层上直接就是VMM虚拟化层，而没有独立出来的HostOS操作系统层。\n\n从下图搬瓦工官网给出的这两者之间的优点对比可以看出，KVM能够支持BBR，所以如果选择OpenVZ的话，是无法使用BBR的，只有KVM架构的VPS才能开启BBR。\n\n- BBR是Google社区开发的一个开源TCP拥塞控制算法，在**Linux 4.9及以上的内核版本中支持**。\n\n- BBR主要是用于提升上传速度，所以如果在服务端配置BBR的话，提升的是服务端的上传速度，也就是提升了客户端的下载速度。\n\n**综上，建议选择KVM虚拟技术，便于开启BBR加速。**\n\n![](2.png)\n\n### 选择机房位置\n\n在产品配置页，会看到有一项要选择VPS所在的机房位置，一般来说，离我们近一点的机房会相对稳定一些，其实都差不多，这里推荐选择**Los Angeles DC2 QNET**。\n\n![](3.png)\n\n## 部署Shadowsocks服务时的注意事项\n\n在网上的一些论坛看到，有些人说用ShadowsocksR（简称SSR）容易被墙，用Shadowsocks（简称SS）要稳一些，所以建议大家使用SS。\n\n- 上面那位大神的教程里介绍了如何在Windows系统上安装和使用Shadowsocks，请自行参考安装。\n- 在Linux系统上安装和使用Shadowsocks请参考[这里](https://blog.huihut.com/2017/08/25/LinuxInstallConfigShadowsocksClient/)，写的也是非常详细，而且还介绍了开机自启的配置方法。\n\n### 建议在使用Shadowsocks时，使用浏览器代理\n\n- 在Windows系统上使用Shadowsocks，启用系统代理时，有时会发现仍不能科学上网。这是因为Shadowsocks-Win版本对系统代理支持的不好，所以建议**使用浏览器代理**的方式。\n\n  ![](4.png) \n\n  具体配置方法请参考[这篇文章的“浏览器代理”章节](https://blog.huihut.com/2017/08/25/LinuxInstallConfigShadowsocksClient/) 。\n\n  ![](7.png)\n\n- 在Linux系统上运行命令安装Shadowsocks以后，可能会发现在etc目录下，并没有shadowsocks.json，但是有一个shadowsocks目录，里面有个config.json文件。那么具体应该怎么来配置呢？其实以下两种方式都是可行的。\n\n  （1）像文章中描述的那样，自建一个shadowsocks.json文件，然后添加配置信息。\n\n  （2）直接修改config.json文件，添加配置信息。\n\n  **只要确保一点**：在后面使用ssllocal -c 命令启动shadowsocks程序时，后面接的路径与你修改的json配置文件的路径一致即可。\n\n- 目前 SwitchyOmega 插件只支持 **Google Chrome 或基于 Chromium 的浏览器** 以及 **Mozilla Firefox 或基于 Mozilla 的浏览器** ，当然国产浏览器说的什么自主研究的极速内核（如：360极速浏览器）大多都是使用的 Chromium 内核，所以也能安装使用。\n\n  但是据说国产浏览器会对浏览器访问的网页进行监控，科学上网久了，会存在被墙（封IP）的风险，所以**建议使用Chrome或Firefox浏览器**。\n\n### Linux环境下，如何让终端Terminal使用Shadowsocks进行科学上网\n\n#### 安装polipo\n\nPolipo是一个轻量级的跨平台代理服务器，可以实现HTTP和SOCKS代理。为了最小化延迟，Polipo管线化多个资源请求，在同一个TCP/IP连接上多路复用。所以我们使用**polipo将http代理转换为socks5代理**。从而使终端命令行程序（如：wget）可以进行科学上网。\n\n通过apt安装polipo\n\n```shell\n$ sudo apt-get install polipo\n```\n\n#### 配置polipo\n\n打开 /etc/polipo/config 文件\n\n```shell\n$ sudo vi /etc/polipo/config\n```\n\n作如下修改，主要是设置socksParentProxy 和 socksProxyType的字段值。\n\n```shell\n# This file only needs to list configuration variables that deviate\n# from the default values.  See /usr/share/doc/polipo/examples/config.sample\n# and \"polipo -v\" for variables you can tweak and further information.\n\nlogSyslog = true\nlogFile = /var/log/polipo/polipo.log\nsocksParentProxy = \"localhost:1080\"\nsocksProxyType = socks5\nloglevel = 4\n```\n\n重启polipo\n\n```shell\n$ service polipo restart\n```\n\n设置别名，便于在终端上使用SS代理。\n\n打开用户主目录下的.bashrc文件\n\n```shell\n$ cd ~/\n$ vi .bashrc\n```\n\n在 .bashrc文件最后面增加下面几行：\n\n```shell\nalias goproxy=\"export http_proxy=http://localhost:8123 https_proxy=http://localhost:8123;echo 'complete proxy settings'\"\nalias disproxy=\"unset http_proxy https_proxy;echo 'unset proxy'\"\n```\n\n保存退出，重启终端Terminal。\n\n#### 测试验证\n\n重启终端Terminal之后，输入以下命令：\n\n```shell\n$ goproxy\n$ wget www.google.com.hk\n```\n\n若显示以下类似结果，则表示Shadowsocks在终端Terminal上配置成功。\n\n![](5.png)\n\n如果想要关闭SS代理，则直接在终端执行 `disproxy`命令即可。\n\n### Windows环境下，如何让MinGW使用Shadowsocks进行科学上网\n\n打开Git Bash，即MinGW，输入以下命令，进入用户目录：\n\n```shell\n$ cd ~/\n```\n\n创建 .bash_profile 文件，并打开。\n\n```shell\n$ vi .bash_profile\n```\n\n添加以下内容：\n\n```shell\n#! /bin/bash\n# add alias\nalias goproxy=\"export http_proxy=127.0.0.1:1080 https_proxy=127.0.0.1:1080; echo 'complete proxy settings'\"\nalias disproxy=\"unset http_proxy https_proxy; echo 'unset proxy'\"\n```\n\n保存退出，重启MinGW，输入以下命令。\n\n*由于我安装的MinGW里面没有wget，所以使用 curl 来测试验证。*\n\n```shell\n$ goproxy\n$ curl www.google.com.hk\n```\n\n若显示以下类似结果，即有内容输出，则表示Shadowsocks在MinGW上配置成功。\n\n![](6.png)\n\n如果想要关闭SS代理，则直接在MinGW上输入 `disproxy`命令即可。","tags":["搬瓦工","shadowsocks","SwitchyOmega"],"categories":["科学上网"]},{"title":"利用 Github Pages + Hexo + NexT 搭建私人博客","url":"/2018/11/02/githubpages-hexo-next/","content":"\n## 为什么选择Github Page\n\n简单快捷，而且Github Pages可以为你提供一个免费的服务器，免去了自己搭建服务器和读写数据库的麻烦。\n\n## 为什么选择Hexo，而不是Jekyll\n\n目前有两大静态博客主流框架：[jekyll](http://jekyllcn.com/)和[hexo](https://hexo.io/)。我个人选择Hexo的主要原因：\n\n- Jekyll基于Ruby实现，所以安装Jekyll需要搭建Ruby环境，但是在Windows上搭建Ruby环境比较麻烦，而 Hexo基于NodeJs实现，在Windows上安装NodeJs开发环境比较简单。\n\n- Jekyll本地预览的操作比较繁琐，而相比之下，Hexo只需简单几个命令，就可以实现本地预览。\n\n- Jekyll生成静态站点的速度比Hexo的慢很多。\n\n**下面就让我们一步步的来搭建属于我们自己的博客吧！**\n\n## 安装Node.js\n\n在 Windows 环境下安装 Node.js 非常简单，到[nodejs官网](https://nodejs.org/zh-cn)下载并安装最新版本即可。安装时，无脑下一步就行了，不需要配置环境变量。\n\n**注意：**Node.js 版本需不低于 10.13，建议使用 Node.js 12.0 及以上版本。\n\n## 安装Git（可选）\n\n去[Git官网](https://git-scm.com/download/win)根据你的电脑参数，下载对应版本。\n\n下载完成，通过在命令行输入 `git version` 查看是否安装成功，有输出版本号说明安装成功。\n\n此时鼠标右击后，菜单里就多了`Git GUI Here`和`Git Bash Here`两个按钮，前者是图形界面的Git操作，后者是命令行操作，这里我们选择使用`Git Bash Here`。\n\n**Git入门教程：** [Pro Git（中文版）](http://git.oschina.net/progit/)\n\n## 安装和体验Hexo\n\nHexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。\n\n### 1. 安装Hexo\n\n在Windows桌面，右键鼠标，点击\"Git Bash Here\"，打开Git Bash。\n\n先配置下淘宝源，这样下载速度会快一些。\n\n```shell\n$ npm config set registry https://registry.npmmirror.com\n```\n\n然后安装hexo。\n\n```shell\n$ npm install -g hexo-cli\n```\n\n在安装过程中，控制台可能会出现一些Warning，可以不用过于在意。\n\n安装完毕后，输入：`hexo -v`。\n\n此时可能会报错：`bash: hexo: command not found`，这是因为没有配置hexo的环境变量导致。\n\n**解决方法**：在系统变量Path里增加hexo的环境变量，具体路径在刚才安装Hexo的时候已经打印在控制台中了。比如我的路径是这样的：\n\n![](hexo_path.jpg)\n\n配置完环境变量后，再输入`hexo -v`，会发现控制台上打印出一些hexo的版本信息，说明Hexo安装成功了。\n\n### 2.  Hexo初始化配置\n\n#### 创建Hexo博客项目文件夹\n\n根据自己的喜好新建目录（如F:\\Blog\\Hexo），进入到F:\\Blog\\Hexo文件夹下，右键鼠标，点击Git Bash Here，进入Git命令框，执行以下操作。\n\n```shell\n$ hexo init\n```\n\n这个命令会从Github上的官方Hexo项目拉取用于项目初始化的代码，其中包含名为package.json的描述性文件。初始化完毕后，可以看到Hexo文件夹下的目录如下：\n\n```shell\n|- node_modules\n|- scaffolds\n|- source\n|- themes\n|- .gitignore\n|- _config.yml\n|- package.json\n```\n\n其中_config.yml为Hexo的配置描述文件，source目录用于存放博客内容（ source/\\_posts目录下默认会生成一个hello-world.md文件），themes目录用于存放主题的样式（一般默认会生成一个landscaple主题目录）。\n\n#### 本地查看效果\n\n在Hexo目录下，打开Git Bash，执行以下命令，然后在浏览器中输入 localhost:4000，即可查看主题效果。\n\n```shell\n$ hexo generate\n$ hexo server\n```\n\n注：这两个命令也可以简写成 hexo g 和 hexo s\n\n![](hexo_preview.jpg)\n\n## 将本地Hexo博客部署到Github Pages上\n\n### 1. 准备工作\n\n- 注册一个Github账号\n- 配置好Github环境，包括配置SSH密钥等。\n\n### 2. 新建Github仓库\n\n（1）登录github，点击`New repository`创建仓库。\n\n![](create_repository.png)\n\n（2）填写仓库属性。\n\n**注意：仓库名一般以`user_name`.github.io的形式命名。其中`user_name`是指你的github用户名。如果没有按照这种形式来命名，待会你就会发现创建的博客站点地址比较长，看起来比较奇怪。**\n\n![](config_repository.png)\n\n（3）查看创建的博客信息。\n\n点击`Settings`\n\n![](setting.png)\n\n进入之后，页面往下滚动，找到标题`GitHub Pages`，就会看到你的站点链接。\n\n![](site.png)\n\n点击这个链接，会发现只是一个静态页面，页面内容就是README.md文件的内容。\n\n**如果仓库名没有按照上面说的格式来命名的话，会发现你的站点链接会相对长一些。其实链接长短并无好坏之分，根据个人喜好而定。**\n\n### 3. 将本地的Hexo博客提交到Github仓库中\n\n（1）安装hexo-deployer-git工具，用于部署博客到Github。\n\n```shell\n$ npm install hexo-deployer-git --save\n```\n\n（2）打开刚刚创建的github仓库，点击`Clone or download`，复制github仓库地址。\n\n![](onekey_copy.png)\n\n（3）打开之前创建的Hexo博客文件夹（如F:\\Blog\\Hexo），用记事本打开该文件夹下的_config.yml文件，在文件底部找到`deploy`字段，并作如下修改：\n\n```yaml\ndeploy:\n  type: git\n  repository: git@github.com:pgz100/pgz100.github.io.git\n  branch: master\n```\n\n其中`repository`是刚刚复制的github仓库地址。*注意：将上述`repository`的值改成自己的仓库地址。*\n\n（4）在Hexo目录下右键打开Git Bash Here，输入以下命令，将你的博客部署到你的Github上。\n\n注：hexo g 是 hexo generate的简写， hexo d 是 hexo deploy 的简写。\n\n```shell\n$ hexo g\n$ hexo d\n```\n\n或直接执行\n\n```shell\n$ hexo g -d\n```\n\n如果此时报错：ERROR Deployer not found: git，则说明deployer没有安装成功，需要执行如下命令再安装一次：\n\n```shell\n$ npm install hexo-deployer-git --save\n```\n\n然后再执行 `hexo g -d`，你的博客就成功部署到你的Github上了。\n\n（5）在浏览器上输入你的博客地址，如：我的博客地址：https://pgz100.github.io/ ，就能看到刚刚部署上去的Hexo的主题效果了。\n\n## 使用NexT主题美化博客\n\n[Next](https://theme-next.iissnan.com/)的标语是**精于心，简于形**，说的很贴切。下面就来看看具体如何使用NexT来美化我们的博客吧。\n\n### 1. 安装主题\n\n进入我们之前创建的Hexo博客目录下，右键鼠标，打开Git Bash，输入以下命令：\n\n```shell\n$ git clone https://github.com/theme-next/hexo-theme-next themes/next\n```\n\n这行命令的意思是从 https://github.com/theme-next/hexo-theme-next 上将NexT主题内容下载到当前目录的themes/next目录下。\n\n### 2. 启用主题\n\n修改Hexo目录下的`_config.yml`文件，之前我们介绍过这个文件，是专门用于配置Hexo的，这里我们把它叫做**站点配置文件**。\n\n```yaml\n# Extensions\n## Plugins: https://hexo.io/plugins/\n## Themes: https://hexo.io/themes/\ntheme: next\n```\n\n### 3. 设置语言为简体中文\n\n进入Hexo/themes/next/languages目录，这个目录存放的是NexT主题支持的所有语言。实际上，Hexo 在生成的时候会根据**站点配置文件**中设置的language，来查找对应的语言翻译，并提取显示文本。在languages目录下，会发现有个叫`zh-CN.yml`的文件，这个文件对应的就是简体中文。\n\n具体设置方法：打开**站点配置文件** _config.yml，找到language字段，将其设置为zh-CN。\n\n**这里需要重点注意下**，在NexT官网的使用文档中，写的是将language配置成zh-Hans，是因为之前NexT主题是在 https://github.com/iissnan/hexo-theme-next 里面维护的，这里的简体中文对应的是 languages/zh-Hans.yml文件，后来NexT主题版本升级为6.0，把仓库也搬到了 https://github.com/theme-next/hexo-theme-next ，这里的简体中文对应的是 languages/zh-CN.yml文件。所以，language字段值的设置与所下载的TexT主题版本是相关联的，我们在设置其它语言时也需要注意一下。\n\n右键鼠标，选择Git Bash Here，打开Git Bash，输入以下命令：\n\n```shell\n$ hexo clean  （最好每次本地预览或更新主题到github前都clean下，防止因为缓存问题，导致更新不及时）\n$ hexo g\n$ hexo s\n```\n\n打开浏览器，输入 `localhost:4000` 预览主题效果。\n\n如果觉得效果满意，可以执行以下命令，将它部署到你的Github上。\n\n```shell\n$ hexo clean\n$ hexo g -d\n```\n\n### 4. 主题的其它相关配置\n\n在Hexo/themes/next目录下，我们会发现也有一个`_config.yml`文件，这个文件是由主题作者提供，用于配置主题相关的选项，这里我们把它叫做**主题配置文件**。\n\n其实，NexT官网有个专业的说明文档，里面详细介绍了NexT的使用和配置方法。更多的NexT主题配置，请进入Next官网，[查看Next使用文档](https://theme-next.iissnan.com/getting-started.html)。另外还有一位大佬写的博客，内容也非常的全面：https://www.cnblogs.com/php-linux/p/8416122.html\n\n## 在Hexo博客上写文章\n\n### 1. 用hexo创建文章\n\n我们在写文章时，有些情况下，需要在文章中插入一些图片，此时可以采用本地引用的方法，将图片放在文章自己的目录中。具体方法如下：\n\n- 打开**站点配置文件** _config.yml，将文件中的配置项`post_asset_folder`设为`true`，并增加配置项`marked`。\n  \n  ```yaml\n  post_asset_folder: true\n  marked:\n  prependRoot: true\n    postAsset: true\n  ```\n  \n- 在本地Hexo目录下（如F:\\Blog\\Hexo），右键鼠标，打开Git Bash，执行命令\n  \n  ```shell\n  $ hexo new my_article\n  ```\n  \n  此时会在source/_posts/目录下生成my_article.md 和 同名文件夹my_article。\n\n- 将需要使用的图片资源放在my_article目录下，在文章中就可以使用相对路径来引用图片资源了，例如：\n  \n  ```shell\n  图片资源路径：_posts/my_article/image.jpg\n  文章引用图片资源的写法：![](image.jpg)\n  ```\n\n### 2. 用Markdown写文章\n\nWindows下主流的Markdown编辑器是MarkdownPad2。这里推荐另外一款编辑器：[Typora](https://typora.io/)，个人感觉也很好用，目前支持Mac OS X（要求10.10及以上的系统版本）、Windows、Linux系统。\n\n### 3. 将文章push到Github上\n\n文章写完后，可以先在本地预览效果，也可以直接使用命令 `hexo g -d`将文章推送到我们的Github仓库中。\n\n## 遇到的问题和解决方案\n\n### 1. 本地博客部署到Github后，Github站点没有更新\n\n可能是因为在执行`hexo g -d`之前没有先执行`hexo clean`来清空database以及删除public目录。\n\n### 2. 如何在博客首页设置文章显示 [阅读全文] ？\n\n在首页显示一篇文章的部分内容，并提供一个链接跳转到全文页面是一个常见的需求。在首页显示文章的摘录并显示 **阅读全文** 按钮，可以通过修改**主题配置文件** _config.yml实现，将auto_excerpt中enable设为true，其中`length:150`是指显示在首页的文字长度为150字符，可根据需要自行设定。\n\n```yaml\nauto_excerpt:\nenable: true\nlength: 150\n```\n","tags":["Github Pages","Hexo","NexT","Win10"],"categories":["博客搭建"]},{"title":"uiautomator2.0脱离PC运行，实现模拟点击","url":"/2018/10/08/uiautomator/","content":"\n最近在开发一个自动化测试工具，但又不想那么麻烦的让手机一直连着电脑，所以想找找有没有办法让工具脱离PC运行，由于之前接触过uiautomator，所以想基于这个框架来实现。刚开始主要参考了一个大神的文章 [uiautomator2.0+脱离PC运行（apk启动uiautomator2.0+）的实现方案](https://blog.csdn.net/cxq234843654/article/details/52605441) 进行方案验证。但在实施过程中，遇到了一些问题，通过各种搜各种查，最终都解决了，期间还顺便把android studio升级到了3.2版本。本文主要是在之前这位大神发表的文章基础上，再将方案和流程细化一下，避免大家再次踩坑。\n\n## 实现效果\n打开MyTest.apk，点击 RUN，就能直接运行uiautomator脚本。\n\n## 开发环境\n**IDE：**Android Studio3.2\n![](1.png)\n\n**硬件：**已经ROOT的红米Note\n\n*如果手机没有 root，则需要事先准备好该手机操作系统对应的系统签名文件，因为 MyTest APP 需要拥有系统权限，才能执行 am instrument 命令来运行  uiautomator 脚本。由于很多手机厂商会对 Android 系统进行定制修改，所以使用原生的 Android 系统证书 platform.x509.pem 和 platform.pk8 文件给 APP 添加系统签名是无效的。所以最终我选择了将手机 ROOT 。*\n\n## 方案概述\n- 新建一个Android app工程MyTest，在Activity中添加Button，用于启动uiautomaotr脚本\n- 给这个app添加系统签名。`若手机已root，则忽略此步。`\n- 在MyTest中新建一个module，命名为MyTestCase，用于编写uiautomaotr脚本\n- 使用`am instrument`命令实现脚本的运行，执行模拟点击\n\n## 具体步骤\n**1、新建一个Android应用，命名为MyTest**\n\n![](2.png)\n![](3.png)\n并选择Empty Activity，一路next到finish。\n\n**2、给UI增加Button，修改res/layout目录下activity_main.xml文件**\n\n```xml\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<android.support.constraint.ConstraintLayout xmlns:android=\"http://schemas.android.com/apk/res/android\"\n    xmlns:app=\"http://schemas.android.com/apk/res-auto\"\n    xmlns:tools=\"http://schemas.android.com/tools\"\n    android:layout_width=\"match_parent\"\n    android:layout_height=\"match_parent\"\n    tools:context=\".MainActivity\">\n\n    <Button\n        android:onClick=\"runMyUiautomator\"\n        android:id=\"@+id/runBtn\"\n        android:layout_width=\"wrap_content\"\n        android:layout_height=\"wrap_content\"\n        android:text=\"run\" />\n\n</android.support.constraint.ConstraintLayout>\n```\n**3、修改MainActivity.java文件MainActivity Class。添加Button事件、uiautomator线程、创建CMDUtils类等。**\n\n*注意： generateCommand 函数的三个入参分别是待会我们要创建的 uiautomator 脚本的包名、类名、方法名。*\n\n```java\npublic class MainActivity extends AppCompatActivity {\n    private static final String TAG = \"MainActivity\";\n    Button runBtn;\n\n    @Override\n    protected void onCreate(Bundle savedInstanceState) {\n        super.onCreate(savedInstanceState);\n        setContentView(R.layout.activity_main);\n        runBtn= findViewById(R.id.runBtn);\n    }\n\n    /**\n     * 点击按钮对应的方法\n     * @param v\n     */\n    public void runMyUiautomator(View v){\n        Log.i(TAG, \"runMyUiautomator: \");\n        new UiautomatorThread().start();\n        Toast.makeText(this, \"start run\", Toast.LENGTH_SHORT).show();\n    }\n\n    /**\n     * 运行uiautomator是个费时的操作，不应该放在主线程，因此另起一个线程运行\n     */\n    class UiautomatorThread extends Thread {\n        @Override\n        public void run() {\n            super.run();\n            String command = generateCommand(\"zhepan.com.mytestcase\", \"ExampleInstrumentedTest \", \"useAppContext\");\n            CMDUtils.CMD_Result rs= CMDUtils.runCMD(command,true,true);\n            Log.e(TAG, \"run: \" + rs.error + \"-------\" + rs.success);\n        }\n\n        /**\n         * 生成命令\n         * @param pkgName uiautomator包名\n         * @param clsName uiautomator类名\n         * @param mtdName uiautomator方法名\n         * @return\n         */\n        public  String generateCommand(String pkgName, String clsName, String mtdName) {\n            String command = \"am instrument -w -r -e debug false -e class \"\n                    + pkgName + \".\" + clsName + \"#\" + mtdName + \" \"\n                    + pkgName + \".test/android.support.test.runner.AndroidJUnitRunner\";\n            Log.e(\"test1: \", command);\n            return command;\n        }\n    }\n}\n```\nCMDUtils.java文件内容如下：\n**注意:** \n\n- 我没有采用给APP添加系统签名的方式来获取系统权限，而是在代码中使用`Runtime.getRuntime().exec(\"su\");`来获取root权限，但`前提是你的手机已经root，且装有授权管理，允许应用来申请root权限`。\n\n- 当执行`Runtime.getRuntime().exec(\"su\");`这行代码时，手机上会弹出一个对话框问你是否允许申请root，但只是执行这条命令有root权限而已，并不是整个程序都有root权限。这点`需要特别注意`。\n\n~~~java\n/**\n * 执行命令\n */\npublic class CMDUtils {\n\n    private static final String TAG = \"CMDUtils\";\n\n    public static class CMD_Result {\n        public int resultCode;\n        public String error;\n        public String success;\n\n        public CMD_Result(int resultCode, String error, String success) {\n            this.resultCode = resultCode;\n            this.error = error;\n            this.success = success;\n        }\n\n    }\n\n    /**\n     * 执行命令\n     *\n     * @param command         命令\n     * @param isShowCommand   是否显示执行的命令\n     * @param isNeedResultMsg 是否反馈执行的结果\n     * @retrun CMD_Result\n     */\n    public static CMD_Result runCMD(String command, boolean isShowCommand,\n                                    boolean isNeedResultMsg) {\n        if (isShowCommand)\n            Log.i(TAG, \"runCMD:\" + command);\n        CMD_Result cmdRsult = null;\n        int result;\n        Process process = null;\n        PrintWriter pw = null;\n        try {\n            process = Runtime.getRuntime().exec(\"su\"); //获取root权限\n            pw = new PrintWriter(process.getOutputStream());\n            pw.println(command);\n            pw.flush();\n            result = process.waitFor();\n            if (isNeedResultMsg) {\n                StringBuilder successMsg = new StringBuilder();\n                StringBuilder errorMsg = new StringBuilder();\n                BufferedReader successResult = new BufferedReader(\n                        new InputStreamReader(process.getInputStream()));\n                BufferedReader errorResult = new BufferedReader(\n                        new InputStreamReader(process.getErrorStream()));\n                String s;\n                while ((s = successResult.readLine()) != null) {\n                    successMsg.append(s);\n                }\n                while ((s = errorResult.readLine()) != null) {\n                    errorMsg.append(s);\n                }\n                cmdRsult = new CMD_Result(result, errorMsg.toString(),\n                        successMsg.toString());\n            }\n        } catch (Exception e) {\n            Log.e(TAG, \"run CMD:\" + command + \" failed\");\n            e.printStackTrace();\n        } finally {\n           if (pw != null) {\n                pw.close();\n            }\n            if (process != null) {\n                process.destroy();\n            }\n        }\n        return cmdRsult;\n    }\n}\n~~~\n**4、新建一个Module，用于编写uiautomator脚本**\n\n单击项目名称，右击“New – Module – Phone&Table Module\"，\n![](4.png)\n并填写如下信息，\n![](5.png)\nNext之后，选择 \"Add No Activity\" --> Finish。\n\n**5、修改mytestcase模块的build.gradle文件**\n\n![](6.png)\n- 打开build.gradle文件，可以看到系统已经自动在defaultConfig中添加了Runner（`testInstrumentationRunner \"android.support.test.runner.AndroidJUnitRunner\"`）。如系统未自动添加，请自行添加一下。\n\n![](7.png)\n\n- 在dependencies中添加依赖\n  ~~~java\n  dependencies {\n   \timplementation fileTree(dir: 'libs', include: ['*.jar'])\n  \n    \timplementation 'com.android.support:appcompat-v7:27.1.1'\n    \timplementation 'junit:junit:4.12'\n    \timplementation 'com.android.support.test:runner:1.0.2'\n    \timplementation 'com.android.support.test.uiautomator:uiautomator-v18:2.1.3'\n    \tandroidTestImplementation 'com.android.support.test.espresso:espresso-core:3.0.2'\n  }\n  ~~~\n\n**6、编写uiautomator脚本并运行（附加原理分析）**\n\n打开系统自行创建的测试类ExampleInstrumentedTest.java文件（在mytestcase\\src\\androidTest\\java\\zhepan\\com\\mytestcase目录下），或自己新建一个测试类。\n\n![](8.png)\n\n修改ExampleInstrumentedTest类如下：\n\n~~~java\n/**\n * Instrumented test, which will execute on an Android device.\n *\n * @see <a href=\"http://d.android.com/tools/testing\">Testing documentation</a>\n */\n@RunWith(AndroidJUnit4.class)\npublic class ExampleInstrumentedTest {\n    private UiDevice mDevice;\n    @Test\n    public void useAppContext() throws UiObjectNotFoundException {\n        mDevice = UiDevice.getInstance(InstrumentationRegistry.getInstrumentation());\n        mDevice.pressHome();\n        UiObject x=mDevice.findObject(new UiSelector().text(\"联系人\"));\n        x.click();\n    }\n}\n~~~\nCase说明：\n\n- @RunWith注解，代表使用什么Runner\n- @Test注解，表示当前的方法为测试方法\n\n**注意：** 还记得第3步MainActivity.java文件中的generateCommand函数吗？这个函数的`三个入参`分别是<span id=\"inline-blue\"> 上面这个测试类的 </span>`包名、类名和方法名`，一定要记得对应上。\n\n接着运行一下你的case，测试是否有效。运行方法：点击带有Test注解的方法左侧绿色三角形\n![](9.png)\n此时，控制台Run窗口会输出如下信息：\n![](10.png)\n**原理分析：**\n\n可以看出，窗口其实执行了3条命令：\n\n```shell\n$ adb push G:\\Test\\MyTest\\mytestcase\\build\\outputs\\apk\\debug\\mytestcase-debug.apk /data/local/tmp/zhepan.com.mytestcase\n```\n\n在我们点击运行之后，AS会自动将用例打包成apk文件。\n\n```shell\n$ adb shell pm install -t -r \"/data/local/tmp/zhepan.com.mytestcase\"\n```\n\n将这个apk安装到手机上\n\n```shell\n$ adb shell am instrument -w -r   -e debug false -e class 'zhepan.com.mytestcase.ExampleInstrumentedTest#useAppContext' zhepan.com.mytestcase.test/android.support.test.runner.AndroidJUnitRunner\n```\n\n执行`am`命令，使用AndroidJunitRunner启动测试用例。\n\n通过分析这个过程，我们知道了AS是如何将用例跑起来的。仿照这个原理我们就可以自己实现通过apk调用uiautomator用例：只要让app中的button响应事件去执行am instrument命令即可，但是由于执行这个命令是需要系统权限的，因此需要给app添加系统签名，或跑在已经root的手机上。\n\n**7、给APP添加系统签名（手机已 ROOT 的可跳过此步）**\n\n大致过程如下，具体的细节可以参照一位大神之前写过的文章[Android Studio自动生成带系统签名的apk](https://blog.csdn.net/cxq234843654/article/details/51557025)： \n（1）修改MyTest APP中的manifest.xml文件，添加`android:sharedUserId=\"android.uid.system\"`\n（2）生成js文件 \n（3）使用keytool-importkeypair对jks文件引入系统签名 \n（4）配置gradle（app）\n\n**8、通过MyTest APP启动uiautomator脚本，实现脱离PC运行**\n\n运行MyTest APP，由于第6步已运行过uiautomator脚本，mytestcase-debug.apk已安装到手机上，所以此处不必再次运行脚本。\n![](11.png)\n点击RUN，则回到主界面，并打开主界面上的联系人。至此，实现了uiautomator2.0脱离PC运行的效果。\n\n---\n\n最后附上项目源码地址：https://github.com/pgz100/myuiautomator","tags":["uiautomator2.0","脱离PC","模拟点击","android studio3.2","系统权限"],"categories":["android系统"]}]